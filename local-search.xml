<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>《Adaptive Learned Bloom Filter (Ada-BF) Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web》笔记</title>
    <link href="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Adaptive-Learned-Bloom-Filter"><a href="#Adaptive-Learned-Bloom-Filter" class="headerlink" title="Adaptive Learned Bloom Filter"></a>Adaptive Learned Bloom Filter</h1><h2 id="Learned-Bloom-filter"><a href="#Learned-Bloom-filter" class="headerlink" title="　Learned Bloom filter"></a>　Learned Bloom filter</h2><ul><li><em>Learned Bloom filter</em> (LBF) 在<em>Bloom filter</em>之前增加了机器学习模型作为预过滤器，对于每个查询的元素$x$，给出得分$s(x)$，$s(x)$通常与$x\in S$的概率正相关。分类器先在一些可用的训练数据上进行预训练，根据其训练数据的特征对给定查询$x\in S$进行判断（二分类）。LBF设置阈值$\tau$，当$s(x)\geq \tau$时则判断$x\in S$，否则便使用<em>Bloom filter</em>进行进一步的判断。就像<em>standard Bloom filter</em>，LBF的<em>false negative rate</em>（FNR）为0。而<em>false positive rate</em>（FPR）可以由分类模型与<em>Bloom filter</em>的误报引起。</li><li>可以看出，当区域$s(x)≥τ$包含更多的$x$时，插入<em>Bloom filter</em>的关键字数会减少，从而导致良好的FPR。由于区域$s(x)≥τ$为正值，为了保证预过滤器判断正确，所以$τ$值越高越好，但$\tau$的增大会增加<em>Bloom filter</em>的负载。因此需要找到两者的平衡。</li></ul><h3 id="Wastage-of-Information"><a href="#Wastage-of-Information" class="headerlink" title="Wastage of Information"></a>Wastage of Information</h3><ul><li>当$s(x)&lt;\tau$时，采用<em>Bloom filter</em>进行查询判断，此时$s(x)$中的信息并没有得到使用。例如，当有两个元素$x_1,x_2$，并且$\tau&gt;s(x_1)\gg s(x_2)$。在使用LBF时，两者会采用相同方法进行判断，而直观来看，$x_1$比$x_2$更有可能属于$S$。</li></ul><h3 id="Strong-dependency-on-Generalization"><a href="#Strong-dependency-on-Generalization" class="headerlink" title="Strong dependency on Generalization"></a>Strong dependency on Generalization</h3><ul><li>由原理可知，当数据分布没有变化时，预过滤器更高的准确率可以降低FPR。但是，在部署了<em>Bloom filters</em>的在线环境中，数据分布可能会发生变化。众所周知，数据流具有分布上有漂移的突发性质。因此，分类器的置信度以及阈值并不是完全可靠的。其次，机器学习对特殊例子的敏感性给系统带来了新的问题，对于任何给定置信水平$τ$的分类器，可以很容易地创建被错误分类的示例。<em>Bloom filter</em>通常用于增加对抗性误报率的网络中，这可能会损害性能。由于冲突而增加的延迟可能会引发<em>Denial-of-Service attacks</em>(DoS)。</li></ul><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>对于一个分类器，分布密度$f(s(x))$在集合内和集合外的元素呈现不同的趋势。观察到，对于键，$f(s(x)|x \in S)$随着$s(x)$的增加呈现上升趋势，而$f(s(x)|x \notin S)$呈现相反的趋势。为了减少整体FPR，$f(s(x)|x \notin S)$高的组需要更低的FPRs。因此，如果用不同的方式调整哈希函数的数量，相应的组需要更多的哈希函数，而对于有几个非键的组允许更高的FPRs。</li></ul><h2 id="Adaptive-Learned-Bloom-Filter-Ada-BF"><a href="#Adaptive-Learned-Bloom-Filter-Ada-BF" class="headerlink" title="Adaptive Learned Bloom Filter (Ada-BF)"></a>Adaptive Learned Bloom Filter (Ada-BF)</h2><ul><li><p>上一节中LBF的公式，LBF实际上将$x$分成了两组。当$s(x)≥τ$时，$x$将被直接识别为集合中的元素，而不需要使用<em>Bloom filter</em>测试。换句话说，它先使用零哈希函数来标识资格。否则，将使用$K$哈希函数测试，则通过$s(x)≥τ$判断从$0$哈希函数到$K$哈希函数的条件。Ada-BF根据$s(x)$将$x$分为$g$个组，对于组$j$，采用$K_j$个哈希函数来判断它的资格。Ada-BF的结构如Figure 1(b)所示。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:100%;"></p></li><li><p>Ada-BF将$s(x)$分为$g$组，其中$x\in \text{Group}\ j$，$s(x)\in[\tau_{j-1};\tau_j), j = 1,2,···,g$，设$0 = τ_0 &lt; τ_1 &lt;···&lt; τ_{g−1} &lt; τ_g = 1$，来自组$j$的关键字使用$K_j$个独立的哈希函数插入到<em>Bloom filter</em>中。对于$j$组，FPR的期望值可表示为</p><script type="math/tex; mode=display">\mathbb{E}\left(\mathrm{FPR}_{j}\right)=\left(1-\left(1-\frac{1}{R}\right)^{\sum_{t=1}^{g} n_{t} K_{t}}\right)^{K_{j}}=\alpha^{K_{j}}</script><p>其中$n_{t}=\sum_{t=1}^{n} I\left(\tau_{t-1} \leq s\left(x_{i} \mid x_{i} \in S\right)&lt;\tau_{t}\right)$落在$\text{group}\ t$的关键字数。为了避免比特数组的过载，我们只在键数$n_j$较多的组中增加$K_j$，而在键数$n_j$较少的组中减少$K_j$。很明显，Ada-BF对LBF进行了推广。当Ada-BF只通过将查询分成两组时$K_1 = K, K_2 = 0， τ_1 = τ$， Ada-BF降为LBF。</p><p>值得注意的是，随着$s(x)$的增加，$f(s(x)|x\in S)$与$f(s(x)|x\notin S)$的趋势相反(Figure 2)。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:100%;"></p></li></ul><h3 id="Simplifying-the-Hyper-Parameters"><a href="#Simplifying-the-Hyper-Parameters" class="headerlink" title="Simplifying the Hyper-Parameters"></a>Simplifying the Hyper-Parameters</h3><ul><li><p>为了实现Ada-BF，需要确定$2g-1$个超参数，包括每组的哈希函数数量$K_j$和分组的评分阈值$τ_j (τ_0 = 0， τ_g = 1)$。使用这些超参数，对于Ada-BF，总体FPR的期望值可以表示为:</p><script type="math/tex; mode=display">\mathbb{E}(\mathrm{FPR})=\sum_{j=1}^{g} p_{j} \mathbb{E}\left(\mathrm{FPR}_{j}\right)=\sum_{j=1}^{g} p_{j} \alpha^{K_{j}}</script><p>其中$p_{j}=\operatorname{Pr}\left(\tau_{j-1} \leq s\left(x_{i} \mid x_{i} \notin S\right)&lt;\tau_{j}\right)$，$<br>p_{j}$可以用$\hat{p}_{j}=\frac{1}{m} \sum_{i=1}^{m} I\left(\tau_{j-1} \leq s\left(x_{i} \mid x_{i} \notin S\right)&lt;\tau_{j}\right)=\frac{m_{j}}{m}$表示($m$为训练数据中非键的数量，$m_j$为$j$组中非键的数量)。由于$\sum_{j=1}^{g} m_{j} \alpha^{K_{j}}=O\left(\max _{j}\left(m_{j} \alpha^{K_{j}}\right)\right)$，可以考虑使用$m_{j} \alpha^{K_{j}}$来近似。而$\alpha^{K_{j}}$随着$K_j$的增大呈指数级下降，为了保持$m_j\alpha^{K_{j}}$在不同组中的稳定，我们需要$m_j$随着$K_j$呈指数级增长。此外，由于$f(s(x)|x\notin S)$在大多数情况下随着$s(x)$变小而增大，所以对于较小的$s(x)$， $K_j$也应该变大，当$j$减少时，我们应该线性增加$K_j$，让$m_j$指数增长。</p></li><li><p>根据以上观点，设置$\frac{p_j}{p_{j+1}}=c$和$K_j-K_{j+1}=1$，其中$j=1,2,\cdots,g-1$，因为$s(x|x\notin S)$的真实密度是未知的，用$\hat{\frac{p_j}{p_{j+1}}}=\frac{m_j}{m_{j+1}}=c$来估计$\frac{p_j}{p_{j+1}}$，该策略确保了$\hat{p}_j$与$K_j$的指数级增长。现在只有三个超参数，$c,K_{min},K_{max}(K_{max}=K_1)$。默认情况下设置$K_{min} = K_{g} = 0$，等价于将$g$组中的所有项目标识为键。</p></li></ul><h3 id="Analysis-of-Adaptive-Learned-Bloom-Filter"><a href="#Analysis-of-Adaptive-Learned-Bloom-Filter" class="headerlink" title="Analysis of Adaptive Learned Bloom Filter"></a>Analysis of Adaptive Learned Bloom Filter</h3><ul><li><p>与LBF相比，Ada-BF充分利用密度分布$s(x)$，对不同区间的FPR进行优化，而且Ada-BF可以在不增加内存使用的情况下降低LBF的FPR。</p><p>当$p_j/p_{j+1}=c_j\geq c &gt; 1$，$K_j-K_{j+1}= 1$时，预期的FPR如下</p></li></ul><script type="math/tex; mode=display">  \mathbb{E}(\mathrm{FPR})=\sum_{j=1}^{g} p_{j} \alpha^{K_{j}}=\frac{\sum_{j=1}^{g} c^{g-j} \alpha^{K_{j}}}{\sum_{j=1}^{g} c^{g-j}} \leq\left\{\begin{array}{ll}  \frac{(1-c)\left(1-(c \alpha)^{g}\right)}{\left(\frac{1}{\alpha}-c\right)\left(\alpha^{g}-(c \alpha)^{g}\right)} \alpha^{K_{\max }}, & c \alpha \neq 1 \\  \frac{1-c}{1-c^{g}} \cdot g, & c \alpha=1  \end{array}\right.</script><p>  其中$K_{max} = K_1$。为了方便分析，设$cα &gt; 1$。假设$g$组的数目是固定的，提高$c$就可以满足这以上条件，而$α$会随着$c$的增大而增大。为了比较，需要LBF的$τ$等于Ada-BF的$\tau_{g-1}$，在这种情况下，分数高于$τ$的查询会被机器学习模型直接判断为键。比较整体的FPR便只需要比较得分低于$τ$的查询的FPR。</p><ul><li><p><strong>Theorem 1</strong>：对于Ada-BF，对于所有的$j\in[g-1],$给定$\frac{p_j}{p_{j+1}}\geq c &gt;1$，如果存在$λ &gt; 0$使$cα≥1+λ$成立，并且对于所有的$j\in[g-1],$$n_{j+1}−n_j &gt; 0$($n_j$是$j$组的键数)。当$g$足够大且$g≤\lfloor2K\rfloor$时(K是LBF哈希函数的个数)，Ada-BF的FPR小于LBF。</p></li><li><p>Theorem 1要求$n_j$的键数不断增加，而$p_j$随着$j$呈指数级下降。如图2所示，在真实数据集上，随着分数的增加，$f(s(x)|x\notin S)$下降得非常快，而$f(s(x)|x \in S)$增加，能够满足定理的条件。</p></li></ul><h2 id="Disjoint-Adaptive-Learned-Bloom-Filter-Disjoint-Ada-BF"><a href="#Disjoint-Adaptive-Learned-Bloom-Filter-Disjoint-Ada-BF" class="headerlink" title="Disjoint Adaptive Learned Bloom Filter (Disjoint Ada-BF)"></a>Disjoint Adaptive Learned Bloom Filter (Disjoint Ada-BF)</h2><ul><li><p>Ada-BF根据键的分数将键分成$g$组，并使用不同数量的哈希函数将键散列到同一个<em>Bloom Filter</em>中。基于类似的想法，disjoint Ada-BF也将键分成$g$组，但是将不同组的键散列到独立的<em>Bloom Filter</em>中。disjoint Ada-BF的结构如图1(c)所示。</p><p>假设<em>Bloom Filter</em>的总预算为$R$位，键被分成$g$组。因此，来自组$j$的键被插入到长度为$R_j (R = \sum_{j=1}^g R_j)$的<em>Bloom filter</em>。在查找阶段，需要确定查询所属的组并检查其在对应Bloom Filter中的成员关系。</p></li></ul><h3 id="Simplifying-the-Hyper-Parameters-1"><a href="#Simplifying-the-Hyper-Parameters-1" class="headerlink" title="Simplifying the Hyper-Parameters"></a>Simplifying the Hyper-Parameters</h3><ul><li>与Ada-BF类似，disjoint Ada-BF也有需要设置的超参数，例如组分割的分数阈值$τ_j$和<em>Bloom Filter</em>的长度$R_j$。阈值$τ_j$的确定与上一节类似。为了找到优化整体FPR的$R_j$，我们再次引用上一节的思想，即不同组的<em>false postivives</em>预期应该是相似的。对于具有$Rj$位的<em>Bloom filter</em>，最优哈希函数数量可以近似为$K_j=\frac{R_j}{n_j}\text{log(2)}$，其中$n_j$是组$j$中的键数。对应的最优FPR的期望为$\mathbb{E}\left(\mathrm{FPR}_{j}\right)=\mu^{R_{j} / n_{j}}(\mu \approx 0.618)$，因此，为了使不同组的<em>false postivives</em>预期相似，$R_j$需要满足<script type="math/tex; mode=display">m_{j} \cdot \mu^{\frac{R_{j}}{n_{j}}}=m_{1} \cdot \mu^{\frac{R_{1}}{n_{1}}} \Longleftrightarrow \frac{R_{j}}{n_{j}}-\frac{R_{1}}{n_{1}}=\frac{(j-1) \log (c)}{\log (\mu)}</script>在已知阈值$τ_j$的前提下，$n_j$是已知的，并且桶的总预算$R$是已知的，因此可以求解$R_j$。</li></ul><h3 id="Analysis-of-Disjoint-Adaptive-Learned-Bloom-Filter"><a href="#Analysis-of-Disjoint-Adaptive-Learned-Bloom-Filter" class="headerlink" title="Analysis of Disjoint Adaptive Learned Bloom Filter"></a>Analysis of Disjoint Adaptive Learned Bloom Filter</h3><ul><li>Disjoint Ada-BF使用一组较短的<em>Bloom Filter</em>来存储键的哈希输出。核心思想与Ada-BF相同，都是通过减少组的FPR来降低整体的FPR。Disjoint Ada-BF为每组分配<em>Bloom Filter</em>，以实现更小的FPR。在下面的定理中，证明在达到LBF的最优预期FPR时，Disjoint Ada-BF消耗更少的桶。</li><li><strong>Theorem 2：</strong>对于所有的$j\in[g-1]$($n_j$是组$j$的键数)，如果$\frac{p_j}{p_{j+1}}=c&gt;1$和$n_{j+1}−n_j &gt; 0$，为了实现LBF的最优FPR，当$g$较大时，Disjoint Ada-BF消耗的桶数比LBF少。</li></ul><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><ul><li><p>论文测试现有几种Bloom filter算法的性能:1)standard Bloom filter，2)learned Bloom filter，3)sandwiched learned Bloom filter  ，4)adaptive learned Bloom filter  ，5)disjoint adaptive learned Bloom filter。使用两个具有不同关联任务的数据集，即恶意url检测和病毒扫描，通过它们的FPRs和相应的内存使用来衡量性能。作者在<a href="https://github.com/DAIZHENWEI/Ada-BF">https://github.com/DAIZHENWEI/Ada-BF</a> 上开源了自己的代码与数据集。</p></li><li><p>url数据集一共有三列（url，label，score），分别为需要检测的url，标签与预先训练的随机森林模型对应得分$\text{score}(x)$(采用“sklearn.ensemble.RandomForestClassifier“)。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:50%;"></p><p>病毒扫描数据集一共有三列（label，score，MD5），分别为标签、预先训练的随机森林模型对应得分$\text{score}(x)$(采用“sklearn.ensemble.RandomForestClassifier“)与文件的MD5签名。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig4.png" style="zoom:50%;"></p></li><li><p>实验的相关设置可参考原论文，最终结果如下。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig5.png" style="zoom:100%;"></p></li></ul><h2 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h2><p>以下为论文代码实现的相关说明与注释，包括Bloom_filter、learned_Bloom_filter、Ada-BF、disjoint_Ada-BF四种。</p><h3 id="Bloom-filter"><a href="#Bloom-filter" class="headerlink" title="Bloom_filter"></a>Bloom_filter</h3><ul><li><p>首先采用<code>sklearn.utils.murmurhash3_32</code>函数作为<em>Bloom filter</em>中的哈希函数，根据key值得到32位的哈希值，对<em>Bloom filter</em>的大小$m$取余则得到$[0,m-1]$范围的值作为下标索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hashfunc</span>(<span class="hljs-params">m</span>):</span><br>    ss = randint(<span class="hljs-number">1</span>, <span class="hljs-number">99999999</span>)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hash_m</span>(<span class="hljs-params">x</span>):</span><br>        <span class="hljs-keyword">return</span> murmurhash3_32(x,seed=ss)%m<br>    <span class="hljs-keyword">return</span> hash_m<br></code></pre></td></tr></table></figure></li><li><p>Standard Bloom filter的类初始化方式如下，根据推导公式$k=ln\ 2\ \cdot\ (m/n)$得到最优$k$值，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BloomFilter</span>():</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, n, hash_len</span>):</span><br>        self.n = n<br>        self.hash_len = <span class="hljs-built_in">int</span>(hash_len)<br>        <span class="hljs-keyword">if</span> (self.hash_len == <span class="hljs-number">0</span>):<br>            <span class="hljs-keyword">raise</span> SyntaxError(<span class="hljs-string">&#x27;The hash table is empty&#x27;</span>)<br>        <span class="hljs-comment"># 根据推导公式得到最优k值</span><br>        <span class="hljs-keyword">if</span> (self.n &gt; <span class="hljs-number">0</span>) &amp; (self.hash_len &gt; <span class="hljs-number">0</span>):<br>            self.k = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">int</span>(self.hash_len/n*<span class="hljs-number">0.6931472</span>))<br>        <span class="hljs-keyword">elif</span> (self.n==<span class="hljs-number">0</span>):<br>            self.k = <span class="hljs-number">1</span><br>        <span class="hljs-comment"># 创建k个哈希函数</span><br>        self.h = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>            self.h.append(hashfunc(self.hash_len))<br>        <span class="hljs-comment"># 初始化“位数组”</span><br>        self.table = np.zeros(self.hash_len, dtype=<span class="hljs-built_in">int</span>)<br></code></pre></td></tr></table></figure><p>插入时进行$k$次哈希映射，将位数组中对应位置$1$，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">insert</span>(<span class="hljs-params">self, key</span>):</span><br>    <span class="hljs-keyword">if</span> self.hash_len == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">raise</span> SyntaxError(<span class="hljs-string">&#x27;cannot insert to an empty hash table&#x27;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> key:<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>            t = self.h[j](i)<br>            self.table[t] = <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>检测时，同样进行$k$次哈希映射，判断对应位是否都为$1$，返回结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test</span>(<span class="hljs-params">self, keys, single_key = <span class="hljs-literal">True</span></span>):</span><br>    <span class="hljs-keyword">if</span> single_key:<br>        test_result = <span class="hljs-number">0</span><br>        match = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> self.hash_len &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>                t = self.h[j](keys)<br>                match += <span class="hljs-number">1</span> * (self.table[t] == <span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">if</span> match == self.k:<br>                test_result = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        test_result = np.zeros(<span class="hljs-built_in">len</span>(keys))<br>        ss=<span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> self.hash_len &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> keys:<br>                match = <span class="hljs-number">0</span><br>                <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>                    t = self.h[j](key)<br>                    match += <span class="hljs-number">1</span>*(self.table[t] == <span class="hljs-number">1</span>)<br>                <span class="hljs-keyword">if</span> match == self.k:<br>                    test_result[ss] = <span class="hljs-number">1</span><br>                ss += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> test_result<br></code></pre></td></tr></table></figure></li><li><p>使用  <code>python Bloom_filter.py --data_path ./Datasets/URL_data.csv --size_of_BF 200000</code>运行代码，url任务对应main函数如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--data_path&#x27;</span>, action=<span class="hljs-string">&quot;store&quot;</span>, dest=<span class="hljs-string">&quot;data_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>,<br>                        <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;path of the dataset&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--size_of_BF&#x27;</span>, action=<span class="hljs-string">&quot;store&quot;</span>, dest=<span class="hljs-string">&quot;R_sum&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, required=<span class="hljs-literal">True</span>,<br>                        <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;size of the BF&quot;</span>)<br>    <br>    <span class="hljs-comment"># 数据集路径与位数组大小</span><br>    results = parser.parse_args()<br>    DATA_PATH = results.data_path<br>    R_sum = results.R_sum<br><br>    data = pd.read_csv(DATA_PATH)<br><br>    negative_sample = data.loc[(data[<span class="hljs-string">&#x27;label&#x27;</span>] == -<span class="hljs-number">1</span>)]<br>    positive_sample = data.loc[(data[<span class="hljs-string">&#x27;label&#x27;</span>] == <span class="hljs-number">1</span>)]<br><br>    <span class="hljs-comment"># 对所有正样例进行插入</span><br>    query = positive_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>    n = <span class="hljs-built_in">len</span>(query)<br>    bloom_filter = BloomFilter(n, R_sum)<br>    bloom_filter.insert(query)<br>    query_negative = negative_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>    <br>    <span class="hljs-comment"># 对所有负样例进行检测，得到结果</span><br>    n1 = bloom_filter.test(query_negative, single_key=<span class="hljs-literal">False</span>)<br>    print(<span class="hljs-string">&#x27;False positive items: &#x27;</span>, <span class="hljs-built_in">sum</span>(n1))<br>    print(<span class="hljs-string">&#x27;FPR:&#x27;</span>, <span class="hljs-built_in">sum</span>(n1)/<span class="hljs-built_in">len</span>(negative_sample))<br></code></pre></td></tr></table></figure></li></ul><h3 id="learned-Bloom-filter"><a href="#learned-Bloom-filter" class="headerlink" title="learned_Bloom_filter"></a>learned_Bloom_filter</h3><ul><li><p>由于数据中已经有了预先训练的随机森林模型对应得分，因此需要确定最优的$\tau$，以url任务为例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># train_negative为30%抽样得到的负样例</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Find_Optimal_Parameters</span>(<span class="hljs-params">max_thres, min_thres, R_sum, train_negative, positive_sample</span>):</span><br>    FP_opt = train_negative.shape[<span class="hljs-number">0</span>]<br>    <br>    <span class="hljs-comment"># 从最小值到最大值遍历计算确定最优值</span><br>    <span class="hljs-keyword">for</span> threshold <span class="hljs-keyword">in</span> np.arange(min_thres, max_thres+<span class="hljs-number">10</span>**(-<span class="hljs-number">6</span>), <span class="hljs-number">0.01</span>):<br>        <span class="hljs-comment"># 根据阈值得到插入Bloomfilter的样例</span><br>        query = positive_sample.loc[(positive_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        n = <span class="hljs-built_in">len</span>(query)<br>        bloom_filter = BloomFilter(n, R_sum)<br>        bloom_filter.insert(query)<br>        <span class="hljs-comment"># 分类器分类错误的样例</span><br>        ML_positive = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &gt; threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        <span class="hljs-comment"># Bloomfilter检测错误的样例</span><br>        bloom_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        BF_positive = bloom_filter.test(bloom_negative, single_key=<span class="hljs-literal">False</span>)<br>        <span class="hljs-comment"># False Positive</span><br>        FP_items = <span class="hljs-built_in">sum</span>(BF_positive) + <span class="hljs-built_in">len</span>(ML_positive)<br>        print(<span class="hljs-string">&#x27;Threshold: %f, False positive items: %d&#x27;</span> %(<span class="hljs-built_in">round</span>(threshold, <span class="hljs-number">2</span>), FP_items))<br>        <span class="hljs-comment"># 保存最优的阈值与对应Bloomfilter</span><br>        <span class="hljs-keyword">if</span> FP_opt &gt; FP_items:<br>            FP_opt = FP_items<br>            thres_opt = threshold<br>            bloom_filter_opt = bloom_filter<br>    <span class="hljs-keyword">return</span> bloom_filter_opt, thres_opt<br></code></pre></td></tr></table></figure><p>获得最优的$\tau$后，在整个负样例上进行检测，得到最终的FPR。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-string">&#x27;&#x27;&#x27;Stage 1: Find the hyper-parameters (spare 30% samples to find the parameters)&#x27;&#x27;&#x27;</span><br>    bloom_filter_opt, thres_opt = Find_Optimal_Parameters(max_thres, min_thres, R_sum, train_negative, positive_sample)<br><br>    <span class="hljs-string">&#x27;&#x27;&#x27;Stage 2: Run LBF on all the samples&#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment">### Test queries</span><br>    ML_positive = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &gt; thres_opt), <span class="hljs-string">&#x27;url&#x27;</span>]<br>    bloom_negative = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thres_opt), <span class="hljs-string">&#x27;url&#x27;</span>]<br>    score_negative = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thres_opt), <span class="hljs-string">&#x27;score&#x27;</span>]<br>    BF_positive = bloom_filter_opt.test(bloom_negative, single_key = <span class="hljs-literal">False</span>)<br>    FP_items = <span class="hljs-built_in">sum</span>(BF_positive) + <span class="hljs-built_in">len</span>(ML_positive)<br>    FPR = FP_items/<span class="hljs-built_in">len</span>(negative_sample)<br>    print(<span class="hljs-string">&#x27;False positive items: &#123;&#125;; FPR: &#123;&#125;; Size of quries: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(FP_items, FPR, <span class="hljs-built_in">len</span>(negative_sample)))<br></code></pre></td></tr></table></figure></li></ul><h3 id="Ada-BF"><a href="#Ada-BF" class="headerlink" title="Ada-BF"></a>Ada-BF</h3><ul><li><p>Ada-BF中Bloom_filter与原始Bloom_filter的差别在于哈希函数的个数，由于$K_j-K_{j+1}=1$，且$K_g=0$，则$K_{max}$与划分的组数有关，因此Ada-BF需要根据组数进行哈希函数数量的修改，在检测时需要根据$k$值进行$k$次映射。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Ada_BloomFilter</span>():</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, n, hash_len, k_max</span>):</span><br>        self.n = n<br>        self.hash_len = <span class="hljs-built_in">int</span>(hash_len)<br>        self.h = []<br>        <span class="hljs-comment"># 创建k_max个哈希函数</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k_max)):<br>            self.h.append(hashfunc(self.hash_len))<br>        self.table = np.zeros(self.hash_len, dtype=<span class="hljs-built_in">int</span>)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">insert</span>(<span class="hljs-params">self, key, k</span>):</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k)):<br>            t = self.h[j](key)<br>            self.table[t] = <span class="hljs-number">1</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test</span>(<span class="hljs-params">self, key, k</span>):</span><br>        test_result = <span class="hljs-number">0</span><br>        match = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k)):<br>            t = self.h[j](key)<br>            match += <span class="hljs-number">1</span>*(self.table[t] == <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> match == k:<br>            test_result = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> test_result<br></code></pre></td></tr></table></figure><p>根据上面的分析，需要确定的最优参数有组数$g$与$\hat{\frac{p_j}{p_{j+1}}}=\frac{m_j}{m_{j+1}}=c$，同样采用从最小值到最大值遍历并保存最优值的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Find_Optimal_Parameters</span>(<span class="hljs-params">c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample</span>):</span><br>    <span class="hljs-comment"># c_min到c_max寻找最优值</span><br>    c_set = np.arange(c_min, c_max+<span class="hljs-number">10</span>**(-<span class="hljs-number">6</span>), <span class="hljs-number">0.1</span>)<br>    FP_opt = train_negative.shape[<span class="hljs-number">0</span>]<br><br>    k_min = <span class="hljs-number">0</span><br>    <span class="hljs-comment"># k_max 与组数有关</span><br>    <span class="hljs-keyword">for</span> k_max <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_group_min, num_group_max+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> c_set:<br>            <span class="hljs-comment"># tau = sum([c**0, c**1,...]) 则各划分区间的最小单位</span><br>            tau = <span class="hljs-built_in">sum</span>(c ** np.arange(<span class="hljs-number">0</span>, k_max - k_min + <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>            n = positive_sample.shape[<span class="hljs-number">0</span>]<br>            hash_len = R_sum<br>            bloom_filter = Ada_BloomFilter(n, hash_len, k_max)<br>            thresholds = np.zeros(k_max - k_min + <span class="hljs-number">1</span>)<br>            thresholds[-<span class="hljs-number">1</span>] = <span class="hljs-number">1.1</span><br>            <span class="hljs-comment"># 抽样后的负样例总数</span><br>            num_negative = <span class="hljs-built_in">sum</span>(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thresholds[-<span class="hljs-number">1</span>])<br>            <span class="hljs-comment"># 按比例分成碎片，一共tau个碎片</span><br>            num_piece = <span class="hljs-built_in">int</span>(num_negative / tau) + <span class="hljs-number">1</span><br>            <br>            score = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thresholds[-<span class="hljs-number">1</span>]), <span class="hljs-string">&#x27;score&#x27;</span>]<br>            score = np.sort(score)<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k_min, k_max):<br>                i = k - k_min<br>                score_1 = score[score &lt; thresholds[-(i + <span class="hljs-number">1</span>)]]<br>                <span class="hljs-comment"># 从后往前计算区间划分阈值 根据m_j/m_&#123;j+1&#125; = c并且剩下样例足够划分</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>(num_piece * c ** i) &lt; <span class="hljs-built_in">len</span>(score_1):<br>                    thresholds[-(i + <span class="hljs-number">2</span>)] = score_1[-<span class="hljs-built_in">int</span>(num_piece * c ** i)]<br><br>            query = positive_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>            score = positive_sample[<span class="hljs-string">&#x27;score&#x27;</span>]<br>            <br>            <span class="hljs-comment"># 插入数据</span><br>            <span class="hljs-keyword">for</span> score_s, query_s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(score, query):<br>                ix = <span class="hljs-built_in">min</span>(np.where(score_s &lt; thresholds)[<span class="hljs-number">0</span>])<br>                k = k_max - ix<br>                bloom_filter.insert(query_s, k)<br>            <span class="hljs-comment"># 进行FPR估计</span><br>            ML_positive = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &gt;= thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;url&#x27;</span>]<br>            query_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;url&#x27;</span>]<br>            score_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;score&#x27;</span>]<br><br>            <span class="hljs-comment"># 进行检测</span><br>            test_result = np.zeros(<span class="hljs-built_in">len</span>(query_negative))<br>            ss = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> score_s, query_s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(score_negative, query_negative):<br>                ix = <span class="hljs-built_in">min</span>(np.where(score_s &lt; thresholds)[<span class="hljs-number">0</span>])<br>                <span class="hljs-comment"># thres = thresholds[ix]</span><br>                k = k_max - ix<br>                test_result[ss] = bloom_filter.test(query_s, k)<br>                ss += <span class="hljs-number">1</span><br>            FP_items = <span class="hljs-built_in">sum</span>(test_result) + <span class="hljs-built_in">len</span>(ML_positive)<br>            print(<span class="hljs-string">&#x27;False positive items: %d, Number of groups: %d, c = %f&#x27;</span> %(FP_items, k_max, <span class="hljs-built_in">round</span>(c, <span class="hljs-number">2</span>)))<br>            <span class="hljs-comment"># 保存最优结果</span><br>            <span class="hljs-keyword">if</span> FP_opt &gt; FP_items:<br>                FP_opt = FP_items<br>                bloom_filter_opt = bloom_filter<br>                thresholds_opt = thresholds<br>                k_max_opt = k_max<br><br>    <span class="hljs-comment"># print(&#x27;Optimal FPs: %f, Optimal c: %f, Optimal num_group: %d&#x27; % (FP_opt, c_opt, num_group_opt))</span><br>    <span class="hljs-keyword">return</span> bloom_filter_opt, thresholds_opt, k_max_opt<br></code></pre></td></tr></table></figure><p>得到最优参数后在整个测试集上做检测，得到最终FPR。</p></li></ul><h3 id="disjoint-Ada-BF"><a href="#disjoint-Ada-BF" class="headerlink" title="disjoint_Ada-BF"></a>disjoint_Ada-BF</h3><ul><li><p>与Ada-BF不同的是，disjoint_Ada-BF需要计算每个组的<em>Bloom filter</em>的位数组大小$R_j$，计算使用的推导公式为</p><script type="math/tex; mode=display">\frac{R_{j}}{n_{j}}-\frac{R_{1}}{n_{1}}=\frac{(j-1) \log (c)}{\log (\mu)}</script><p>由于在划分阈值的时候，各组区间的非键数按$c$指数增长，因此可以用以计算$c^{j-1}$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">R_size</span>(<span class="hljs-params">count_key, count_nonkey, R0</span>):</span><br>    R = [<span class="hljs-number">0</span>]*<span class="hljs-built_in">len</span>(count_key)<br>    R[<span class="hljs-number">0</span>] = <span class="hljs-built_in">max</span>(R0,<span class="hljs-number">1</span>)<br>    <span class="hljs-comment">#　根据推导公式计算R</span><br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(count_key)):<br>        R[k] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">int</span>(count_key[k] * (np.log(count_nonkey[<span class="hljs-number">0</span>]/count_nonkey[k])/np.log(<span class="hljs-number">0.618</span>) + R[<span class="hljs-number">0</span>]/count_key[<span class="hljs-number">0</span>])), <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> R<br></code></pre></td></tr></table></figure><p>根据以上函数，调节$R_0$使得最终得到的$R$数组满足所给定内存，则退出调节。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">### Search the Bloom filters&#x27; size</span><br>R = np.zeros(num_group_1 - <span class="hljs-number">1</span>)<br>R[:] = <span class="hljs-number">0.5</span> * R_sum<br>non_empty_ix = <span class="hljs-built_in">min</span>(np.where(count_key &gt; <span class="hljs-number">0</span>)[<span class="hljs-number">0</span>])<br><span class="hljs-keyword">if</span> non_empty_ix &gt; <span class="hljs-number">0</span>:<br>    R[<span class="hljs-number">0</span>:non_empty_ix] = <span class="hljs-number">0</span><br>kk = <span class="hljs-number">1</span><br><span class="hljs-comment"># 通过调节R_0的大小,使得根据推导公式分配的R满足要求</span><br><span class="hljs-keyword">while</span> <span class="hljs-built_in">abs</span>(<span class="hljs-built_in">sum</span>(R) - R_sum) &gt; <span class="hljs-number">200</span>:<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">sum</span>(R) &gt; R_sum):<br>        R[non_empty_ix] = R[non_empty_ix] - <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        R[non_empty_ix] = R[non_empty_ix] + <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>)<br>    R[non_empty_ix:] = R_size(count_key[non_empty_ix:-<span class="hljs-number">1</span>], count_nonkey[non_empty_ix:-<span class="hljs-number">1</span>], R[non_empty_ix])<br>    <span class="hljs-comment"># 调节大小可以忽略时结束</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>) == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">break</span><br>    kk += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li><li><p>为每个组创建一个<em>Bloom filter</em>，其他操作类似。</p></li></ul><h2 id="Preventing-Misinformation-Spread-over-Social-Media-in-Real-Time"><a href="#Preventing-Misinformation-Spread-over-Social-Media-in-Real-Time" class="headerlink" title="Preventing Misinformation Spread over Social Media in Real-Time"></a>Preventing Misinformation Spread over Social Media in Real-Time</h2><ul><li><p>由于互联网的发展，像Twitter这样的社交媒体几秒内便可在全球范围内传播信息。每天大约有5亿条推文，也就是每秒产生6000 - 10000条推文。Twitter最近报道了一项对其全球分布式索引系统(Twia)的重大改革，该系统使一条推文在一秒钟内就能被全世界看到，而误导内容(或错误信息)也因此会以极快速度在网络上产生并传播。</p></li><li><p>如果已经确定了一个错误信息的来源及其内容，为了防止其在网络快速传播，过滤这些错误信息的系统必须满足几个关键的条件。首先，一旦确定了错误信息的来源及其内容，应该在毫秒内告知全球各地的所有服务器错误信息的相关内容，同时需要保证最小的通讯开销。其次，给定大量生成的信息，需要在没有任何计算开销的情况下正确地清除信息。由于前所未有的数据生成速度，在清除信息的过程中任何计算开销都将导致系统崩溃。这是<em>Bloom filter</em>的经典用例，我们不希望错误信息通过过滤器，并且不会产生任何计算开销。否则，数据生成速率将超过我们的过滤速率。</p></li><li><p><strong>在理想情况下，使用<em>Bloom filter</em>可以压缩错误信息的数据库。每在数据库中中增加一个错误信息，只需要传输几个比特。</strong>只要FPR足够低，系统就不会崩溃。总的来说，FPR非常重要，我们希望每次更新的通信(内存)尽可能少。由于机器学习在自然语言处理方面取得显著的成功，因此有了一个更高性能的LBF，但仅靠机器学习无法保证应用程序所需的零<em>false negative</em>。</p></li><li><p>在<em>Preventing Misinformation Spread over Social Media in Real-Time</em>实验在<a href="https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset?select=Fake.csv">假新闻数据集</a>上进行，该数据集包括23481条假新闻和21417条真新闻，采用的机器学习模型利用<strong>TFIDF</strong>特征训练<strong>朴素贝叶斯分类模型</strong>，并测试不同<em>Learned Bloom filter</em>的FPR。与之前的实验结果相似，Ada-BF和disjoint Ada-BF相比于BF和LBF有明显的优势。在相同的内存预算下，BF和LBF使FPRs降低了70%以上。而Ada-BF和disjoint Ada-BF只需要LBF一半的空间，有效地将通信开销减少了$1 / 2$。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig6.png" style="zoom:44%;"></p></li><li><p>在进一步实验中，除了精确的成员测试外，查询到的新闻是否与数据库中的假新闻高度相似也很重要。然而，<strong>目前的Bloom filter不能处理这个任务</strong>。Kirsch和Mitzenmacher提出了<strong><em>Distance-sensitive bloom filters</em></strong>，这可能是一个可能的解决方案，<em>Learned Bloom filter</em>可以很容易地扩展到<em>Distance-sensitive bloom filters</em>。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Bloom Filter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Network Applications of Bloom Filters：A Survey》笔记</title>
    <link href="/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Bloom-Filter"><a href="#Bloom-Filter" class="headerlink" title="Bloom Filter"></a>Bloom Filter</h1><ul><li><strong>Bloom filter</strong>是一种空间效率高的随机数据结构，采用位数组表示一个集合以提供成员查询。<em>Bllom filter</em>是容许错误判断的，即把不属于这个集合的元素误判断属于这一集合，这样的错误称作<em>false positives</em>。因此<em>Bloom filter</em>不适用于零错误的应用，它通过极低的错误率节省了大量的空间。</li><li><strong>The Bloom filter principle:</strong> <em>Wherever a list or set is used, and space is at a premium, consider using a Bloom filter if the effect of false positives can be mitigated.</em> (当空间消耗昂贵而允许false positives时，考虑使用布隆过滤器。)</li></ul><h2 id="Standard-Bloom-Filter"><a href="#Standard-Bloom-Filter" class="headerlink" title="Standard Bloom Filter"></a>Standard Bloom Filter</h2><ul><li><p><em>Bllom Filter</em>采用一个$m$位的位数组来表示包含$n$个元素的集合$S=\{x_1,x_2,\dots,x_n\}$，位数组全初始化为$0$。<em>Bllom Filter</em>使用$k$个相互独立的哈希函数，将集合中的每个元素映射到$\{1,\dots,m\}$的范围中。对于集合中的每一个元素$x\in S$，第$i$个$（1\leq i \leq k）$哈希函数映射的位$h_i(x)$被设置为$1$（不进行重复设置）。</p></li><li><p>在判断$y$是否属于集合$S$时，如果所有$h_i(y)$$（1\leq i \leq k）$的位都已经设置为$1$，那么认为$y\in S$，否则$y \notin S$，因此存在将$y$误判为$S$中元素的情况。</p><p><img src="/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" alt></p></li><li><p><em>Bllom Filter</em>在判断一个元素是否属于它表示的集合时会有一定的错误率（<em>false positive rate</em>）。在很多应用中，只要<em>false positive</em>足够小，则可以接受这样的错误。假设$kn&lt;m$且各个哈希函数是完全随机的，则当$S$中的所有元素被哈希映射到<em>Bloom filter</em>后，某一特定位仍然为$0$的概率为</p><script type="math/tex; mode=display">p^{\prime}=\left(1-\frac{1}{m}\right)^{k n} \approx \mathrm{e}^{-k n / m}.</script><p>其中$1/m$表示任意一个哈希函数选中这一位的概率（前提是哈希函数是完全随机的），则$(1-1/m)$表示哈希一次没有选中这一位的概率。要把$S$完全映射到位数组中，需要做$kn$次哈希。令$p=e^{-kn/m}$，则$p$近似$p’$(在$O(1/m)$内)。</p><p>令$\rho$为位数组中$0$的比例，则$\mathbb{E}(\rho)=p’$。则错误率（<em>false positive rate</em>）为</p><script type="math/tex; mode=display">(1-\rho)^{k} \approx\left(1-p^{\prime}\right)^{k} \approx(1-p)^{k} .</script><p>得到</p><script type="math/tex; mode=display">f^{\prime}=\left(1-\left(1-\frac{1}{m}\right)^{k n}\right)^{k}=\left(1-p^{\prime}\right)^{k}, \\f=\left(1-\mathrm{e}^{-k n / m}\right)^{k}=(1-p)^{k}.</script><p>相比$p’$和$f’$，$p$和$f$更常见于分析中。</p></li><li><p><em>Bllom Filter</em>有另外一种表示方式，则将$m$位位数组平均分给$k$个hash函数，这样每个哈希函数的范围变为$m/k$位。在这种情况下，某一特定位为0的概率为</p><script type="math/tex; mode=display">\left(1-\frac{k}{m}\right)^{n} \approx \mathrm{e}^{-k n / m}.</script><p>近似上看，两者的表现类似。但在$k\geq1$时，</p><script type="math/tex; mode=display">\left(1-\frac{k}{m}\right)^{n} \leq\left(1-\frac{1}{m}\right)^{k n}</script><p>则精确得到第二种表示方式的<em>false positive rate</em>小于或等于第一种，并且将位按哈希函数划分能够实现并行化。</p></li><li><p>对于给定的$m$与$n$，根据<em>Bllom Filter</em>的原理可以知道：使用更多的哈希函数，那么在对一个不属于集合的元素进行查询时得到$0$的概率就大；而减少哈希函数的个数，则会提高位数组中$0$的比重，因此需要找到最合适的哈希函数值。如上得到$f=\exp \left(k \ln \left(1-\mathrm{e}^{-k n / m}\right)\right)$，设$g=k\ ln(1-e^{-kn/m})$，则寻找$f$的最小值等价于寻找$g$的最小值。求导可得</p><script type="math/tex; mode=display">\frac{\partial g}{\partial k}=\ln \left(1-\mathrm{e}^{-\frac{k n}{m}}\right)+\frac{k n}{m} \frac{\mathrm{e}^{-\frac{k n}{m}}}{1-\mathrm{e}^{-\frac{k n}{m}}}</script><p>解得零点$k=ln\ 2\ \cdot\ (m/n)$，该点也是一个全局最优值，对应解得$p=1/2$。在这种情况下，最小错误率$f=(1/2)^k\approx (0.6185)^{m/n}$。同样对于$f’$与$p’$，可以得到当$p’=1/2$时，$g’$取最小值。</p></li></ul><h3 id="A-Lower-Bound"><a href="#A-Lower-Bound" class="headerlink" title="A Lower Bound"></a>A Lower Bound</h3><ul><li>在不超过一定错误率的情况下，<em>Bloom Filter</em>需要设置足够大的$m$才能表示全集中任意$n$个元素的集合。假设全集中共有$u$个元素，允许的最大错误率为$\epsilon$，假设$X$为全集中任取$n$个元素的集合，$F(X)$是表示$X$的位数组。那么对于集合$X$中任意一个元素$x$，在$s = F(X)$中查询$x$都能得到肯定的结果，即$S$能够接受$x$。而<em>Bloom Filter</em>有错误率（<em>false positive rate</em>），对于一个确定的位数组来说，最多接受$n+\epsilon (u-n)$个元素。而一个确定的位数组可以表示$\left(\begin{array}{c}<br>n+\epsilon(u-n) \\<br>n<br>\end{array}\right)$个集合。$m$位的位数组共有$2^m$个不同的组合，全集中共有$\left(\begin{array}{c}<br>u \\<br>n<br>\end{array}\right)$个$n$元素的集合，因此要让$m$位的位数组表示所有$n$个元素的集合，有<script type="math/tex; mode=display">2^{m}\left(\begin{array}{c}n+\epsilon(u-n) \\n\end{array}\right) \geq\left(\begin{array}{l}u \\n\end{array}\right)</script>即<script type="math/tex; mode=display">m \geq \log _{2} \frac{\left(\begin{array}{l}u \\n\end{array}\right)}{\left(\begin{array}{c}n+\epsilon(u-n) \\n\end{array}\right)} \approx \log _{2} \frac{\left(\begin{array}{l}u \\n\end{array}\right)}{\left(\begin{array}{c}\epsilon u \\n\end{array}\right)} \geq \log _{2} \epsilon^{-n}=n \log _{2}(1 / \epsilon)</script>因此，$m$至少要大于$n \log _{2}(1 / \epsilon)$才能使错误率不大于给定的$\epsilon$。根据上节中$f=(1/2)^k=(1/2)^{ln\ 2\ \cdot\ (m/n)}$，令$f\leq \epsilon$得到<script type="math/tex; mode=display">m \geq n \frac{\log _{2}(1 / \epsilon)}{\ln 2}=n \log _{2} \mathrm{e} \cdot \log _{2}(1 / \epsilon).</script>这个结果是我们上面得到的最小值的$log_2e\approx1.44$倍，这说明在哈希函数的个数取到最优时，要让错误率不超过$\epsilon$，$m$至少需要取到最小值的$1.44$倍。</li></ul><h3 id="Hashing-vs-Bloom-Filters"><a href="#Hashing-vs-Bloom-Filters" class="headerlink" title="Hashing vs. Bloom Filters"></a>Hashing vs. Bloom Filters</h3><ul><li>哈希函数是常用的用以表示集合的方式，集合的每个元素都被映射到$\Theta(\text{log}\  n)$位上，然后再用一个哈希值的列表（已排序）表示集合。这种方法产生的错误率很小，如果集合中的每个元素用$2\ \text{log}_2\ n$位来表示，则两个特定的元素映射到相同哈希值的可能性为$1/n^2$，而不在集合中的元素与集合中的元素映射到相同哈希值的概率为$n/n^2=1/n$。</li><li><em>Bloom Filters</em>可以看作哈希的自然推广，它在错误率与采用的位数（空间消耗）中寻找均衡，只有一个哈希函数的<em>Bloom Filters</em>等价于普通的<em>Hashing</em>。<em>Bloom filters</em>产生一个恒定的<em>false positive rate</em>，当用以表示每个集合元素的比特数是恒定的。例如，当$m = 8n$时，<em>false positive rate</em>仅大于0.02。如果需要逐渐消失的错误率，每个元素至少需要采用$\Theta(\text{log}\  n)$位来表示，这也是<em>Bloom Filters</em>不受学术界关注的原因。相反，在实际应用中，为了保持每个元素的位数不变，一个常数错误可能是很有价值的。</li></ul><h3 id="Standard-Bloom-Filter-Tricks"><a href="#Standard-Bloom-Filter-Tricks" class="headerlink" title="　Standard Bloom Filter Tricks"></a>　Standard Bloom Filter Tricks</h3><ul><li><em>Bloom filter</em>的简单结构使得某些操作非常容易实现。假设有两个<em>Bloom filter</em>表示集合$S_1$和$S_2$，它们具有相同的比特数，并且使用相同的哈希函数。则一个表示$S_1,S_2$的并集的<em>Bloom filter</em>可以通过原有<em>Bloom filter</em>的两个位向量的<strong>OR</strong>得到。</li><li><p><em>Bloom filter</em>可以很容易地将大小减半，允许应用程序动态地缩小<em>Bloom filter</em>。假设<em>Bloom filter</em>的大小为$2$的幂。将<em>Bloom filter</em>的大小减半，可以将前半部分与后半部分做<strong>OR</strong>操作得到。当散列进行查找时，最高位可能被屏蔽。</p></li><li><p><em>Bloom filter</em>也可以用来近似两个集合之间的交集。假设有两个<em>Bloom filter</em>表示集合$S_1$和$S_2$，它们具有相同的比特数，并且使用相同的哈希函数。直观地说，这两个位向量的内积是它们相似性的度量。如果第$j$位是被两个<em>Bloom filter</em>同时设置的，那么它是被$S_1\cap S_2$中的元素设置，或者它同时被$S1−(S1∩S2)$中的某个元素和$S2−(S1∩S2)$中的另一个元素设置。则第$j$位被同时设置的概率为</p><script type="math/tex; mode=display">\begin{array}{l}\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1} \cap S_{2}\right|}\right) \\+\left(1-\frac{1}{m}\right)^{k\left|S_{1} \cap S_{2}\right|}\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1}-\left(S_{1} \cap S_{2}\right)\right|}\right)\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{2}-\left(S_{1} \cap S_{2}\right)\right|}\right)\end{array}</script><p>化简得到两个<em>Bloom filter</em>的期望内积和为</p><script type="math/tex; mode=display">m\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1}\right|}-\left(1-\frac{1}{m}\right)^{k\left|S_{2}\right|}+\left(1-\frac{1}{m}\right)^{k\left(\left|S_{1}\right|+\left|S_{2}\right|-\left|S_{1} \cap S_{2}\right|\right)}\right) .</script><p>因此，已知$|S_1|,|S_2|, k, m，$以及内积的大小，可以用上式计算$|S_1∩S_2|$。如果没有给出$|S_1|,|S_2|$，它们也可以通过计算$S_1$,$S_2$的<em>Bloom filter</em>中的$0$位数来估计，集合$S$的$0$位数在其期望$m(1 - 1/m)^{k|S|}$附近。设$Z_1,Z_2$分别为$S_1,S_2$<em>Bloom filter</em>中$0$的个数，$Z_{12}$为内积中$0$的个数，则得到</p><script type="math/tex; mode=display">\frac{1}{m}\left(1-\frac{1}{m}\right)^{-k\left|S_{1} \cap S_{2}\right|} \approx \frac{Z_{1}+Z_{2}-Z_{12}}{Z_{1} Z_{2}}</script></li></ul><h2 id="Counting-Bloom-Filters"><a href="#Counting-Bloom-Filters" class="headerlink" title="　Counting Bloom Filters"></a>　Counting Bloom Filters</h2><ul><li><p>假设我们有一个随时间变化的集合，会进行元素插入和删除操作。将元素插入Bloom过滤器只需将元素进行哈希$k$次，并将对应位设为$1$。但不能通过逆过程来执行删除操作，如果我们对要删除的元素进行散列，并将其对应的位设为0。在这种情况下，Bloom filter不再正确地反映集合中的所有元素。</p></li><li><p>为了避免这个问题，Fan等人引入了计数布隆过滤器<em>(counting Bloom filter)</em>的思想。在一个<em>counting Bloom filter</em>中，采用一个计数器来代替位。当元素插入时，相应的计数器增加，当元素删除时，相应的计数器被减少。为了避免计数器溢出，可以选择足够大的计数器。Fan等人的分析表明，每个计数器4位就适用于大多数应用了。</p></li><li><p>要确定一个好的计数器大小，可以考虑一个<em>counting Bloom filter</em>表示$n$个元素的集合，使用$k$个哈希函数和$m$个计数器。设$c(i)$为第$i$个计数器的计数。第$i$个计数器为$j$次的概率是一个二项式随机变量</p><script type="math/tex; mode=display">\mathbb{P}(c(i)=j)=\left(\begin{array}{c}n k \\j\end{array}\right)\left(\frac{1}{m}\right)^{j}\left(1-\frac{1}{m}\right)^{n k-j} .</script><p>任何计数器至少为$j$的概率大于$m\mathbb{P}(c(i)\geq j)$，则</p><script type="math/tex; mode=display">\mathbb{P}(c(i) \geq j) \leq\left(\begin{array}{c}n k \\j\end{array}\right) \frac{1}{m^{j}} \leq\left(\frac{\mathrm{e} n k}{j m}\right)^{j}</script><p>假设$k≤(ln 2)m/n$，因为$k = (ln 2)m/n$获得最佳的<em>false positive rate</em>，则</p><script type="math/tex; mode=display">\mathbb{P}\left(\max _{i} c(i) \geq j\right) \leq m\left(\frac{\mathrm{e} \ln 2}{j}\right)^{j}</script><p>如果每个计数器设置为4位，则某个计数器达到16时，计数器就会溢出。从上面公式得到</p><script type="math/tex; mode=display">\mathbb{P}\left(\max _{i} c(i) \geq 16\right) \leq 1.37\times10^{-15}\times m</script><p>这个限制适用于最多$n$个项目的集合，这将满足大多数应用程序。另一种解释这个结果的方法是，当有$m\ \text{ln}\ 2$个总计数器增量分布在$m$个计数器上时，计数器的最大值很有可能是$O(\text{log}\ m)$，因此每个计数器只需要$O(\text{log}\ \text{log}\ m)$位。</p></li><li><p>在实践中，当计数器溢出时，一种解决方法是保持它的最大值。只有当计数器最终降至0而它本应保持非0时，这才会导致更多的<em>false positive rate</em>。如果删除是随机的，则此事件的预期时间相对较大。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Bloom Filter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2021/03/05/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <url>/2021/03/05/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="第一篇博客"><a href="#第一篇博客" class="headerlink" title="第一篇博客"></a>第一篇博客</h1><ul><li>测试一下</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  
  
  
  <entry>
    <title>about</title>
    <link href="/"/>
    <url>/</url>
    
    <content type="html"><![CDATA[]]></content>
    
  </entry>
  
  
  
</search>
