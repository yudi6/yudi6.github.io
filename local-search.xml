<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>《Modeling Transferable Topics for Cross-Target Stance Detection》笔记</title>
    <link href="/2021/04/21/%E3%80%8AModeling%20Transferable%20Topics%20for%20Cross-Target%20Stance%20Detection%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/04/21/%E3%80%8AModeling%20Transferable%20Topics%20for%20Cross-Target%20Stance%20Detection%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Modeling-Transferable-Topics-for-Cross-Target-Stance-Detection"><a href="#Modeling-Transferable-Topics-for-Cross-Target-Stance-Detection" class="headerlink" title="Modeling Transferable Topics for Cross-Target Stance Detection"></a>Modeling Transferable Topics for Cross-Target Stance Detection</h1><ul><li>论文：<a href="https://dl.acm.org/doi/abs/10.1145/3331184.3331367">https://dl.acm.org/doi/abs/10.1145/3331184.3331367</a></li></ul><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><ul><li><p>定向的立场检测方法主要在目标内进行，即使用同一目标的数据对模型进行训练和测试。当我们面对一个新的目标时，我们已经标记了与现有目标有关的数据，但是很少或没有用于新目标的已标记数据。因此，缺乏新目标的标记训练数据限制了特定目标模型的构建。</p></li><li><p>本课题推动了交叉目标立场检测的研究，利用相关的源目标标记数据来构建新目标模型，先前的两个研究已经解决了跨目标立场检测问题。Augenstein等人整合了目标的语义表示来学习文本表示，Xu等人的进一步利用自注意力机制来关注重点词。然而，他们在训练过程中不考虑任何来自最终目标的信息，因此模型更多地学习到源目标的基于目标特征。此外，他们只利用最终目标来学习文本表示，并没有明确地建立两个目标之间可迁移知识的模型，因此跨目标适应能力相当有限。</p></li><li><p>跨目标立场检测任务的关键研究挑战是对可转移知识的有效建模，以促进跨目标的适应。用户经常讨论目标的一些从属话题，通过对这些话题的表达可以推断出他们对目标的立场。此外，两个目标之间的共同主题可以作为可转移的知识来利用，以帮助模型实现跨目标。表1为一个示例。虽然两个文本属于不同的对象，但它们都表达了对主题的态度。论文将这些主题知识整合到立场检测模型中，以提高其跨目标适应能力。</p><p><img src="/2021/04/21/%E3%80%8AModeling%20Transferable%20Topics%20for%20Cross-Target%20Stance%20Detection%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:100%;"></p></li></ul><ul><li><p>论文提出了一种跨目标立场检测方法，将主题知识获取和文本表示学习整合到一个统一的端到端框架中。为了有效获取可转移的主题知识并通过反向传播进行训练，论文采用神经变分推理，利用源目标和最终目标的未标记数据产生潜在的主题，并利用获得的主题知识增强文本表示。论文的工作贡献如下：</p><ul><li>利用可转移的主题知识进行跨目标的模型适应，并提出了一种有效的跨目标立场检测方法。</li><li>我们的方法利用来自源目标和最终目标的数据获取主题知识，并在端到端框架中学习表示。</li><li>实验结果表明，该方法在跨目标立场检测方面优于目前最先进的方法。</li></ul></li></ul><h2 id="PROBLEM-STATEMENT"><a href="#PROBLEM-STATEMENT" class="headerlink" title="PROBLEM STATEMENT"></a>PROBLEM STATEMENT</h2><ul><li>源目标一组已标记的文本数据集$\mathcal{D}_s^l=\{(x_s^{(i)},y_s^{(i)})\}_{i=1}^{N_s}$，其中$x_s$是一个句子，$y_s$是立场标签。最终目标的一组未标记的文本数据集$\mathcal{D}_d=\{x_d^{(i)}\}_{i=1}^{N_d}$，还拥有来自两个目标的大量未标记文本(称为外部数据)$\mathcal{D}_e=\{x_e^{(i)}\}_{i=1}^{N_e}$。其中$x_e$属于源目标或最终目标。通常，$N_e\gg N_s\approx N_d$。跨目标立场检测任务是预测$\mathcal{D}_d$中文本的立场标签。</li></ul><h2 id="PROPOSED-METHOD"><a href="#PROPOSED-METHOD" class="headerlink" title="PROPOSED METHOD"></a>PROPOSED METHOD</h2><ul><li><p>论文提出了<strong>Variational Transfer Network(VTN)</strong>结构用于跨目标立场检测。如图1，它由两个部分组成。第一部分是主题知识获取模块，其目的是利用来自两个目标的大量未标记数据$\mathcal{D}_e$来获取可转移的主题知识。第二部分是一个带有识别器的主题增强记忆网络，它将主题知识存储在记忆中，并使用$\mathcal{D}_s^l$和$\mathcal{D}_d$来学习目标不变表示$h’$与进行立场预测。</p><p><img src="/2021/04/21/%E3%80%8AModeling%20Transferable%20Topics%20for%20Cross-Target%20Stance%20Detection%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:100%;"></p></li></ul><h3 id="Topic-Knowledge-Acquisition-with-Neural-Variational-Inference"><a href="#Topic-Knowledge-Acquisition-with-Neural-Variational-Inference" class="headerlink" title="Topic Knowledge Acquisition with Neural Variational Inference"></a>Topic Knowledge Acquisition with Neural Variational Inference</h3><ul><li><p>获取可转移的知识是该方法的核心功能，论文采用主题建模方式产生潜在的主题来获取知识，以实现有效的跨目标适应。</p></li><li><p><strong><em>Topic modeling based on variational autoencoder</em></strong>：用$K$表示主题建模过程中主题的数量。对于每个主题$k \ (k = 1,2，…，K)$，引入一个待学习的参数向量作为主题嵌入$t_k∈\mathbb{R}^d$，主题知识$T$由这些主题嵌入$T = \{t_1,t_2，…, t_K\}$，给定词嵌入矩阵$E∈\mathbb{R}^{V ×d}$，其中$V$为词汇数量，可以通过计算主题与词的语义相似度，得到每个主题$k$的词分布$ϕ_k∈\mathbb{R}^V$:</p><script type="math/tex; mode=display">\phi_{k}=\text{Softmax}\left(\mathrm{E} t_{k}\right), \quad k=1,2, \ldots, K</script><p>在我们的框架中，为了通过反向传播训练主题建模过程，我们采用了<strong><em>neural variational inference</em></strong>，通过变分自编码器(VAE)实现了LDA风格的主题建模。</p><p>设$\boldsymbol{x}∈\mathbb{Z}^{V}_+$表示文本$x∈D_e$的词袋表示。基于VAE，每个长度为$N$个单词的文本$x$的生成过程为:</p><ul><li><p>根据先验分布(standard Gaussian)确定一个潜在变量$z∈\mathbb{R}^K$：$z∼N(0, 1)$</p></li><li><p>得到主题分布$θ = Softmax(\mathbf{W}z)∈\mathbb{R}^K$，其中$W$是一个可学习的矩阵。</p></li><li><p>对于位置$n(n = 1,2，…， N)$的每个单词，得到$w_n∼\boldsymbol{\phi}^⊤θ$。</p><p>这里，得到单词$w_n$的概率是由以下公式计算:</p><script type="math/tex; mode=display">p\left(w_{n} \mid \boldsymbol{\theta}, \boldsymbol{\phi}\right)=\sum_{k=1}^{K} p(k \mid \boldsymbol{\theta}) \cdot p\left(w_{n} \mid \boldsymbol{\phi}_{k}\right)=\left[\boldsymbol{\theta}^{\top} \boldsymbol{\phi}\right]_{w_{n}}</script><p>因此我们有$w_n∼\boldsymbol{\phi}^⊤θ$，且$\boldsymbol{\phi}^⊤θ\in\mathbb{R}^V$。</p></li></ul><p>由于$z$的后验推断是难以处理的，VAE引入一个变分分布$q(z\ |\ \boldsymbol{x})$来近似真实的后验。$q(z\ |\ \boldsymbol{x})$是一个对角线高斯函数:$q(z\ |\ \boldsymbol{x}) = N(z;\mu，σ^2I)$，$\mu，σ^2$由多层感知器(MLP)参数化：$\mu= MLP_\mu(\boldsymbol{x})， log(σ^2) = MLP_σ (\boldsymbol{x})$。</p></li><li><p><strong><em>objective function</em></strong>：在训练过程中，基于VAE的主题模型以最大化变分下界为目标:</p><script type="math/tex; mode=display">  \operatorname{ELBO}(\boldsymbol{x})=\underset{\boldsymbol{z} \sim q(\boldsymbol{z} \mid \boldsymbol{x})}{\mathbb{E}}\left[\boldsymbol{x}^{\top} \log \left(\boldsymbol{\phi}^{\top} \boldsymbol{\theta}\right)\right]-\mathbb{D}_{\mathrm{KL}}[q(z \mid \boldsymbol{x}) \| p(z)]</script><p>  第一项是重建输入$\boldsymbol{x}$，第二项KL散度项作为正则化项，将变后验与先验相匹配。因此，<strong>NVI</strong>网络的目标函数为:T</p><script type="math/tex; mode=display">  \min _{\left\{\mathrm{T}, \mathrm{W}, \mathrm{MLP}_{\mu}, \mathrm{MLP}_{\sigma}\right\}} \mathcal{L}_{\mathrm{NVI}}=-\sum_{x \in \mathcal{D}_{e}} \operatorname{ELBO}(\boldsymbol{x})</script></li></ul><h3 id="Knowledge-Transfer-with-Topic-Memory"><a href="#Knowledge-Transfer-with-Topic-Memory" class="headerlink" title="Knowledge Transfer with Topic Memory"></a>Knowledge Transfer with Topic Memory</h3><ul><li><p>为了充分利用该网络实现目标间的知识转移，论文将主题知识存储在外部记忆中，并采用多跳记忆网络学习文本表示和预测立场。</p></li><li><p><strong><em>Building topic memory</em></strong>：传统记忆网络包含一个输入记忆$M_{in}$和一个输出记忆$M_{out}$。论文采用了简化版本，在网络中只包含一个内存矩阵$M$，即$M = M_{in} = M_{out}$。使用$T$初始化外部记忆，即$M = T$，并在训练过程中进一步更新记忆。</p></li><li><p><strong><em>Topic-enhanced text representation learning</em></strong>:形式上，主题内存$M$有$K$个槽$\{m_1,m_2，…，m_K\}$，每个槽位$m_k$保存着对应主题$k$的信息。</p><p>从$\mathcal{D}_s^l$选择一个句子，使用一个双向LSTM对其进行编码，选择最后一个时间的两个方向上的隐状态来获取它的向量表示$h$，然后采用注意力机制获取重要的内存插槽(即主题)，生成增强的文本表示$h’$:</p><script type="math/tex; mode=display">\begin{array}{c}\alpha_{k}=\text{Softmax}\left(\boldsymbol{m}_{k}^{\top} \mathbf{W}_{1} \boldsymbol{h}\right), \quad \boldsymbol{o}=\sum_{k=1}^{K} \alpha_{k} \boldsymbol{m}_{k} \\\boldsymbol{h}^{\prime}=\mathbf{W}_{2} \boldsymbol{h}+\boldsymbol{o}\end{array}</script><p>其中$α_k$为句子与主题$k$的匹配分数，$h$为访问内存的查询向量。主题记忆产生的输出向量$o$对主题知识进行编码，矩阵$\mathbf{W}_1$和$\mathbf{W}_2$是需要学习的参数。</p><p>如果采用单跳存储网络，$h ‘$将是用于预测立场的最终表示。进一步将其扩展为多跳样式，利用前一跳产生的$h ‘$作为后一跳的查询向量。</p></li><li><p><strong><em>Stance predictor</em></strong>：采用一个带有softmax函数的MLP作为立场预测器，输出预测的立场分布$\hat{y}= softmax (MlP_{SP}(h’))$。通过最小化源目标数据$D_sl$上的交叉熵损失来训练内存网络:</p><script type="math/tex; mode=display">\min _{\Theta_{\mathrm{M}}} \mathcal{L}_{\mathrm{SP}}=\sum_{x \in \mathcal{D}_{s}^{l}} \text { CROSS-ENTROPY }(\hat{y}, y)</script></li></ul><h3 id="Target-Invariant-Representation-Learning-with-Target-Discriminator"><a href="#Target-Invariant-Representation-Learning-with-Target-Discriminator" class="headerlink" title="Target-Invariant Representation Learning with Target Discriminator"></a>Target-Invariant Representation Learning with Target Discriminator</h3><ul><li><p>为了进一步使文本表示更具<em>target-invariant</em>，便于跨目标的模型适应，引入了一个目标识别器来对输入文本的目标标签进行分类，即判断文本属于源目标还是最终目标，实现方法为MLP(记为$MLP_{TD}$)。如果识别器不能预测文本的目标标签，那么它的表示是<em>target-invariant</em>的。引入目标识别器的另一个好处是，可以利用目标目标中的未标记数据来训练主题记忆。</p></li><li><p>具体来说，给定一个来自$\mathcal{D}_s^l$或$\mathcal{D}_d$的句子，其表示$h ‘$的目的是混淆目标分类器，使目标分类在$\mathcal{D}_s^l∪\mathcal{D}_d$上的交叉熵损失$\mathcal{L}_{TD}$最大化，而分类器本身的目的是使LTD最小化。因此，带有识别器的记忆网络的训练过程是一个对抗性的训练过程，具有如下的极大极小博弈</p><script type="math/tex; mode=display">\min _{\Theta_{\mathrm{M}}} \max _{\mathrm{MLPTD}} \mathcal{L}_{\mathrm{SP}}-\lambda \mathcal{L}_{\mathrm{TD}}</script><p>其中$λ$为权衡参数。我们通过反向传播中的梯度反转操作来实现这个过程，这是一种在基于迁移学习模型中广泛使用的技术。</p></li></ul><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><ul><li>采用端到端的培训方式来优化VTN。它由两部分组成：NVI网络训练以及使用$\mathcal{D}_s^l∪\mathcal{D}_d$训练的带有识别器的记忆网络(MN-D)。具体来说，我们迭代训练两部分：首先训练两个epoch的NVI，并使用训练的主题嵌入初始化记忆的MN-D，进一步训练两个epoch的MN-D。然后利用MN-D训练的主题记忆更新主题嵌入，再训练两个epoch的NVI。上述过程迭代直到收敛。？</li></ul><h2 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h2><ul><li><p>实验相关设置见原论文，结果如下</p><p><img src="/2021/04/21/%E3%80%8AModeling%20Transferable%20Topics%20for%20Cross-Target%20Stance%20Detection%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:70%;"></p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>查看这篇的论文的原因是基于我们的微博数据集缺少立场标签，若采用其他有立场标签数据所构建的立场分类器对我们的微博数据集进行立场检测，需要考虑立场分类器的跨目标学习能力，即立场分类器是否仍然适用于新任务。与情感分类不同，不同的立场分类在面对不同目标时侧重点不同，而在谣言检测中，目标是起源推文（微博），谣言之间的目标往往不具有相关性。</li><li>论文通过挖掘不同目标文本内相同的主题存在的联系以实现立场分类任务的跨目标学习，但该方法要求源目标与最终目标存在相关性，如文中实验中的<em>Feminist Movement</em> (FM)与<em>Legalization of Abortion</em> (LA), <em>Hillary Clinton</em>(HC)与<em>Donald Trump</em>(DT)。可以看到这两个实验具有比较高的相关性，这是我们在weibo或推特数据集上没有的，因此该迁移方法并不是简单适用于我们的立场检测。</li><li>论文提供了使用主题模型指导立场检测任务的思路，而且采用的对抗性训练过程使分类器表现出了<em>target-invariant</em>，这是我们的立场检测所需要的。</li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Stance Detection</tag>
      
      <tag>Topic Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《A Convolutional Approach for Misinformation Identification》笔记</title>
    <link href="/2021/03/30/%E3%80%8AA%20Convolutional%20Approach%20for%20Misinformation%20Identification%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/30/%E3%80%8AA%20Convolutional%20Approach%20for%20Misinformation%20Identification%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="A-Convolutional-Approach-for-Misinformation-Identification"><a href="#A-Convolutional-Approach-for-Misinformation-Identification" class="headerlink" title="A Convolutional Approach for Misinformation Identification"></a>A Convolutional Approach for Misinformation Identification</h1><ul><li>论文：<a href="http://114.215.172.152/research/Classification/A%20convolutional%20approach%20for%20misinformation%20identification.pdf">http://114.215.172.152/research/Classification/A%20convolutional%20approach%20for%20misinformation%20identification.pdf</a></li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>GRU-2的缺点：在错误信息输入序列有限的情况下，GRU-2不具备实际早期检测任务的条件。有限的输入序列可能不够长，不足以体现动态时序信号，因此GRU-2在某些情况下不会捕捉到动态时间信号特征；训练后的RNN模型具有一个恒定的递归转移矩阵，并导致序列信号在每两个连续输入之间的传播方式相同，这对于动态和复杂的情况是不够的；GRU-2模型偏向于输入序列的最新元素但关键特征不一定出现在输入序列的后部。</p></li><li><p>CNN的卷积架构和$k$-max pooling操作可以灵活地提取分散在一个输入序列中的关键特征。论文提出了一种用于错误信息识别和早期检测任务的<strong>Convolutional Approach  for Misinformation Identification (CAMI)</strong>模型。首先，我们研究了所采用的数据集中的数据分布(详见第3节)，观察错误信息和真实信息的<strong>长尾分布</strong>。在此基础上，我们提出了适当的方法将每个事件划分为几个阶段，将所有事件分成若干组微博，通过段落向量学习每组的表示。因此，CAMI的输入序列是由事件分成的组。CAMI不仅能自动从输入实例中提取局部-全局的重要特征，而且还能灵活地提取分散在一个输入序列中的关键特征。CAMI模型的可视化实验中获得了一些观察结果，该模型有助于更好地理解人类在网络空间中的行为，并更准确地塑造现实社会媒体场景。</p></li><li><p>主要贡献：</p><ul><li><p>我们使用无监督的段落向量方法学习输入微博帖子的表示，使用有监督的CNN方法自动获取虚假信息和真实信息的关键特征。</p></li><li><p>我们将所提出的模型所捕获的信息可视化，这将帮助我们理解社交媒体上的信息所具有的内在属性。</p></li><li><p>在两个真实世界的数据集上进行的实验表明CAMI在错误信息识别方面明显优于最先进的方法。</p></li></ul></li></ul><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul><li><p>之前的研究多用手工制作的特征，使用了超过文本之外的内容。</p></li><li><p>此外，其他一些作品提取了更有效的手工制作特征，包括冲突观点[Jin等人，2016]，时间属性[Kwon等人，2013;Ma等人，2015]，用户反馈[Giudice, 2010;Rieh et al]，并发出包含怀疑的推文[赵等人，2015]。上述基于特征工程的方法都未能覆盖动态复杂社交媒体场景中的潜在特征，未能形成重要特征之间更深层的交互。为了克服这些缺陷，基于RNN的模型试图捕捉错误信息扩散过程中的动态时间信号，并逐步学习事件的时间和文本表示，而不依赖任何手工制作的特征[Ma等人，2016]。</p></li><li><p>CNN由堆叠的卷积层和池化层组成，这些结构有助于建模重要的语义特征，并在各自的领域取得了很大的改进。例如，CNN已成功应用于语音识别、句子语义分析、点击率预测]、图像语义分割和强化学习任务]。CNN通常采用随机梯度下降训练，用反向传播计算梯度。</p></li><li><p>在Twitter数据集中错误信息和真实信息的事件数分别为498和494，在微博数据集中为2313和2351。微博数据集的分布如下。</p><p><img src="/2021/03/30/%E3%80%8AA%20Convolutional%20Approach%20for%20Misinformation%20Identification%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:70%"></p></li></ul><h2 id="Proposed-CAMI-Model"><a href="#Proposed-CAMI-Model" class="headerlink" title="Proposed CAMI Model"></a>Proposed CAMI Model</h2><ul><li><strong>Problem Definition：</strong>给定一组事件，每个事件包含一系列相关的微博帖子，每个微博帖子都有对应时间戳。这里的任务是在事件级别识别事件是否为误报，即通过分析事件的相关微博帖子序列来检测事件是否为误报。</li></ul><h3 id="Proposed-Model"><a href="#Proposed-Model" class="headerlink" title="Proposed Model"></a>Proposed Model</h3><ul><li><p>所提议的CAMI模型的框架如图所示，一共有3个小模块，以下将自底向上描述各模块。</p><p><img src="/2021/03/30/%E3%80%8AA%20Convolutional%20Approach%20for%20Misinformation%20Identification%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:50%"></p></li><li><p>由于虚假信息可能是用一种实话实说的方式来描述的，所以很难从一个特定的微博帖子中识别出虚假信息。相对而言，从一个事件的相关微博帖子序列中检测虚假信息是合理的，虚假信息和真实信息的属性对虚假信息的识别起着至关重要的作用，我们需要将事件的所有微博帖子作为一个整体来处理。</p></li><li><p><strong>Splitting all correlative microblog posts of an event into several groups：</strong>通过对微博帖子建模，将一个事件中所有相关的微博帖子集中到一个时间窗序列中以提取整体特征。首先，一个事件平均由数千条相关微博组成，事件之间存在差异。此外，在某些特定的时间窗口内的微博帖子具有很强的相关性，我们可以将这些相邻的微博帖子作为一个组以代表一个特定的事件阶段。</p></li><li><p>所有事件都需要以统一的方式进行分割，这样才能提取出有区别的特征。例如，真实信息往往在一开始就被发布或转载，很快就会消失，而错误信息往往在中间阶段吸引了相对持久的注意力。所以不同的微博帖子在同一时间窗口的信息量可能会有所不同。我们需要尽可能确保事件的一个阶段不被间断，也就是说，那些最相关的微博帖子应属于事件阶段的同一个组中。</p></li><li><p>考虑到所采用的数据集的长尾分布，采用等时间间隔可能会导致各组微博数量不平衡而影响特征学习的效果。最好按时间顺序将所有事件的微博帖子分成等量的组，具体来说，我们收集事件所有相关微博帖子的时间戳，并从每个事件的所有时间戳中减去相应事件的开始时间戳，然后这些时间戳被归一化。最后，整个时间戳按时间顺序平均分成20份，每个时间窗口为</p><script type="math/tex; mode=display">T_i = [t_{i−1}, t_i) , i = 1, 2, · · · , 20,</script><p>其中$t_i$是第$i$个时间段的结束时间戳，注意可能存在时间窗口使得该窗口内没有微博。</p></li><li><p><strong>Learning representation for each group via paragraph vector：</strong>我们将一个时间窗口的微博帖子作为一个事件段，用一系列的事件段对整体特征进行建模。为了方便起见，这里使用段落向量[Le and Mikolov, 2014]。一个事件内微博帖子的可以看作是一个段落来学习段落表示$\text g_i$，</p><script type="math/tex; mode=display">\underset{\mathbf{D}, \mathbf{W}}{\arg \max } \frac{1}{N} \sum_{n=k}^{N-k} \log p\left(\mathbf{w}_{n} \mid \mathbf{w}_{n-k}, \cdots \mathbf{w}_{n+k}\right)</script><p>通过softmax进行预测，</p><script type="math/tex; mode=display">\begin{array}{l}p\left(\mathbf{w}_{n} \mid \mathbf{w}_{n-k}, \cdots \mathbf{w}_{n+k}\right)=\frac{\exp \left(\boldsymbol{\theta}^{T} \mathbf{x}_{n}\right)}{\Sigma_{i} \exp \left(\boldsymbol{\theta}^{T} \mathbf{x}_{i}\right)} \\\mathbf{x}_{n}=h\left(\mathbf{g}_{j}, \mathbf{w}_{n-k}, \cdots, \mathbf{w}_{n+k} ; \mathbf{D}, \mathbf{W}\right)\end{array}</script><p>给定一个有$N$个单词的段落，一个单词用在$\mathbf{W}$中的列向量$\mathbf{w}_n$来表示，段落用在$\mathbf{D}$中的列向量$\text{g}_j$来表示，而且$θ$是softmax参数，$h$是拼接或平均运算。上下文单词和段落记忆用于预测当前单词。</p></li><li><p><strong>Modeling high-level interactions by CNN：</strong>CNN常用的架构包括卷积层、$k$-max池化层和全连接层。对于一个$n$阶段的事件实例$e_i$，每个阶段采用$\text{g}_j\in\mathbb{R}^d$做嵌入。我们可以得到实例矩阵$\mathbf{G}\in \mathbb{R}^{d\times n}$，在卷积神经网络，卷积层是通过权重矩阵$\mathbf{C}\in\mathbb{R}^{d\times\omega}$的卷积运算得到的，对卷积结果应用非线性函数，得到特征映射的一个元素为：</p><script type="math/tex; mode=display">\mathbf{f}[i]=\tanh \left(\langle\mathbf{G}[:, i: i+\omega-1], \mathbf{C}\rangle_{F}\right)</script><p>其中$\mathbf{G}[:, i: i+\omega-1]$表示$\mathbf{G}$的第$i$到$i+w-1$行，$F$表示<strong>Frobenius inner product</strong>。最后,我们采用$k$-max池化特性映射$\mathbf{f}$捕捉最重要的特性$f_{max}^k$。</p></li><li><p>此外，可以重复上面的卷积和池化操作。最后通过softmax获得最终输出$p_{e_i}$。其中$p_{e_i}$为预测事件$e_i$是否属于误报的概率。</p></li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><ul><li><p>实验相关设置见原论文，结果如下，</p><p><img src="/2021/03/30/%E3%80%8AA%20Convolutional%20Approach%20for%20Misinformation%20Identification%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:100%"></p><p>关于早期检测的结果如下。</p><p><img src="/2021/03/30/%E3%80%8AA%20Convolutional%20Approach%20for%20Misinformation%20Identification%E3%80%8B%E7%AC%94%E8%AE%B0/fig4.png" style="zoom:100%"></p></li></ul><script type="math/tex; mode=display">\begin{array}{c}F_{E}[x, y]=\min _{B K P}\left\{\left[\sum_{k=1}^{n_{s}} \sum_{j=0}^{y-1} \operatorname{error}\left(x_{E, s_{k}}\left[b_{j}, b_{j+1}\right]\right)\right]+\left[\sum_{k=1}^{n_{s}} \operatorname{error}\left(x_{E, s_{k}}\left[b_{y}, b_{y+1}\right]\right)\right]\right\} \\=\min _{b_{y}}\left\{F\left[b_{y}, y-1\right]+\left[\sum_{k=1}^{n_{s}} \operatorname{error}\left(x_{E, s_{k}}\left[b_{y}, b_{y+1}\right]\right)\right]\right\}\end{array}</script>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rumour Detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Detecting Rumors from Microblogs with Recurrent Neural Networks》笔记</title>
    <link href="/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Detecting-Rumors-with-Recurrent-Neural-Networks"><a href="#Detecting-Rumors-with-Recurrent-Neural-Networks" class="headerlink" title="Detecting Rumors  with Recurrent Neural Networks"></a>Detecting Rumors  with Recurrent Neural Networks</h1><ul><li>论文：<a href="https://ink.library.smu.edu.sg/sis_research/4630/">https://ink.library.smu.edu.sg/sis_research/4630/</a></li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>社会心理学文献将谣言定义为一个真实性未经证实或故意造假的故事或陈述。现有的谣言检测模型使用了学习算法结合了从帖子的内容、用户特征和扩散模式中得到的特征，或者简单地利用正则表达式来发现推文中的谣言。特性工程是至关重要的，但它是非常细致、有偏见和需要人工的。例如，图1中的两个时间序列图描述了中典型谣言信号的浅层模式。虽然它们可以显示谣言事件和非谣言事件的时间特征，但对于特征工程来说，这两种情况之间的差异既不明显也不强烈。</p><p><img src="/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:70%"></p></li></ul><ul><li>RNN适合于谣言检测，这是因为RNN中单元之间的连接循环形成了网络的内部状态，这能够捕捉到谣言扩散的动态特征。利用RNN，我们将事件的社会语境信息建模为一个变长时间序列。我们假设人们在听到谣言时会转发谣言或对其发表评论，从而产生连续不断的帖子。方法在监督下学习谣言帖子的时间和文本特征。在两个真实的微博数据集上进行的大量实验表明，基于RNN的方法具有出色的性能。该模型也被证明对谣言的早期检测是有效的，在谣言最初传播几小时后就可以获得足够的准确性。</li><li>据我们所知，这是首次使用深度学习模型来检测微博上的谣言。基于rnn的模型实现了显著的改进，超过了最先进的学习算法与依赖手工制作的特征。该模型具有更强的可扩展性，通过复杂的循环单元和额外的隐藏层，可以比现有的方法更准确地检测谣言。</li><li>基于RNN的模型与现有的检测相比（如在线谣言揭穿服务）相比允许早期检测，更有效。</li><li>我们为任务构建了两个带有ground truth标签的微博数据集，总共包含超过5000个声明，扩展到500万条相关微博帖子。我们将这个庞大的谣言数据集完全公开，以便用于研究目的。</li></ul><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul><li>之前的研究多用手工制作的特征，使用了超过文本之外的内容。</li><li>Zhao等人[2015]利用“not true”、“unconfirmed”或“debunk”等提示词，对质疑和否认推文进行早期的谣言检测。</li></ul><h2 id="RNN-Recurrent-Neural-Network"><a href="#RNN-Recurrent-Neural-Network" class="headerlink" title="RNN: Recurrent Neural Network"></a>RNN: Recurrent Neural Network</h2><ul><li><p>RNN: Recurrent Neural Network  </p><script type="math/tex; mode=display">\begin{aligned}h_{t} &=\tanh \left(U x_{t}+W h_{t-1}+b\right) \\o_{t} &=V h_{t}+c\end{aligned}</script></li><li><p>Long Short-Term Memory (LSTM)  </p><script type="math/tex; mode=display">\begin{aligned}i_{t} &=\sigma\left(x_{t} W_{i}+h_{t-1} U_{i}+c_{t-1} V_{i}\right) \\f_{t} &=\sigma\left(x_{t} W_{f}+h_{t-1} U_{f}+c_{t-1} V_{f}\right) \\\tilde{c_{t}} &=\tanh \left(x_{t} W_{c}+h_{t-1} U_{c}\right) \\c_{t} &=f_{t} c_{t-1}+i_{t} \tilde{c_{t}} \\o_{t} &=\sigma\left(x_{t} W_{o}+h_{t-1} U_{o}+c_{t} V_{o}\right) \\h_{t} &=o_{t} \tanh \left(c_{t}\right)\end{aligned}</script></li><li><p>Gated Recurrent Unit (GRU)  </p><script type="math/tex; mode=display">\begin{array}{l}z_{t}=\sigma\left(x_{t} U_{z}+h_{t-1} W_{z}\right) \\r_{t}=\sigma\left(x_{t} U_{r}+h_{t-1} W_{r}\right) \\\tilde{h}_{t}=\tanh \left(x_{t} U_{h}+\left(h_{t-1} \cdot r_{t}\right) W_{h}\right) \\h_{t}=\left(1-z_{t}\right) \cdot h_{t-1}+z_{t} \cdot \tilde{h}_{t}\end{array}</script></li></ul><h2 id="RNN-based-Rumor-Detection"><a href="#RNN-based-Rumor-Detection" class="headerlink" title="RNN-based Rumor Detection"></a>RNN-based Rumor Detection</h2><ul><li>首先，我们引入一种方法，将输入的微博帖子转换为连续的变长时间序列，然后用不同类型隐藏层单元和层树进行分类。</li><li>我们定义一组给定的事件为$E = \{E_i\}$，其中每个事件$E_i = {(m_{i,j}, t_{i,j})}$由时间戳$t_{i,j}$上的所有相关帖子$m_{i,j}$组成，任务是将每个事件分类为谣言或非谣言。</li></ul><h3 id="Variable-length-Time-Series"><a href="#Variable-length-Time-Series" class="headerlink" title="Variable-length Time Series"></a>Variable-length Time Series</h3><ul><li><p>由于一个热门事件中可能会有成千上万的帖子，而最终只有一个分类的输出单元。反向传播通过大量的时间序列，会导致梯度消失或爆炸。因此将帖子按一定时间间隔处理作为序列中的单个单元，再使用RNN建模。最初，我们将整个时间线平均划分为$N$个间隔($N$是参考长度)。系统尝试通过删除集合$U_0$中的空间隔来发现非空间隔的集合$U’$（即，$U’$中的每个间隔至少具有一条推特）。这些非空间隔中总时间跨度最长的被选入集合$\bar U$。 如果$\bar U$中的间隔数小于$N$，并且间隔数大于上一轮的间隔数，我们将间隔减半并继续进行分区； 否则，它返回由$\bar U$给定的发现的连续间隔。算法如下</p><p><img src="/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:70%"></p></li></ul><h3 id="Structures-of-Models"><a href="#Structures-of-Models" class="headerlink" title="Structures of Models"></a>Structures of Models</h3><ul><li><p>根据上节构建的时间序列，RNN的循环单元自然地拟合时间间隔。在每个区间内，我们使用区间内词语的$tf\ast idf$值作为输入。我们根据$tf\ast idf$值保留最前面的$K$项来对词进行删减，因此输入维数为$K$。RNN的结构如图2所示。注意，输出单元与最后的时间步骤相关联，它使用softmax来实现这两个类的概率输出。</p><p><img src="/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:70%"></p></li><li><p><strong>tanh-RNN</strong>：最基本的结构，其中隐藏的单元不是门控的，以有限的方式捕获跨时间间隔的上下文。设$g_c$为ground-truth，其中$c$表示类标签事件的二维多项式分布。对于每个训练实例(即每个事件)，我们的目标是最小化预测概率分布与真实值之间的平方误差:</p><script type="math/tex; mode=display">\min \sum_{c}\left(g_{c}-p_{c}\right)^{2}+\sum_{i}\left\|\theta_{i}\right\|^{2}</script><p>其中$g_c$和$p_c$分别是目标分布和预测分布，$\theta_i$表示待估计的模型参数，使用L2正则化惩罚。</p></li><li><p><strong>Single-layer LSTM and GRU ：</strong>长距离依赖关系对于捕获事件生命周期中的谣言形式和隐藏特征非常重要。门控单元不仅保留了当前时间步长的内容，而且还注入了前一步的学习到信息。然而，由于门控单元的存在，参数的规模明显增大。例如，GRUs由于引入了复位门和更新门，使得原有的参数空间增加了三倍。为了降低复杂度，我们在输入层和隐藏层之间添加了一个嵌入层(固定长度为100)，使得参数的规模变得更小。不使用预先训练的基于外部集合的向量，而是使用我们的模型自己学习嵌入向量$E$。</p></li><li><p><strong>Multi-layer GRU：</strong>通过添加第二个GRU层来捕捉不同时间步长之间更高层次的特征。考虑到LSTMs更复杂的参数集，我们只将GRU扩展为多个层。</p><script type="math/tex; mode=display">\begin{array}{l}x_{e}=x_{t} E \\z_{t}^{(1)}=\sigma\left(x_{e} U_{z}^{(1)}+h_{t-1}^{(1)} W_{z}^{(1)}\right) \\r_{t}^{(1)}=\sigma\left(x_{e} U_{r}^{(1)}+h_{t-1}^{(1)} W_{r}^{(1)}\right) \\\tilde{h}_{t}^{(1)}=\tanh \left(x_{e} U_{h}^{(1)}+\left(h_{t-1}^{(1)} \cdot r_{t}^{(1)}\right) W_{h}^{(1)}\right) \\h_{t}^{(1)}=\left(1-z_{t}^{(1)}\right) \cdot h_{t-1}^{(1)}+z_{t}^{(1)} \cdot \tilde{h}_{t}^{(1)} \\z_{t}^{(2)}=\sigma\left(h_{t}^{(1)} U_{z}^{(2)}+h_{t-1}^{(2)} W_{z}^{(2)}\right) \\r_{t}^{(2)}=\sigma\left(h_{t}^{(1)} U_{r}^{(2)}+h_{t-1}^{(2)} W_{r}^{(2)}\right) \\\tilde{h}_{t}^{(2)}=\tanh \left(h_{t}^{(1)} U_{h}^{(2)}+\left(h_{t-1}^{(2)} \cdot r_{t}^{(2)}\right) W_{h}^{(2)}\right) \\h_{t}^{(2)}=\left(1-z_{t}^{(2)}\right) \cdot h_{t-1}^{(2)}+z_{t}^{(2)} \cdot \tilde{h}_{t}^{(2)}\end{array}</script></li><li><p><strong>Model Training：</strong>通过利用损失的反向传播对所有参数的导数来训练所有RNN模型，使用AdaGrad算法进行参数更新。词汇大小$K$设为5000，嵌入向量大小设为100，隐藏单元大小设为100，学习率设为0.5。</p></li></ul><h2 id="Experiments-and-Results"><a href="#Experiments-and-Results" class="headerlink" title="Experiments and Results"></a>Experiments and Results</h2><ul><li><p>使用的数据集信息如下</p><p><img src="/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/fig4.png" style="zoom:70%"></p></li><li><p>实验结果</p><table><tr><td><img src="/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/fig5.png" border="0"></td><td><img src="/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/fig6.png" border="0"></td></tr></table><p><img src="/2021/03/29/%E3%80%8ADetecting%20Rumors%20from%20Microblogs%20with%20Recurrent%20Neural%20Networks%E3%80%8B%E7%AC%94%E8%AE%B0/fig7.png"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rumour Detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《All-in-one ： Multi-task Learning for Rumour Verification》笔记</title>
    <link href="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Rumour-Verification"><a href="#Rumour-Verification" class="headerlink" title="Rumour Verification"></a>Rumour Verification</h1><ul><li>论文：<a href="https://arxiv.org/abs/1806.03713">https://arxiv.org/abs/1806.03713</a></li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>社交媒体作为关注事件和突发新闻的平台越来越受用户欢迎。然而，并不是所有在社交媒体上传播的信息都是准确的，不准确的信息会对社会造成严重的危害。科学界对开发验证社交媒体信息的工具越来越感兴趣，Facebook也投入了大量的努力来减轻错误信息造成的问题。</p></li><li><p>谣言分辨过程分为四个子任务(如图1)：</p><ol><li>谣言检测，确定一个声明是否值得验证;</li><li>跟踪谣言，在谣言发生时收集消息来源和观点;</li><li>立场分类，确定消息来源或用户对谣言真实性的态度;</li><li>谣言验证，作为预测谣言真实性的最终步骤。</li></ol><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:100%;"></p><p>这些步骤可以在谣言生命周期的不同时间执行。理想情况下，谣言可以被认定为真或假。然而，当没有足够的证据来确定它们的真实性时，它们也可能仍然是未经核实的。</p></li><li><p>谣言分辨过程可以表示为一个多任务问题，其中真实性分类任务是主要任务，其余任务是辅助任务，可以利用这些任务来提高真实性分类器的性能。多任务学习可以帮助密切相关任务的共享表征的学习，即两个互补的任务可以相互给予”提示“。</p></li><li><p>结果利用这三个子任务的多任务学习场景（其中真实性分类是主要任务，立场分类和谣言检测为辅助任务），比单任务的学习与现在最新的系统都有实质性改进。</p></li></ul><h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><h3 id="Rumour-classification-system"><a href="#Rumour-classification-system" class="headerlink" title="Rumour classification system"></a>Rumour classification system</h3><ul><li>(Zubiaga等人，2018a)将谣言检测定义为区分谣言(未经验证的信息)和非谣言(所有其他传播的信息)的任务。谣言检测后，则将被分类为谣言的信息输入到系统的立场分类和验证组件中，最终确定谣言的真实性。</li><li><strong>Stance classification</strong>：确定与谣言相关的其他帖子是持支持、否认或是质疑态度，还是只是评论。用户对谣言所表达的立场可以表明谣言的真实性，有研究表明，容易引发否认和质疑的谣言更有可能被证明是错误。之前基于立场分类方面的工作探索了序列分类器的使用，已经证明序列分类器实质上优于标准的，非序列分类器。</li><li><strong>Rumour detection：</strong>谣言检测方面的工作更为稀缺。最早的方法之一是由Zhao等人(2015)提出的基于规则的方法，从而确定相关信息是谣言。Zubiaga等人(2017)提出了一种连续的方法来利用事件中早期帖子的上下文。序列方法在召回率方面取得了显著的改进，这是基于规则的方法所缺乏的。</li><li><strong>Rumour verification：</strong>谣言验证的常见方法包括从揭露谣言的网站(如snopes.com、emergent.com、politifact.com)收集已解决谣言的语料。Wang(2017)基于politifact.com的声明创建了一个数据集，并根据真实程度进行了标注，提出了一种混合卷积神经网络，将元数据与文本集成在一起。Twitter是一个研究谣言的流行平台，而谣言的种子和注释通常仍然来自辟谣网站。Giasemidis等人(2016)从Twitter收集了72个谣言数据集，这项工作测量了在不同的时间窗下一声明的可信度。</li><li><strong>Sequence classification：</strong>考虑谣言检测与谣言验证的工作强调了在处理谣言时采取时序敏感方法的重要性，因此实验中使用基于LSTM的架构。</li></ul><h3 id="Multi-task-learning"><a href="#Multi-task-learning" class="headerlink" title="Multi-task learning"></a>Multi-task learning</h3><ul><li>多任务学习是指用一个共享的表示形式对几个相关的任务进行联合学习。论文中使用了最常见的多任务学习方法，即<strong><em>hard parameter sharing</em></strong>，这意味着不同的任务使用相同的隐藏层。多任务学习通过使用其他数据集的相关任务和正则化，有效地增加了训练集的规模，而该模型必须学习多个任务的共享表示，减小了在其中某一任务过拟合的风险。在多任务学习中，辅助任务可以用来指导主任务学习由于任务和特征之间的复杂关系而忽略或无法识别的特征。例如，当潜在的有帮助的特性不是作为主要任务使用，而是成为辅助任务中的标签时，多任务学习是特别有用的。在实验中，立场分类可以作真实性分类系统的一种特征，其关系如之前所示。</li></ul><h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><ul><li>使用的谣言数据集为PHEME和RumourEval，其中包含不同级别的谣言检测、立场识别和谣言验证。</li></ul><h4 id="RumourEval"><a href="#RumourEval" class="headerlink" title="RumourEval"></a>RumourEval</h4><ul><li><p>RumourEval是作为the SemEval-2017 Task 8 competition的一部分数据集。它包含325条讨论谣言的推特帖子，RumourEval数据集中的所有对话都是谣言，因此该数据集只涵盖谣言立场和准确性分类的任务。它分为训练、测试和验证集。测试集包含与训练和验证集相同的事件有关的各种谣言，此外还有两个谣言：关于玛丽娜·乔伊斯和希拉里·克林顿的健康状况。</p></li><li><p>表1显示了RumourEval数据集中每组对话线程、分支和tweet的数量，以及这两个任务的标签分布。在立场分类任务中，质疑<strong>Q</strong>和否认<strong>D</strong>较少。对于谣言验证任务，训练集包含的真实例比假实例或未验证实例多，而开发和测试集则更加平衡。</p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:100%;"></p></li></ul><h4 id="PHEME"><a href="#PHEME" class="headerlink" title="PHEME"></a>PHEME</h4><ul><li><p>该数据集包含3个级别的注释。首先，每个线程被注释为谣言或非谣言；第二，谣言会被贴上真假或未经证实的标签。第三，通过众包？？对一个子集(RumourEval中使用的线程)进行注解，用于推文层面的立场分类。</p></li><li><p>表2为数据集中每个事件的大小以及谣言检测和验证任务的标签分布。 事件的大小差别很大，并且具有不同的标签比例。总的来说，PHEME数据集包含的谣言比非谣言少，而谣言的大多数是真实的。</p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:100%;"></p></li></ul><h2 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h2><h3 id="Sequential-approach"><a href="#Sequential-approach" class="headerlink" title="Sequential approach"></a>Sequential approach</h3><ul><li>遵循Zubiaga等人描述的<strong>branchLSTM</strong>方法，将对话分解成线性分支，并将它们用作训练实例作为模型输入。该模型由一个LSTM层、几个密集的ReLU层和一个预测分类概率的softmax层组成。由于立场分类任务在一篇推特级别注释，使用每个时间戳LSTM的输出。而对于谣言检测和验证任务，只使用最后一次输出。对于每线程的预测结果，我们对每个分支进行多数投票，利用分类交叉熵损失对模型进行训练。</li></ul><h3 id="Multi-task-learning-approach"><a href="#Multi-task-learning-approach" class="headerlink" title="Multi-task learning approach"></a>Multi-task learning approach</h3><ul><li><p>使用方法如图3。它的基础是一种顺序方法，由共享的LSTM层(硬参数共享)表示，随后是一些特定于任务的层。可能的任务组合在图3中以虚线的形式显示，根据组合的不同，它们可以出现也可以不出现。我们在三种设置下进行实验：立场与谣言验证，谣言检测与谣言验证，以及一起学习所有三个任务。在多任务模型中，成本函数是每个任务损失的总和。三个任务的数据集大小不相等，因此，当训练实例缺少其中一个任务的标签时，它的预测不会给损失函数增加任何东西，就像它被正确地预测了一样。</p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig4.png" style="zoom:100%;"></p></li></ul><h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><ul><li>采用多数投票法，在谣言验证任务中，由于类别不平衡，因此具有较强的基线，从而获得了较高的准确率。</li><li>NileTMRG是SemEval-2017任务8中的最佳准确性分类系统。NileTMRG模型基于线性的支持向量机(SVM)，使用单词袋并结合选定的特征：URL的存在性、hashtag的存在以及支持、否认和查询推文的比例表示推文。实验在NileTMRG模型的基础上做了我们自己的NileTMRG*实现。这个模型需要数据集中每个tweet的立场标签，但是这些标签对于PHEME是不可用的，因此使用了Kochkina的立场分类模型实现，而最终NileTMRG*获得了更好的效果。</li><li>NileTMRG模型显示了流水线任务按顺序执行的场景，上一个步骤(立场分类)的结果作为下一个步骤(谣言验证)的输入，证明了立场分类是谣言验证的有效指标。</li></ul><h3 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h3><ul><li>我们对数据集中的tweet进行以下预处理：删除非字母字符，将所有单词转换为小写，使用<strong>NLTK</strong>进行词性分类。对推文文本进行预处理后，我们对一条推文中的每个单词提取谷歌新闻数据集上预先训练好的word2vec词嵌入，并取其平均值，得到一条推文表示。由于tweet的长度较短，这种表示方式在tweet上表现得很好。</li></ul><h2 id="Experiment-setup"><a href="#Experiment-setup" class="headerlink" title="Experiment setup"></a>Experiment setup</h2><ul><li><p>使用<strong>the Tree of Parzen Estimators (TPE)</strong>算法来搜索参数空间，相关超参数设置见原论文。</p></li><li><p>最终结果如下图</p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig5.png" style="zoom:100%;"></p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig6.png" style="zoom:100%;"></p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig7.png" style="zoom:100%;"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rumour Verification</tag>
      
      <tag>Multi-task</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Learning Reporting Dynamics during Breaking News for Rumour Detection in Social Media》笔记</title>
    <link href="/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Rumour-Detection-And-PHEME-Dataset"><a href="#Rumour-Detection-And-PHEME-Dataset" class="headerlink" title="Rumour Detection And PHEME Dataset"></a>Rumour Detection And PHEME Dataset</h1><ul><li>论文：<a href="https://arxiv.org/abs/1610.07363">https://arxiv.org/abs/1610.07363</a></li><li>PHEME 数据集：<a href="https://figshare.com/articles/PHEME_dataset_of_rumours_and_nonrumours/4010619">https://figshare.com/articles/PHEME_dataset_of_rumours_and_nonrumours/4010619</a></li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li>近年来，利用社交媒体来关注新闻已经变得很普遍。像Twitter这样的知名平台越来越多地被人们用来了解最新的新闻发展，以及被新闻记者用来收集新闻。然而，如恐怖袭击或暴乱的突发新闻在社交媒体上的传播速度不可避免地造成许多在新闻报道的早期阶段发布的信息是未经核实的。</li><li>谣言检测系统用于警告用户文章的未验证状态，告知用户这篇文章以后可能被证明是假的。这可以有助于限制传播虚假信息的传播，从而减少对个人、社区和社会的危害。</li><li>科学文献中关于谣言检测的研究很少，(Zhao et al., 2015)  是其中一篇解决该问题的著作。他们引入了一种寻找<strong>询问推文</strong>的方法，即寻找那些质疑原帖子可信性的推文，以确定原帖子是否是谣言。如果一条推文与手动管理的正则表达式中的一个匹配，那么它就被认为是一个询问推文。这种方法存在局限性：它依赖于人工定期修改正则表达式列表，因为这些正则表达式可能不适用于新的数据集；它假设询问推文出现，但并不是所有的谣言都一定会引发查询，这可能导致低召回率；它没有考虑到相关环境，我们可以利用环境来了解该信息是如何产生的。</li><li>论文定义谣言检测任务的目标为识别<strong>尚未被验证的信息片段</strong>，并从非谣言中区分它们。主要贡献有：<ul><li>描述了一种用于收集和注释Twitter数据集的新方法，该数据集包含各种各样的谣言和非谣言。我们的方法是一种自底向上的方法，通过与突发新闻报道相关的推特时间轴来注释谣言。</li><li>基于<strong>CRF</strong>来学习突发新闻的动态信息，这使我们能够利用上下文学习背景知识以分类谣言信息，这一过程仅根据推文的内容来判断是否是谣言。</li><li>研究了<strong>CRF</strong>作为序列分类器在五个突发新闻的推特数据集上的检测谣言性能，将CRF的性能与其他分类器比较。实验表明，CRF有实质性的改善。</li></ul></li></ul><h2 id="Definition-of-Rumour"><a href="#Definition-of-Rumour" class="headerlink" title="Definition of Rumour"></a>Definition of Rumour</h2><ul><li>谣言的定义：<em>circulating story of questionable veracity, which is apparently credible but hard to verify, and produces sufficient skepticism and/or anxiety so as to motivate finding out the actual truth.</em>  </li></ul><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><ul><li><p>论文通过模拟用户跟踪与突发新闻相关的报告的场景来收集数据，其中包括谣言和非谣言。我们的数据收集方法从Twitter流API中收集可能会引发谣言发起与传播的新闻事件相关的tweet，一旦记者告知有新闻价值的事件发生，就跟踪与该事件相关的主要标签和关键字来收集数据，随后记者通过查看关于突发新闻tweet的时间轴，将每条tweet进行注释，标志谣言或非谣言。标注采用的系统如下</p><p><img src="/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:100%;"></p></li><li><p>数据集的五个事件：</p><ul><li><em>Ferguson unrest: citizens of Ferguson in Michigan, USA, protested after the fatal shooting of an 18-year-old African American, Michael Brown, by a white police officer on August 9, 2014.</em></li><li><em>Ottawa shooting: shootings occurred on Ottawas Parliament Hill in Canada, resulting in the death of a Canadian soldier on October 22, 2014.</em></li><li><em>Sydney siege: a gunman held hostage ten customers and eight employees of a Lindt chocolate caf located at Martin Place in Sydney, Australia, on December 15, 2014.</em>  </li><li><em>Charlie Hebdo shooting: two brothers forced their way into the offices of the French satirical weekly newspaper Charlie Hebdo in Paris, killing 11 people and wounding 11 more, on January 7, 2015.</em></li><li><em>Germanwings plane crash: a passenger plane from Barcelona to Dsseldorf crashed in the French Alps on March 24, 2015, killing all passengers and crew. The plane was ultimately found to have been deliberately crashed by the co-pilot of the plane.</em>  </li></ul></li><li><p>考虑到数据集的大小，通过挑选引发大量转发的推文进行采样，转发阈值根据结果数据集的大小选择。对于样本子集中的每一条推文，同样收集所有回复它们的推文，对话收集脚本可在<a href="https://github.com/azubiaga/phemetwitter-conversation-collection上获得。使用回复推文有两个目的：在人工注释工作，回复推文可以为判断谣言与否提供帮助；而我们需要采用(Zhao">https://github.com/azubiaga/phemetwitter-conversation-collection上获得。使用回复推文有两个目的：在人工注释工作，回复推文可以为判断谣言与否提供帮助；而我们需要采用(Zhao</a> et al., 2015) <strong>询问推文</strong>的方法来作为实验的baseline。</p></li><li><p>各数据集的具体谣言与非谣言数目如Table 1。</p><p><img src="/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:100%;"></p><p>谣言数目随时间轴的变化（分为10段）如下图，</p><p><img src="/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:100%;"></p><p>可以看到并没有明显的规律性。</p></li><li></li></ul><h2 id="Rumour-Detection-Task"><a href="#Rumour-Detection-Task" class="headerlink" title="Rumour Detection Task"></a>Rumour Detection Task</h2><ul><li>该任务以推文的演进时间线$T_L=\{t_1,t_2,\dots,t_{|TL|}\}$作为输入，分类器通过分配标签$Y=\{R,NR\}$来确定这些tweet是谣言还是非谣言，因此任务变成二分类问题。</li><li></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rumour Detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Adaptive Learned Bloom Filter (Ada-BF) Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web》笔记</title>
    <link href="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Adaptive-Learned-Bloom-Filter"><a href="#Adaptive-Learned-Bloom-Filter" class="headerlink" title="Adaptive Learned Bloom Filter"></a>Adaptive Learned Bloom Filter</h1><ul><li>论文：<a href="https://par.nsf.gov/servlets/purl/10217248">https://par.nsf.gov/servlets/purl/10217248</a></li></ul><h2 id="Learned-Bloom-filter"><a href="#Learned-Bloom-filter" class="headerlink" title="　Learned Bloom filter"></a>　Learned Bloom filter</h2><ul><li><em>Learned Bloom filter</em> (LBF) 在<em>Bloom filter</em>之前增加了机器学习模型作为预过滤器，对于每个查询的元素$x$，给出得分$s(x)$，$s(x)$通常与$x\in S$的概率正相关。分类器先在一些可用的训练数据上进行预训练，根据其训练数据的特征对给定查询$x\in S$进行判断（二分类）。LBF设置阈值$\tau$，当$s(x)\geq \tau$时则判断$x\in S$，否则便使用<em>Bloom filter</em>进行进一步的判断。就像<em>standard Bloom filter</em>，LBF的<em>false negative rate</em>（FNR）为0。而<em>false positive rate</em>（FPR）可以由分类模型与<em>Bloom filter</em>的误报引起。</li><li>可以看出，当区域$s(x)≥τ$包含更多的$x$时，插入<em>Bloom filter</em>的关键字数会减少，从而导致良好的FPR。由于区域$s(x)≥τ$为正值，为了保证预过滤器判断正确，所以$τ$值越高越好，但$\tau$的增大会增加<em>Bloom filter</em>的负载。因此需要找到两者的平衡。</li></ul><h3 id="Wastage-of-Information"><a href="#Wastage-of-Information" class="headerlink" title="Wastage of Information"></a>Wastage of Information</h3><ul><li>当$s(x)&lt;\tau$时，采用<em>Bloom filter</em>进行查询判断，此时$s(x)$中的信息并没有得到使用。例如，当有两个元素$x_1,x_2$，并且$\tau&gt;s(x_1)\gg s(x_2)$。在使用LBF时，两者会采用相同方法进行判断，而直观来看，$x_1$比$x_2$更有可能属于$S$。</li></ul><h3 id="Strong-dependency-on-Generalization"><a href="#Strong-dependency-on-Generalization" class="headerlink" title="Strong dependency on Generalization"></a>Strong dependency on Generalization</h3><ul><li>由原理可知，当数据分布没有变化时，预过滤器更高的准确率可以降低FPR。但是，在部署了<em>Bloom filters</em>的在线环境中，数据分布可能会发生变化。众所周知，数据流具有分布上有漂移的突发性质。因此，分类器的置信度以及阈值并不是完全可靠的。其次，机器学习对特殊例子的敏感性给系统带来了新的问题，对于任何给定置信水平$τ$的分类器，可以很容易地创建被错误分类的示例。<em>Bloom filter</em>通常用于增加对抗性误报率的网络中，这可能会损害性能。由于冲突而增加的延迟可能会引发<em>Denial-of-Service attacks</em>(DoS)。</li></ul><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>对于一个分类器，分布密度$f(s(x))$在集合内和集合外的元素呈现不同的趋势。观察到，对于键，$f(s(x)|x \in S)$随着$s(x)$的增加呈现上升趋势，而$f(s(x)|x \notin S)$呈现相反的趋势。为了减少整体FPR，$f(s(x)|x \notin S)$高的组需要更低的FPRs。因此，如果用不同的方式调整哈希函数的数量，相应的组需要更多的哈希函数，而对于有几个非键的组允许更高的FPRs。</li></ul><h2 id="Adaptive-Learned-Bloom-Filter-Ada-BF"><a href="#Adaptive-Learned-Bloom-Filter-Ada-BF" class="headerlink" title="Adaptive Learned Bloom Filter (Ada-BF)"></a>Adaptive Learned Bloom Filter (Ada-BF)</h2><ul><li><p>上一节中LBF的公式，LBF实际上将$x$分成了两组。当$s(x)≥τ$时，$x$将被直接识别为集合中的元素，而不需要使用<em>Bloom filter</em>测试。换句话说，它先使用零哈希函数来标识资格。否则，将使用$K$哈希函数测试，则通过$s(x)≥τ$判断从$0$哈希函数到$K$哈希函数的条件。Ada-BF根据$s(x)$将$x$分为$g$个组，对于组$j$，采用$K_j$个哈希函数来判断它的资格。Ada-BF的结构如Figure 1(b)所示。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:100%;"></p></li><li><p>Ada-BF将$s(x)$分为$g$组，其中$x\in \text{Group}\ j$，$s(x)\in[\tau_{j-1};\tau_j), j = 1,2,···,g$，设$0 = τ_0 &lt; τ_1 &lt;···&lt; τ_{g−1} &lt; τ_g = 1$，来自组$j$的关键字使用$K_j$个独立的哈希函数插入到<em>Bloom filter</em>中。对于$j$组，FPR的期望值可表示为</p><script type="math/tex; mode=display">\mathbb{E}\left(\mathrm{FPR}_{j}\right)=\left(1-\left(1-\frac{1}{R}\right)^{\sum_{t=1}^{g} n_{t} K_{t}}\right)^{K_{j}}=\alpha^{K_{j}}</script><p>其中$n_{t}=\sum_{t=1}^{n} I\left(\tau_{t-1} \leq s\left(x_{i} \mid x_{i} \in S\right)&lt;\tau_{t}\right)$落在$\text{group}\ t$的关键字数。为了避免比特数组的过载，我们只在键数$n_j$较多的组中增加$K_j$，而在键数$n_j$较少的组中减少$K_j$。很明显，Ada-BF对LBF进行了推广。当Ada-BF只通过将查询分成两组时$K_1 = K, K_2 = 0， τ_1 = τ$， Ada-BF降为LBF。</p><p>值得注意的是，随着$s(x)$的增加，$f(s(x)|x\in S)$与$f(s(x)|x\notin S)$的趋势相反(Figure 2)。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:100%;"></p></li></ul><h3 id="Simplifying-the-Hyper-Parameters"><a href="#Simplifying-the-Hyper-Parameters" class="headerlink" title="Simplifying the Hyper-Parameters"></a>Simplifying the Hyper-Parameters</h3><ul><li><p>为了实现Ada-BF，需要确定$2g-1$个超参数，包括每组的哈希函数数量$K_j$和分组的评分阈值$τ_j (τ_0 = 0， τ_g = 1)$。使用这些超参数，对于Ada-BF，总体FPR的期望值可以表示为:</p><script type="math/tex; mode=display">\mathbb{E}(\mathrm{FPR})=\sum_{j=1}^{g} p_{j} \mathbb{E}\left(\mathrm{FPR}_{j}\right)=\sum_{j=1}^{g} p_{j} \alpha^{K_{j}}</script><p>其中$p_{j}=\operatorname{Pr}\left(\tau_{j-1} \leq s\left(x_{i} \mid x_{i} \notin S\right)&lt;\tau_{j}\right)$，$<br>p_{j}$可以用$\hat{p}_{j}=\frac{1}{m} \sum_{i=1}^{m} I\left(\tau_{j-1} \leq s\left(x_{i} \mid x_{i} \notin S\right)&lt;\tau_{j}\right)=\frac{m_{j}}{m}$表示($m$为训练数据中非键的数量，$m_j$为$j$组中非键的数量)。由于$\sum_{j=1}^{g} m_{j} \alpha^{K_{j}}=O\left(\max _{j}\left(m_{j} \alpha^{K_{j}}\right)\right)$，可以考虑使用$m_{j} \alpha^{K_{j}}$来近似。而$\alpha^{K_{j}}$随着$K_j$的增大呈指数级下降，为了保持$m_j\alpha^{K_{j}}$在不同组中的稳定，我们需要$m_j$随着$K_j$呈指数级增长。此外，由于$f(s(x)|x\notin S)$在大多数情况下随着$s(x)$变小而增大，所以对于较小的$s(x)$， $K_j$也应该变大，当$j$减少时，我们应该线性增加$K_j$，让$m_j$指数增长。</p></li><li><p>根据以上观点，设置$\frac{p_j}{p_{j+1}}=c$和$K_j-K_{j+1}=1$，其中$j=1,2,\cdots,g-1$，因为$s(x|x\notin S)$的真实密度是未知的，用$\hat{\frac{p_j}{p_{j+1}}}=\frac{m_j}{m_{j+1}}=c$来估计$\frac{p_j}{p_{j+1}}$，该策略确保了$\hat{p}_j$与$K_j$的指数级增长。现在只有三个超参数，$c,K_{min},K_{max}(K_{max}=K_1)$。默认情况下设置$K_{min} = K_{g} = 0$，等价于将$g$组中的所有项目标识为键。</p></li></ul><h3 id="Analysis-of-Adaptive-Learned-Bloom-Filter"><a href="#Analysis-of-Adaptive-Learned-Bloom-Filter" class="headerlink" title="Analysis of Adaptive Learned Bloom Filter"></a>Analysis of Adaptive Learned Bloom Filter</h3><ul><li><p>与LBF相比，Ada-BF充分利用密度分布$s(x)$，对不同区间的FPR进行优化，而且Ada-BF可以在不增加内存使用的情况下降低LBF的FPR。</p><p>当$p_j/p_{j+1}=c_j\geq c &gt; 1$，$K_j-K_{j+1}= 1$时，预期的FPR如下</p></li></ul><script type="math/tex; mode=display">  \mathbb{E}(\mathrm{FPR})=\sum_{j=1}^{g} p_{j} \alpha^{K_{j}}=\frac{\sum_{j=1}^{g} c^{g-j} \alpha^{K_{j}}}{\sum_{j=1}^{g} c^{g-j}} \leq\left\{\begin{array}{ll}  \frac{(1-c)\left(1-(c \alpha)^{g}\right)}{\left(\frac{1}{\alpha}-c\right)\left(\alpha^{g}-(c \alpha)^{g}\right)} \alpha^{K_{\max }}, & c \alpha \neq 1 \\  \frac{1-c}{1-c^{g}} \cdot g, & c \alpha=1  \end{array}\right.</script><p>  其中$K_{max} = K_1$。为了方便分析，设$cα &gt; 1$。假设$g$组的数目是固定的，提高$c$就可以满足这以上条件，而$α$会随着$c$的增大而增大。为了比较，需要LBF的$τ$等于Ada-BF的$\tau_{g-1}$，在这种情况下，分数高于$τ$的查询会被机器学习模型直接判断为键。比较整体的FPR便只需要比较得分低于$τ$的查询的FPR。</p><ul><li><p><strong>Theorem 1</strong>：对于Ada-BF，对于所有的$j\in[g-1],$给定$\frac{p_j}{p_{j+1}}\geq c &gt;1$，如果存在$λ &gt; 0$使$cα≥1+λ$成立，并且对于所有的$j\in[g-1],$$n_{j+1}−n_j &gt; 0$($n_j$是$j$组的键数)。当$g$足够大且$g≤\lfloor2K\rfloor$时(K是LBF哈希函数的个数)，Ada-BF的FPR小于LBF。</p></li><li><p>Theorem 1要求$n_j$的键数不断增加，而$p_j$随着$j$呈指数级下降。如图2所示，在真实数据集上，随着分数的增加，$f(s(x)|x\notin S)$下降得非常快，而$f(s(x)|x \in S)$增加，能够满足定理的条件。</p></li></ul><h2 id="Disjoint-Adaptive-Learned-Bloom-Filter-Disjoint-Ada-BF"><a href="#Disjoint-Adaptive-Learned-Bloom-Filter-Disjoint-Ada-BF" class="headerlink" title="Disjoint Adaptive Learned Bloom Filter (Disjoint Ada-BF)"></a>Disjoint Adaptive Learned Bloom Filter (Disjoint Ada-BF)</h2><ul><li><p>Ada-BF根据键的分数将键分成$g$组，并使用不同数量的哈希函数将键散列到同一个<em>Bloom Filter</em>中。基于类似的想法，disjoint Ada-BF也将键分成$g$组，但是将不同组的键散列到独立的<em>Bloom Filter</em>中。disjoint Ada-BF的结构如图1(c)所示。</p><p>假设<em>Bloom Filter</em>的总预算为$R$位，键被分成$g$组。因此，来自组$j$的键被插入到长度为$R_j (R = \sum_{j=1}^g R_j)$的<em>Bloom filter</em>。在查找阶段，需要确定查询所属的组并检查其在对应Bloom Filter中的成员关系。</p></li></ul><h3 id="Simplifying-the-Hyper-Parameters-1"><a href="#Simplifying-the-Hyper-Parameters-1" class="headerlink" title="Simplifying the Hyper-Parameters"></a>Simplifying the Hyper-Parameters</h3><ul><li>与Ada-BF类似，disjoint Ada-BF也有需要设置的超参数，例如组分割的分数阈值$τ_j$和<em>Bloom Filter</em>的长度$R_j$。阈值$τ_j$的确定与上一节类似。为了找到优化整体FPR的$R_j$，我们再次引用上一节的思想，即不同组的<em>false postivives</em>预期应该是相似的。对于具有$Rj$位的<em>Bloom filter</em>，最优哈希函数数量可以近似为$K_j=\frac{R_j}{n_j}\text{log(2)}$，其中$n_j$是组$j$中的键数。对应的最优FPR的期望为$\mathbb{E}\left(\mathrm{FPR}_{j}\right)=\mu^{R_{j} / n_{j}}(\mu \approx 0.618)$，因此，为了使不同组的<em>false postivives</em>预期相似，$R_j$需要满足<script type="math/tex; mode=display">m_{j} \cdot \mu^{\frac{R_{j}}{n_{j}}}=m_{1} \cdot \mu^{\frac{R_{1}}{n_{1}}} \Longleftrightarrow \frac{R_{j}}{n_{j}}-\frac{R_{1}}{n_{1}}=\frac{(j-1) \log (c)}{\log (\mu)}</script>在已知阈值$τ_j$的前提下，$n_j$是已知的，并且桶的总预算$R$是已知的，因此可以求解$R_j$。</li></ul><h3 id="Analysis-of-Disjoint-Adaptive-Learned-Bloom-Filter"><a href="#Analysis-of-Disjoint-Adaptive-Learned-Bloom-Filter" class="headerlink" title="Analysis of Disjoint Adaptive Learned Bloom Filter"></a>Analysis of Disjoint Adaptive Learned Bloom Filter</h3><ul><li>Disjoint Ada-BF使用一组较短的<em>Bloom Filter</em>来存储键的哈希输出。核心思想与Ada-BF相同，都是通过减少组的FPR来降低整体的FPR。Disjoint Ada-BF为每组分配<em>Bloom Filter</em>，以实现更小的FPR。在下面的定理中，证明在达到LBF的最优预期FPR时，Disjoint Ada-BF消耗更少的桶。</li><li><strong>Theorem 2：</strong>对于所有的$j\in[g-1]$($n_j$是组$j$的键数)，如果$\frac{p_j}{p_{j+1}}=c&gt;1$和$n_{j+1}−n_j &gt; 0$，为了实现LBF的最优FPR，当$g$较大时，Disjoint Ada-BF消耗的桶数比LBF少。</li></ul><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><ul><li><p>论文测试现有几种Bloom filter算法的性能:1)standard Bloom filter，2)learned Bloom filter，3)sandwiched learned Bloom filter  ，4)adaptive learned Bloom filter  ，5)disjoint adaptive learned Bloom filter。使用两个具有不同关联任务的数据集，即恶意url检测和病毒扫描，通过它们的FPRs和相应的内存使用来衡量性能。作者在<a href="https://github.com/DAIZHENWEI/Ada-BF">https://github.com/DAIZHENWEI/Ada-BF</a> 上开源了自己的代码与数据集。</p></li><li><p>url数据集一共有三列（url，label，score），分别为需要检测的url，标签与预先训练的随机森林模型对应得分$\text{score}(x)$(采用“sklearn.ensemble.RandomForestClassifier“)。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:50%;"></p><p>病毒扫描数据集一共有三列（label，score，MD5），分别为标签、预先训练的随机森林模型对应得分$\text{score}(x)$(采用“sklearn.ensemble.RandomForestClassifier“)与文件的MD5签名。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig4.png" style="zoom:50%;"></p></li><li><p>实验的相关设置可参考原论文，最终结果如下。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig5.png" style="zoom:100%;"></p></li></ul><h2 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h2><p>以下为论文代码实现的相关说明与注释，包括Bloom_filter、learned_Bloom_filter、Ada-BF、disjoint_Ada-BF四种。</p><h3 id="Bloom-filter"><a href="#Bloom-filter" class="headerlink" title="Bloom_filter"></a>Bloom_filter</h3><ul><li><p>首先采用<code>sklearn.utils.murmurhash3_32</code>函数作为<em>Bloom filter</em>中的哈希函数，根据key值得到32位的哈希值，对<em>Bloom filter</em>的大小$m$取余则得到$[0,m-1]$范围的值作为下标索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hashfunc</span>(<span class="hljs-params">m</span>):</span><br>    ss = randint(<span class="hljs-number">1</span>, <span class="hljs-number">99999999</span>)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hash_m</span>(<span class="hljs-params">x</span>):</span><br>        <span class="hljs-keyword">return</span> murmurhash3_32(x,seed=ss)%m<br>    <span class="hljs-keyword">return</span> hash_m<br></code></pre></td></tr></table></figure></li><li><p>Standard Bloom filter的类初始化方式如下，根据推导公式$k=ln\ 2\ \cdot\ (m/n)$得到最优$k$值，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BloomFilter</span>():</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, n, hash_len</span>):</span><br>        self.n = n<br>        self.hash_len = <span class="hljs-built_in">int</span>(hash_len)<br>        <span class="hljs-keyword">if</span> (self.hash_len == <span class="hljs-number">0</span>):<br>            <span class="hljs-keyword">raise</span> SyntaxError(<span class="hljs-string">&#x27;The hash table is empty&#x27;</span>)<br>        <span class="hljs-comment"># 根据推导公式得到最优k值</span><br>        <span class="hljs-keyword">if</span> (self.n &gt; <span class="hljs-number">0</span>) &amp; (self.hash_len &gt; <span class="hljs-number">0</span>):<br>            self.k = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">int</span>(self.hash_len/n*<span class="hljs-number">0.6931472</span>))<br>        <span class="hljs-keyword">elif</span> (self.n==<span class="hljs-number">0</span>):<br>            self.k = <span class="hljs-number">1</span><br>        <span class="hljs-comment"># 创建k个哈希函数</span><br>        self.h = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>            self.h.append(hashfunc(self.hash_len))<br>        <span class="hljs-comment"># 初始化“位数组”</span><br>        self.table = np.zeros(self.hash_len, dtype=<span class="hljs-built_in">int</span>)<br></code></pre></td></tr></table></figure><p>插入时进行$k$次哈希映射，将位数组中对应位置$1$，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">insert</span>(<span class="hljs-params">self, key</span>):</span><br>    <span class="hljs-keyword">if</span> self.hash_len == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">raise</span> SyntaxError(<span class="hljs-string">&#x27;cannot insert to an empty hash table&#x27;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> key:<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>            t = self.h[j](i)<br>            self.table[t] = <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>检测时，同样进行$k$次哈希映射，判断对应位是否都为$1$，返回结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test</span>(<span class="hljs-params">self, keys, single_key = <span class="hljs-literal">True</span></span>):</span><br>    <span class="hljs-keyword">if</span> single_key:<br>        test_result = <span class="hljs-number">0</span><br>        match = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> self.hash_len &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>                t = self.h[j](keys)<br>                match += <span class="hljs-number">1</span> * (self.table[t] == <span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">if</span> match == self.k:<br>                test_result = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        test_result = np.zeros(<span class="hljs-built_in">len</span>(keys))<br>        ss=<span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> self.hash_len &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> keys:<br>                match = <span class="hljs-number">0</span><br>                <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>                    t = self.h[j](key)<br>                    match += <span class="hljs-number">1</span>*(self.table[t] == <span class="hljs-number">1</span>)<br>                <span class="hljs-keyword">if</span> match == self.k:<br>                    test_result[ss] = <span class="hljs-number">1</span><br>                ss += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> test_result<br></code></pre></td></tr></table></figure></li><li><p>使用  <code>python Bloom_filter.py --data_path ./Datasets/URL_data.csv --size_of_BF 200000</code>运行代码，url任务对应main函数如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--data_path&#x27;</span>, action=<span class="hljs-string">&quot;store&quot;</span>, dest=<span class="hljs-string">&quot;data_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>,<br>                        <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;path of the dataset&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--size_of_BF&#x27;</span>, action=<span class="hljs-string">&quot;store&quot;</span>, dest=<span class="hljs-string">&quot;R_sum&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, required=<span class="hljs-literal">True</span>,<br>                        <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;size of the BF&quot;</span>)<br>    <br>    <span class="hljs-comment"># 数据集路径与位数组大小</span><br>    results = parser.parse_args()<br>    DATA_PATH = results.data_path<br>    R_sum = results.R_sum<br><br>    data = pd.read_csv(DATA_PATH)<br><br>    negative_sample = data.loc[(data[<span class="hljs-string">&#x27;label&#x27;</span>] == -<span class="hljs-number">1</span>)]<br>    positive_sample = data.loc[(data[<span class="hljs-string">&#x27;label&#x27;</span>] == <span class="hljs-number">1</span>)]<br><br>    <span class="hljs-comment"># 对所有正样例进行插入</span><br>    query = positive_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>    n = <span class="hljs-built_in">len</span>(query)<br>    bloom_filter = BloomFilter(n, R_sum)<br>    bloom_filter.insert(query)<br>    query_negative = negative_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>    <br>    <span class="hljs-comment"># 对所有负样例进行检测，得到结果</span><br>    n1 = bloom_filter.test(query_negative, single_key=<span class="hljs-literal">False</span>)<br>    print(<span class="hljs-string">&#x27;False positive items: &#x27;</span>, <span class="hljs-built_in">sum</span>(n1))<br>    print(<span class="hljs-string">&#x27;FPR:&#x27;</span>, <span class="hljs-built_in">sum</span>(n1)/<span class="hljs-built_in">len</span>(negative_sample))<br></code></pre></td></tr></table></figure></li></ul><h3 id="learned-Bloom-filter"><a href="#learned-Bloom-filter" class="headerlink" title="learned_Bloom_filter"></a>learned_Bloom_filter</h3><ul><li><p>由于数据中已经有了预先训练的随机森林模型对应得分，因此需要确定最优的$\tau$，以url任务为例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># train_negative为30%抽样得到的负样例</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Find_Optimal_Parameters</span>(<span class="hljs-params">max_thres, min_thres, R_sum, train_negative, positive_sample</span>):</span><br>    FP_opt = train_negative.shape[<span class="hljs-number">0</span>]<br>    <br>    <span class="hljs-comment"># 从最小值到最大值遍历计算确定最优值</span><br>    <span class="hljs-keyword">for</span> threshold <span class="hljs-keyword">in</span> np.arange(min_thres, max_thres+<span class="hljs-number">10</span>**(-<span class="hljs-number">6</span>), <span class="hljs-number">0.01</span>):<br>        <span class="hljs-comment"># 根据阈值得到插入Bloomfilter的样例</span><br>        query = positive_sample.loc[(positive_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        n = <span class="hljs-built_in">len</span>(query)<br>        bloom_filter = BloomFilter(n, R_sum)<br>        bloom_filter.insert(query)<br>        <span class="hljs-comment"># 分类器分类错误的样例</span><br>        ML_positive = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &gt; threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        <span class="hljs-comment"># Bloomfilter检测错误的样例</span><br>        bloom_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        BF_positive = bloom_filter.test(bloom_negative, single_key=<span class="hljs-literal">False</span>)<br>        <span class="hljs-comment"># False Positive</span><br>        FP_items = <span class="hljs-built_in">sum</span>(BF_positive) + <span class="hljs-built_in">len</span>(ML_positive)<br>        print(<span class="hljs-string">&#x27;Threshold: %f, False positive items: %d&#x27;</span> %(<span class="hljs-built_in">round</span>(threshold, <span class="hljs-number">2</span>), FP_items))<br>        <span class="hljs-comment"># 保存最优的阈值与对应Bloomfilter</span><br>        <span class="hljs-keyword">if</span> FP_opt &gt; FP_items:<br>            FP_opt = FP_items<br>            thres_opt = threshold<br>            bloom_filter_opt = bloom_filter<br>    <span class="hljs-keyword">return</span> bloom_filter_opt, thres_opt<br></code></pre></td></tr></table></figure><p>获得最优的$\tau$后，在整个负样例上进行检测，得到最终的FPR。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-string">&#x27;&#x27;&#x27;Stage 1: Find the hyper-parameters (spare 30% samples to find the parameters)&#x27;&#x27;&#x27;</span><br>    bloom_filter_opt, thres_opt = Find_Optimal_Parameters(max_thres, min_thres, R_sum, train_negative, positive_sample)<br><br>    <span class="hljs-string">&#x27;&#x27;&#x27;Stage 2: Run LBF on all the samples&#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment">### Test queries</span><br>    ML_positive = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &gt; thres_opt), <span class="hljs-string">&#x27;url&#x27;</span>]<br>    bloom_negative = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thres_opt), <span class="hljs-string">&#x27;url&#x27;</span>]<br>    score_negative = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thres_opt), <span class="hljs-string">&#x27;score&#x27;</span>]<br>    BF_positive = bloom_filter_opt.test(bloom_negative, single_key = <span class="hljs-literal">False</span>)<br>    FP_items = <span class="hljs-built_in">sum</span>(BF_positive) + <span class="hljs-built_in">len</span>(ML_positive)<br>    FPR = FP_items/<span class="hljs-built_in">len</span>(negative_sample)<br>    print(<span class="hljs-string">&#x27;False positive items: &#123;&#125;; FPR: &#123;&#125;; Size of quries: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(FP_items, FPR, <span class="hljs-built_in">len</span>(negative_sample)))<br></code></pre></td></tr></table></figure></li></ul><h3 id="Ada-BF"><a href="#Ada-BF" class="headerlink" title="Ada-BF"></a>Ada-BF</h3><ul><li><p>Ada-BF中Bloom_filter与原始Bloom_filter的差别在于哈希函数的个数，由于$K_j-K_{j+1}=1$，且$K_g=0$，则$K_{max}$与划分的组数有关，因此Ada-BF需要根据组数进行哈希函数数量的修改，在检测时需要根据$k$值进行$k$次映射。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Ada_BloomFilter</span>():</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, n, hash_len, k_max</span>):</span><br>        self.n = n<br>        self.hash_len = <span class="hljs-built_in">int</span>(hash_len)<br>        self.h = []<br>        <span class="hljs-comment"># 创建k_max个哈希函数</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k_max)):<br>            self.h.append(hashfunc(self.hash_len))<br>        self.table = np.zeros(self.hash_len, dtype=<span class="hljs-built_in">int</span>)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">insert</span>(<span class="hljs-params">self, key, k</span>):</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k)):<br>            t = self.h[j](key)<br>            self.table[t] = <span class="hljs-number">1</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test</span>(<span class="hljs-params">self, key, k</span>):</span><br>        test_result = <span class="hljs-number">0</span><br>        match = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k)):<br>            t = self.h[j](key)<br>            match += <span class="hljs-number">1</span>*(self.table[t] == <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> match == k:<br>            test_result = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> test_result<br></code></pre></td></tr></table></figure><p>根据上面的分析，需要确定的最优参数有组数$g$与$\hat{\frac{p_j}{p_{j+1}}}=\frac{m_j}{m_{j+1}}=c$，同样采用从最小值到最大值遍历并保存最优值的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Find_Optimal_Parameters</span>(<span class="hljs-params">c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample</span>):</span><br>    <span class="hljs-comment"># c_min到c_max寻找最优值</span><br>    c_set = np.arange(c_min, c_max+<span class="hljs-number">10</span>**(-<span class="hljs-number">6</span>), <span class="hljs-number">0.1</span>)<br>    FP_opt = train_negative.shape[<span class="hljs-number">0</span>]<br><br>    k_min = <span class="hljs-number">0</span><br>    <span class="hljs-comment"># k_max 与组数有关</span><br>    <span class="hljs-keyword">for</span> k_max <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_group_min, num_group_max+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> c_set:<br>            <span class="hljs-comment"># tau = sum([c**0, c**1,...]) 则各划分区间的最小单位</span><br>            tau = <span class="hljs-built_in">sum</span>(c ** np.arange(<span class="hljs-number">0</span>, k_max - k_min + <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>            n = positive_sample.shape[<span class="hljs-number">0</span>]<br>            hash_len = R_sum<br>            bloom_filter = Ada_BloomFilter(n, hash_len, k_max)<br>            thresholds = np.zeros(k_max - k_min + <span class="hljs-number">1</span>)<br>            thresholds[-<span class="hljs-number">1</span>] = <span class="hljs-number">1.1</span><br>            <span class="hljs-comment"># 抽样后的负样例总数</span><br>            num_negative = <span class="hljs-built_in">sum</span>(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thresholds[-<span class="hljs-number">1</span>])<br>            <span class="hljs-comment"># 按比例分成碎片，一共tau个碎片</span><br>            num_piece = <span class="hljs-built_in">int</span>(num_negative / tau) + <span class="hljs-number">1</span><br>            <br>            score = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thresholds[-<span class="hljs-number">1</span>]), <span class="hljs-string">&#x27;score&#x27;</span>]<br>            score = np.sort(score)<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k_min, k_max):<br>                i = k - k_min<br>                score_1 = score[score &lt; thresholds[-(i + <span class="hljs-number">1</span>)]]<br>                <span class="hljs-comment"># 从后往前计算区间划分阈值 根据m_j/m_&#123;j+1&#125; = c并且剩下样例足够划分</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>(num_piece * c ** i) &lt; <span class="hljs-built_in">len</span>(score_1):<br>                    thresholds[-(i + <span class="hljs-number">2</span>)] = score_1[-<span class="hljs-built_in">int</span>(num_piece * c ** i)]<br><br>            query = positive_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>            score = positive_sample[<span class="hljs-string">&#x27;score&#x27;</span>]<br>            <br>            <span class="hljs-comment"># 插入数据</span><br>            <span class="hljs-keyword">for</span> score_s, query_s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(score, query):<br>                ix = <span class="hljs-built_in">min</span>(np.where(score_s &lt; thresholds)[<span class="hljs-number">0</span>])<br>                k = k_max - ix<br>                bloom_filter.insert(query_s, k)<br>            <span class="hljs-comment"># 进行FPR估计</span><br>            ML_positive = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &gt;= thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;url&#x27;</span>]<br>            query_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;url&#x27;</span>]<br>            score_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;score&#x27;</span>]<br><br>            <span class="hljs-comment"># 进行检测</span><br>            test_result = np.zeros(<span class="hljs-built_in">len</span>(query_negative))<br>            ss = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> score_s, query_s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(score_negative, query_negative):<br>                ix = <span class="hljs-built_in">min</span>(np.where(score_s &lt; thresholds)[<span class="hljs-number">0</span>])<br>                <span class="hljs-comment"># thres = thresholds[ix]</span><br>                k = k_max - ix<br>                test_result[ss] = bloom_filter.test(query_s, k)<br>                ss += <span class="hljs-number">1</span><br>            FP_items = <span class="hljs-built_in">sum</span>(test_result) + <span class="hljs-built_in">len</span>(ML_positive)<br>            print(<span class="hljs-string">&#x27;False positive items: %d, Number of groups: %d, c = %f&#x27;</span> %(FP_items, k_max, <span class="hljs-built_in">round</span>(c, <span class="hljs-number">2</span>)))<br>            <span class="hljs-comment"># 保存最优结果</span><br>            <span class="hljs-keyword">if</span> FP_opt &gt; FP_items:<br>                FP_opt = FP_items<br>                bloom_filter_opt = bloom_filter<br>                thresholds_opt = thresholds<br>                k_max_opt = k_max<br><br>    <span class="hljs-comment"># print(&#x27;Optimal FPs: %f, Optimal c: %f, Optimal num_group: %d&#x27; % (FP_opt, c_opt, num_group_opt))</span><br>    <span class="hljs-keyword">return</span> bloom_filter_opt, thresholds_opt, k_max_opt<br></code></pre></td></tr></table></figure><p>得到最优参数后在整个测试集上做检测，得到最终FPR。</p></li></ul><h3 id="disjoint-Ada-BF"><a href="#disjoint-Ada-BF" class="headerlink" title="disjoint_Ada-BF"></a>disjoint_Ada-BF</h3><ul><li><p>与Ada-BF不同的是，disjoint_Ada-BF需要计算每个组的<em>Bloom filter</em>的位数组大小$R_j$，计算使用的推导公式为</p><script type="math/tex; mode=display">\frac{R_{j}}{n_{j}}-\frac{R_{1}}{n_{1}}=\frac{(j-1) \log (c)}{\log (\mu)}</script><p>由于在划分阈值的时候，各组区间的非键数按$c$指数增长，因此可以用以计算$c^{j-1}$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">R_size</span>(<span class="hljs-params">count_key, count_nonkey, R0</span>):</span><br>    R = [<span class="hljs-number">0</span>]*<span class="hljs-built_in">len</span>(count_key)<br>    R[<span class="hljs-number">0</span>] = <span class="hljs-built_in">max</span>(R0,<span class="hljs-number">1</span>)<br>    <span class="hljs-comment">#　根据推导公式计算R</span><br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(count_key)):<br>        R[k] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">int</span>(count_key[k] * (np.log(count_nonkey[<span class="hljs-number">0</span>]/count_nonkey[k])/np.log(<span class="hljs-number">0.618</span>) + R[<span class="hljs-number">0</span>]/count_key[<span class="hljs-number">0</span>])), <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> R<br></code></pre></td></tr></table></figure><p>根据以上函数，调节$R_0$使得最终得到的$R$数组满足所给定内存，则退出调节。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">### Search the Bloom filters&#x27; size</span><br>R = np.zeros(num_group_1 - <span class="hljs-number">1</span>)<br>R[:] = <span class="hljs-number">0.5</span> * R_sum<br>non_empty_ix = <span class="hljs-built_in">min</span>(np.where(count_key &gt; <span class="hljs-number">0</span>)[<span class="hljs-number">0</span>])<br><span class="hljs-keyword">if</span> non_empty_ix &gt; <span class="hljs-number">0</span>:<br>    R[<span class="hljs-number">0</span>:non_empty_ix] = <span class="hljs-number">0</span><br>kk = <span class="hljs-number">1</span><br><span class="hljs-comment"># 通过调节R_0的大小,使得根据推导公式分配的R满足要求</span><br><span class="hljs-keyword">while</span> <span class="hljs-built_in">abs</span>(<span class="hljs-built_in">sum</span>(R) - R_sum) &gt; <span class="hljs-number">200</span>:<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">sum</span>(R) &gt; R_sum):<br>        R[non_empty_ix] = R[non_empty_ix] - <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        R[non_empty_ix] = R[non_empty_ix] + <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>)<br>    R[non_empty_ix:] = R_size(count_key[non_empty_ix:-<span class="hljs-number">1</span>], count_nonkey[non_empty_ix:-<span class="hljs-number">1</span>], R[non_empty_ix])<br>    <span class="hljs-comment"># 调节大小可以忽略时结束</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>) == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">break</span><br>    kk += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li><li><p>为每个组创建一个<em>Bloom filter</em>，其他操作类似。</p></li></ul><h2 id="Preventing-Misinformation-Spread-over-Social-Media-in-Real-Time"><a href="#Preventing-Misinformation-Spread-over-Social-Media-in-Real-Time" class="headerlink" title="Preventing Misinformation Spread over Social Media in Real-Time"></a>Preventing Misinformation Spread over Social Media in Real-Time</h2><ul><li><p>由于互联网的发展，像Twitter这样的社交媒体几秒内便可在全球范围内传播信息。每天大约有5亿条推文，也就是每秒产生6000 - 10000条推文。Twitter最近报道了一项对其全球分布式索引系统(Twia)的重大改革，该系统使一条推文在一秒钟内就能被全世界看到，而误导内容(或错误信息)也因此会以极快速度在网络上产生并传播。</p></li><li><p>如果已经确定了一个错误信息的来源及其内容，为了防止其在网络快速传播，过滤这些错误信息的系统必须满足几个关键的条件。首先，一旦确定了错误信息的来源及其内容，应该在毫秒内告知全球各地的所有服务器错误信息的相关内容，同时需要保证最小的通讯开销。其次，给定大量生成的信息，需要在没有任何计算开销的情况下正确地清除信息。由于前所未有的数据生成速度，在清除信息的过程中任何计算开销都将导致系统崩溃。这是<em>Bloom filter</em>的经典用例，我们不希望错误信息通过过滤器，并且不会产生任何计算开销。否则，数据生成速率将超过我们的过滤速率。</p></li><li><p><strong>在理想情况下，使用<em>Bloom filter</em>可以压缩错误信息的数据库。每在数据库中中增加一个错误信息，只需要传输几个比特。</strong>只要FPR足够低，系统就不会崩溃。总的来说，FPR非常重要，我们希望每次更新的通信(内存)尽可能少。由于机器学习在自然语言处理方面取得显著的成功，因此有了一个更高性能的LBF，但仅靠机器学习无法保证应用程序所需的零<em>false negative</em>。</p></li><li><p>在<em>Preventing Misinformation Spread over Social Media in Real-Time</em>实验在<a href="https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset?select=Fake.csv">假新闻数据集</a>上进行，该数据集包括23481条假新闻和21417条真新闻，采用的机器学习模型利用<strong>TFIDF</strong>特征训练<strong>朴素贝叶斯分类模型</strong>，并测试不同<em>Learned Bloom filter</em>的FPR。与之前的实验结果相似，Ada-BF和disjoint Ada-BF相比于BF和LBF有明显的优势。在相同的内存预算下，BF和LBF使FPRs降低了70%以上。而Ada-BF和disjoint Ada-BF只需要LBF一半的空间，有效地将通信开销减少了$1 / 2$。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig6.png" style="zoom:44%;"></p></li><li><p>在进一步实验中，除了精确的成员测试外，查询到的新闻是否与数据库中的假新闻高度相似也很重要。然而，<strong>目前的Bloom filter不能处理这个任务</strong>。Kirsch和Mitzenmacher提出了<strong><em>Distance-sensitive bloom filters</em></strong>，这可能是一个可能的解决方案，<em>Learned Bloom filter</em>可以很容易地扩展到<em>Distance-sensitive bloom filters</em>。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Bloom Filter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Network Applications of Bloom Filters：A Survey》笔记</title>
    <link href="/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Bloom-Filter"><a href="#Bloom-Filter" class="headerlink" title="Bloom Filter"></a>Bloom Filter</h1><ul><li><p>论文：<a href="https://www.tandfonline.com/doi/abs/10.1080/15427951.2004.10129096">https://www.tandfonline.com/doi/abs/10.1080/15427951.2004.10129096</a></p></li><li><p><strong>Bloom filter</strong>是一种空间效率高的随机数据结构，采用位数组表示一个集合以提供成员查询。<em>Bllom filter</em>是容许错误判断的，即把不属于这个集合的元素误判断属于这一集合，这样的错误称作<em>false positives</em>。因此<em>Bloom filter</em>不适用于零错误的应用，它通过极低的错误率节省了大量的空间。</p></li><li><strong>The Bloom filter principle:</strong> <em>Wherever a list or set is used, and space is at a premium, consider using a Bloom filter if the effect of false positives can be mitigated.</em> (当空间消耗昂贵而允许false positives时，考虑使用布隆过滤器。)</li></ul><h2 id="Standard-Bloom-Filter"><a href="#Standard-Bloom-Filter" class="headerlink" title="Standard Bloom Filter"></a>Standard Bloom Filter</h2><ul><li><p><em>Bllom Filter</em>采用一个$m$位的位数组来表示包含$n$个元素的集合$S=\{x_1,x_2,\dots,x_n\}$，位数组全初始化为$0$。<em>Bllom Filter</em>使用$k$个相互独立的哈希函数，将集合中的每个元素映射到$\{1,\dots,m\}$的范围中。对于集合中的每一个元素$x\in S$，第$i$个$（1\leq i \leq k）$哈希函数映射的位$h_i(x)$被设置为$1$（不进行重复设置）。</p></li><li><p>在判断$y$是否属于集合$S$时，如果所有$h_i(y)$$（1\leq i \leq k）$的位都已经设置为$1$，那么认为$y\in S$，否则$y \notin S$，因此存在将$y$误判为$S$中元素的情况。</p><p><img src="/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" alt></p></li><li><p><em>Bllom Filter</em>在判断一个元素是否属于它表示的集合时会有一定的错误率（<em>false positive rate</em>）。在很多应用中，只要<em>false positive</em>足够小，则可以接受这样的错误。假设$kn&lt;m$且各个哈希函数是完全随机的，则当$S$中的所有元素被哈希映射到<em>Bloom filter</em>后，某一特定位仍然为$0$的概率为</p><script type="math/tex; mode=display">p^{\prime}=\left(1-\frac{1}{m}\right)^{k n} \approx \mathrm{e}^{-k n / m}.</script><p>其中$1/m$表示任意一个哈希函数选中这一位的概率（前提是哈希函数是完全随机的），则$(1-1/m)$表示哈希一次没有选中这一位的概率。要把$S$完全映射到位数组中，需要做$kn$次哈希。令$p=e^{-kn/m}$，则$p$近似$p’$(在$O(1/m)$内)。</p><p>令$\rho$为位数组中$0$的比例，则$\mathbb{E}(\rho)=p’$。则错误率（<em>false positive rate</em>）为</p><script type="math/tex; mode=display">(1-\rho)^{k} \approx\left(1-p^{\prime}\right)^{k} \approx(1-p)^{k} .</script><p>得到</p><script type="math/tex; mode=display">f^{\prime}=\left(1-\left(1-\frac{1}{m}\right)^{k n}\right)^{k}=\left(1-p^{\prime}\right)^{k}, \\f=\left(1-\mathrm{e}^{-k n / m}\right)^{k}=(1-p)^{k}.</script><p>相比$p’$和$f’$，$p$和$f$更常见于分析中。</p></li><li><p><em>Bllom Filter</em>有另外一种表示方式，则将$m$位位数组平均分给$k$个hash函数，这样每个哈希函数的范围变为$m/k$位。在这种情况下，某一特定位为0的概率为</p><script type="math/tex; mode=display">\left(1-\frac{k}{m}\right)^{n} \approx \mathrm{e}^{-k n / m}.</script><p>近似上看，两者的表现类似。但在$k\geq1$时，</p><script type="math/tex; mode=display">\left(1-\frac{k}{m}\right)^{n} \leq\left(1-\frac{1}{m}\right)^{k n}</script><p>则精确得到第二种表示方式的<em>false positive rate</em>小于或等于第一种，并且将位按哈希函数划分能够实现并行化。</p></li><li><p>对于给定的$m$与$n$，根据<em>Bllom Filter</em>的原理可以知道：使用更多的哈希函数，那么在对一个不属于集合的元素进行查询时得到$0$的概率就大；而减少哈希函数的个数，则会提高位数组中$0$的比重，因此需要找到最合适的哈希函数值。如上得到$f=\exp \left(k \ln \left(1-\mathrm{e}^{-k n / m}\right)\right)$，设$g=k\ ln(1-e^{-kn/m})$，则寻找$f$的最小值等价于寻找$g$的最小值。求导可得</p><script type="math/tex; mode=display">\frac{\partial g}{\partial k}=\ln \left(1-\mathrm{e}^{-\frac{k n}{m}}\right)+\frac{k n}{m} \frac{\mathrm{e}^{-\frac{k n}{m}}}{1-\mathrm{e}^{-\frac{k n}{m}}}</script><p>解得零点$k=ln\ 2\ \cdot\ (m/n)$，该点也是一个全局最优值，对应解得$p=1/2$。在这种情况下，最小错误率$f=(1/2)^k\approx (0.6185)^{m/n}$。同样对于$f’$与$p’$，可以得到当$p’=1/2$时，$g’$取最小值。</p></li></ul><h3 id="A-Lower-Bound"><a href="#A-Lower-Bound" class="headerlink" title="A Lower Bound"></a>A Lower Bound</h3><ul><li>在不超过一定错误率的情况下，<em>Bloom Filter</em>需要设置足够大的$m$才能表示全集中任意$n$个元素的集合。假设全集中共有$u$个元素，允许的最大错误率为$\epsilon$，假设$X$为全集中任取$n$个元素的集合，$F(X)$是表示$X$的位数组。那么对于集合$X$中任意一个元素$x$，在$s = F(X)$中查询$x$都能得到肯定的结果，即$S$能够接受$x$。而<em>Bloom Filter</em>有错误率（<em>false positive rate</em>），对于一个确定的位数组来说，最多接受$n+\epsilon (u-n)$个元素。而一个确定的位数组可以表示$\left(\begin{array}{c}<br>n+\epsilon(u-n) \\<br>n<br>\end{array}\right)$个集合。$m$位的位数组共有$2^m$个不同的组合，全集中共有$\left(\begin{array}{c}<br>u \\<br>n<br>\end{array}\right)$个$n$元素的集合，因此要让$m$位的位数组表示所有$n$个元素的集合，有<script type="math/tex; mode=display">2^{m}\left(\begin{array}{c}n+\epsilon(u-n) \\n\end{array}\right) \geq\left(\begin{array}{l}u \\n\end{array}\right)</script>即<script type="math/tex; mode=display">m \geq \log _{2} \frac{\left(\begin{array}{l}u \\n\end{array}\right)}{\left(\begin{array}{c}n+\epsilon(u-n) \\n\end{array}\right)} \approx \log _{2} \frac{\left(\begin{array}{l}u \\n\end{array}\right)}{\left(\begin{array}{c}\epsilon u \\n\end{array}\right)} \geq \log _{2} \epsilon^{-n}=n \log _{2}(1 / \epsilon)</script>因此，$m$至少要大于$n \log _{2}(1 / \epsilon)$才能使错误率不大于给定的$\epsilon$。根据上节中$f=(1/2)^k=(1/2)^{ln\ 2\ \cdot\ (m/n)}$，令$f\leq \epsilon$得到<script type="math/tex; mode=display">m \geq n \frac{\log _{2}(1 / \epsilon)}{\ln 2}=n \log _{2} \mathrm{e} \cdot \log _{2}(1 / \epsilon).</script>这个结果是我们上面得到的最小值的$log_2e\approx1.44$倍，这说明在哈希函数的个数取到最优时，要让错误率不超过$\epsilon$，$m$至少需要取到最小值的$1.44$倍。</li></ul><h3 id="Hashing-vs-Bloom-Filters"><a href="#Hashing-vs-Bloom-Filters" class="headerlink" title="Hashing vs. Bloom Filters"></a>Hashing vs. Bloom Filters</h3><ul><li>哈希函数是常用的用以表示集合的方式，集合的每个元素都被映射到$\Theta(\text{log}\  n)$位上，然后再用一个哈希值的列表（已排序）表示集合。这种方法产生的错误率很小，如果集合中的每个元素用$2\ \text{log}_2\ n$位来表示，则两个特定的元素映射到相同哈希值的可能性为$1/n^2$，而不在集合中的元素与集合中的元素映射到相同哈希值的概率为$n/n^2=1/n$。</li><li><em>Bloom Filters</em>可以看作哈希的自然推广，它在错误率与采用的位数（空间消耗）中寻找均衡，只有一个哈希函数的<em>Bloom Filters</em>等价于普通的<em>Hashing</em>。<em>Bloom filters</em>产生一个恒定的<em>false positive rate</em>，当用以表示每个集合元素的比特数是恒定的。例如，当$m = 8n$时，<em>false positive rate</em>仅大于0.02。如果需要逐渐消失的错误率，每个元素至少需要采用$\Theta(\text{log}\  n)$位来表示，这也是<em>Bloom Filters</em>不受学术界关注的原因。相反，在实际应用中，为了保持每个元素的位数不变，一个常数错误可能是很有价值的。</li></ul><h3 id="Standard-Bloom-Filter-Tricks"><a href="#Standard-Bloom-Filter-Tricks" class="headerlink" title="　Standard Bloom Filter Tricks"></a>　Standard Bloom Filter Tricks</h3><ul><li><em>Bloom filter</em>的简单结构使得某些操作非常容易实现。假设有两个<em>Bloom filter</em>表示集合$S_1$和$S_2$，它们具有相同的比特数，并且使用相同的哈希函数。则一个表示$S_1,S_2$的并集的<em>Bloom filter</em>可以通过原有<em>Bloom filter</em>的两个位向量的<strong>OR</strong>得到。</li><li><p><em>Bloom filter</em>可以很容易地将大小减半，允许应用程序动态地缩小<em>Bloom filter</em>。假设<em>Bloom filter</em>的大小为$2$的幂。将<em>Bloom filter</em>的大小减半，可以将前半部分与后半部分做<strong>OR</strong>操作得到。当散列进行查找时，最高位可能被屏蔽。</p></li><li><p><em>Bloom filter</em>也可以用来近似两个集合之间的交集。假设有两个<em>Bloom filter</em>表示集合$S_1$和$S_2$，它们具有相同的比特数，并且使用相同的哈希函数。直观地说，这两个位向量的内积是它们相似性的度量。如果第$j$位是被两个<em>Bloom filter</em>同时设置的，那么它是被$S_1\cap S_2$中的元素设置，或者它同时被$S1−(S1∩S2)$中的某个元素和$S2−(S1∩S2)$中的另一个元素设置。则第$j$位被同时设置的概率为</p><script type="math/tex; mode=display">\begin{array}{l}\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1} \cap S_{2}\right|}\right) \\+\left(1-\frac{1}{m}\right)^{k\left|S_{1} \cap S_{2}\right|}\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1}-\left(S_{1} \cap S_{2}\right)\right|}\right)\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{2}-\left(S_{1} \cap S_{2}\right)\right|}\right)\end{array}</script><p>化简得到两个<em>Bloom filter</em>的期望内积和为</p><script type="math/tex; mode=display">m\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1}\right|}-\left(1-\frac{1}{m}\right)^{k\left|S_{2}\right|}+\left(1-\frac{1}{m}\right)^{k\left(\left|S_{1}\right|+\left|S_{2}\right|-\left|S_{1} \cap S_{2}\right|\right)}\right) .</script><p>因此，已知$|S_1|,|S_2|, k, m，$以及内积的大小，可以用上式计算$|S_1∩S_2|$。如果没有给出$|S_1|,|S_2|$，它们也可以通过计算$S_1$,$S_2$的<em>Bloom filter</em>中的$0$位数来估计，集合$S$的$0$位数在其期望$m(1 - 1/m)^{k|S|}$附近。设$Z_1,Z_2$分别为$S_1,S_2$<em>Bloom filter</em>中$0$的个数，$Z_{12}$为内积中$0$的个数，则得到</p><script type="math/tex; mode=display">\frac{1}{m}\left(1-\frac{1}{m}\right)^{-k\left|S_{1} \cap S_{2}\right|} \approx \frac{Z_{1}+Z_{2}-Z_{12}}{Z_{1} Z_{2}}</script></li></ul><h2 id="Counting-Bloom-Filters"><a href="#Counting-Bloom-Filters" class="headerlink" title="　Counting Bloom Filters"></a>　Counting Bloom Filters</h2><ul><li><p>假设我们有一个随时间变化的集合，会进行元素插入和删除操作。将元素插入Bloom过滤器只需将元素进行哈希$k$次，并将对应位设为$1$。但不能通过逆过程来执行删除操作，如果我们对要删除的元素进行散列，并将其对应的位设为0。在这种情况下，Bloom filter不再正确地反映集合中的所有元素。</p></li><li><p>为了避免这个问题，Fan等人引入了计数布隆过滤器<em>(counting Bloom filter)</em>的思想。在一个<em>counting Bloom filter</em>中，采用一个计数器来代替位。当元素插入时，相应的计数器增加，当元素删除时，相应的计数器被减少。为了避免计数器溢出，可以选择足够大的计数器。Fan等人的分析表明，每个计数器4位就适用于大多数应用了。</p></li><li><p>要确定一个好的计数器大小，可以考虑一个<em>counting Bloom filter</em>表示$n$个元素的集合，使用$k$个哈希函数和$m$个计数器。设$c(i)$为第$i$个计数器的计数。第$i$个计数器为$j$次的概率是一个二项式随机变量</p><script type="math/tex; mode=display">\mathbb{P}(c(i)=j)=\left(\begin{array}{c}n k \\j\end{array}\right)\left(\frac{1}{m}\right)^{j}\left(1-\frac{1}{m}\right)^{n k-j} .</script><p>任何计数器至少为$j$的概率大于$m\mathbb{P}(c(i)\geq j)$，则</p><script type="math/tex; mode=display">\mathbb{P}(c(i) \geq j) \leq\left(\begin{array}{c}n k \\j\end{array}\right) \frac{1}{m^{j}} \leq\left(\frac{\mathrm{e} n k}{j m}\right)^{j}</script><p>假设$k≤(ln 2)m/n$，因为$k = (ln 2)m/n$获得最佳的<em>false positive rate</em>，则</p><script type="math/tex; mode=display">\mathbb{P}\left(\max _{i} c(i) \geq j\right) \leq m\left(\frac{\mathrm{e} \ln 2}{j}\right)^{j}</script><p>如果每个计数器设置为4位，则某个计数器达到16时，计数器就会溢出。从上面公式得到</p><script type="math/tex; mode=display">\mathbb{P}\left(\max _{i} c(i) \geq 16\right) \leq 1.37\times10^{-15}\times m</script><p>这个限制适用于最多$n$个项目的集合，这将满足大多数应用程序。另一种解释这个结果的方法是，当有$m\ \text{ln}\ 2$个总计数器增量分布在$m$个计数器上时，计数器的最大值很有可能是$O(\text{log}\ m)$，因此每个计数器只需要$O(\text{log}\ \text{log}\ m)$位。</p></li><li><p>在实践中，当计数器溢出时，一种解决方法是保持它的最大值。只有当计数器最终降至0而它本应保持非0时，这才会导致更多的<em>false positive rate</em>。如果删除是随机的，则此事件的预期时间相对较大。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Bloom Filter</tag>
      
    </tags>
    
  </entry>
  
  
  
  
  
  
  <entry>
    <title>about</title>
    <link href="/"/>
    <url>/</url>
    
    <content type="html"><![CDATA[]]></content>
    
  </entry>
  
  
  
</search>
