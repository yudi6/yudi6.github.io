<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>《All-in-one ： Multi-task Learning for Rumour Verification》笔记</title>
    <link href="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Rumour-Verification"><a href="#Rumour-Verification" class="headerlink" title="Rumour Verification"></a>Rumour Verification</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>社交媒体作为关注事件和突发新闻的平台越来越受用户欢迎。然而，并不是所有在社交媒体上传播的信息都是准确的，不准确的信息会对社会造成严重的危害。科学界对开发验证社交媒体信息的工具越来越感兴趣，Facebook也投入了大量的努力来减轻错误信息造成的问题。</p></li><li><p>谣言分辨过程分为四个子任务(如图1)：</p><ol><li>谣言检测，确定一个声明是否值得验证;</li><li>跟踪谣言，在谣言发生时收集消息来源和观点;</li><li>立场分类，确定消息来源或用户对谣言真实性的态度;</li><li>谣言验证，作为预测谣言真实性的最终步骤。</li></ol><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:100%;"></p><p>这些步骤可以在谣言生命周期的不同时间执行。理想情况下，谣言可以被认定为真或假。然而，当没有足够的证据来确定它们的真实性时，它们也可能仍然是未经核实的。</p></li><li><p>谣言分辨过程可以表示为一个多任务问题，其中真实性分类任务是主要任务，其余任务是辅助任务，可以利用这些任务来提高真实性分类器的性能。多任务学习可以帮助密切相关任务的共享表征的学习，即两个互补的任务可以相互给予”提示“。</p></li><li><p>结果利用这三个子任务的多任务学习场景（其中真实性分类是主要任务，立场分类和谣言检测为辅助任务），比单任务的学习与现在最新的系统都有实质性改进。</p></li></ul><h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><h3 id="Rumour-classification-system"><a href="#Rumour-classification-system" class="headerlink" title="Rumour classification system"></a>Rumour classification system</h3><ul><li>(Zubiaga等人，2018a)将谣言检测定义为区分谣言(未经验证的信息)和非谣言(所有其他传播的信息)的任务。谣言检测后，则将被分类为谣言的信息输入到系统的立场分类和验证组件中，最终确定谣言的真实性。</li><li><strong>Stance classification</strong>：确定与谣言相关的其他帖子是持支持、否认或是质疑态度，还是只是评论。用户对谣言所表达的立场可以表明谣言的真实性，有研究表明，容易引发否认和质疑的谣言更有可能被证明是错误。之前基于立场分类方面的工作探索了序列分类器的使用，已经证明序列分类器实质上优于标准的，非序列分类器。</li><li><strong>Rumour detection：</strong>谣言检测方面的工作更为稀缺。最早的方法之一是由Zhao等人(2015)提出的基于规则的方法，从而确定相关信息是谣言。Zubiaga等人(2017)提出了一种连续的方法来利用事件中早期帖子的上下文。序列方法在召回率方面取得了显著的改进，这是基于规则的方法所缺乏的。</li><li><strong>Rumour verification：</strong>谣言验证的常见方法包括从揭露谣言的网站(如snopes.com、emergent.com、politifact.com)收集已解决谣言的语料。Wang(2017)基于politifact.com的声明创建了一个数据集，并根据真实程度进行了标注，提出了一种混合卷积神经网络，将元数据与文本集成在一起。Twitter是一个研究谣言的流行平台，而谣言的种子和注释通常仍然来自辟谣网站。Giasemidis等人(2016)从Twitter收集了72个谣言数据集，这项工作测量了在不同的时间窗下一声明的可信度。</li><li><strong>Sequence classification：</strong>考虑谣言检测与谣言验证的工作强调了在处理谣言时采取时序敏感方法的重要性，因此实验中使用基于LSTM的架构。</li></ul><h3 id="Multi-task-learning"><a href="#Multi-task-learning" class="headerlink" title="Multi-task learning"></a>Multi-task learning</h3><ul><li>多任务学习是指用一个共享的表示形式对几个相关的任务进行联合学习。论文中使用了最常见的多任务学习方法，即<strong><em>hard parameter sharing</em></strong>，这意味着不同的任务使用相同的隐藏层。多任务学习通过使用其他数据集的相关任务和正则化，有效地增加了训练集的规模，而该模型必须学习多个任务的共享表示，减小了在其中某一任务过拟合的风险。在多任务学习中，辅助任务可以用来指导主任务学习由于任务和特征之间的复杂关系而忽略或无法识别的特征。例如，当潜在的有帮助的特性不是作为主要任务使用，而是成为辅助任务中的标签时，多任务学习是特别有用的。在实验中，立场分类可以作真实性分类系统的一种特征，其关系如之前所示。</li></ul><h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><ul><li>使用的谣言数据集为PHEME和RumourEval，其中包含不同级别的谣言检测、立场识别和谣言验证。</li></ul><h4 id="RumourEval"><a href="#RumourEval" class="headerlink" title="RumourEval"></a>RumourEval</h4><ul><li><p>RumourEval是作为the SemEval-2017 Task 8 competition的一部分数据集。它包含325条讨论谣言的推特帖子，RumourEval数据集中的所有对话都是谣言，因此该数据集只涵盖谣言立场和准确性分类的任务。它分为训练、测试和验证集。测试集包含与训练和验证集相同的事件有关的各种谣言，此外还有两个谣言：关于玛丽娜·乔伊斯和希拉里·克林顿的健康状况。</p></li><li><p>表1显示了RumourEval数据集中每组对话线程、分支和tweet的数量，以及这两个任务的标签分布。在立场分类任务中，质疑<strong>Q</strong>和否认<strong>D</strong>较少。对于谣言验证任务，训练集包含的真实例比假实例或未验证实例多，而开发和测试集则更加平衡。</p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:100%;"></p></li></ul><h4 id="PHEME"><a href="#PHEME" class="headerlink" title="PHEME"></a>PHEME</h4><ul><li><p>该数据集包含3个级别的注释。首先，每个线程被注释为谣言或非谣言；第二，谣言会被贴上真假或未经证实的标签。第三，通过众包？？对一个子集(RumourEval中使用的线程)进行注解，用于推文层面的立场分类。</p></li><li><p>表2为数据集中每个事件的大小以及谣言检测和验证任务的标签分布。 事件的大小差别很大，并且具有不同的标签比例。总的来说，PHEME数据集包含的谣言比非谣言少，而谣言的大多数是真实的。</p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:100%;"></p></li></ul><h2 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h2><h3 id="Sequential-approach"><a href="#Sequential-approach" class="headerlink" title="Sequential approach"></a>Sequential approach</h3><ul><li>遵循Zubiaga等人描述的<strong>branchLSTM</strong>方法，将对话分解成线性分支，并将它们用作训练实例作为模型输入。该模型由一个LSTM层、几个密集的ReLU层和一个预测分类概率的softmax层组成。由于立场分类任务在一篇推特级别注释，使用每个时间戳LSTM的输出。而对于谣言检测和验证任务，只使用最后一次输出。对于每线程的预测结果，我们对每个分支进行多数投票，利用分类交叉熵损失对模型进行训练。</li></ul><h3 id="Multi-task-learning-approach"><a href="#Multi-task-learning-approach" class="headerlink" title="Multi-task learning approach"></a>Multi-task learning approach</h3><ul><li><p>使用方法如图3。它的基础是一种顺序方法，由共享的LSTM层(硬参数共享)表示，随后是一些特定于任务的层。可能的任务组合在图3中以虚线的形式显示，根据组合的不同，它们可以出现也可以不出现。我们在三种设置下进行实验：立场与谣言验证，谣言检测与谣言验证，以及一起学习所有三个任务。在多任务模型中，成本函数是每个任务损失的总和。三个任务的数据集大小不相等，因此，当训练实例缺少其中一个任务的标签时，它的预测不会给损失函数增加任何东西，就像它被正确地预测了一样。</p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig4.png" style="zoom:100%;"></p></li></ul><h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><ul><li>采用多数投票法，在谣言验证任务中，由于类别不平衡，因此具有较强的基线，从而获得了较高的准确率。</li><li>NileTMRG是SemEval-2017任务8中的最佳准确性分类系统。NileTMRG模型基于线性的支持向量机(SVM)，使用单词袋并结合选定的特征：URL的存在性、hashtag的存在以及支持、否认和查询推文的比例表示推文。实验在NileTMRG模型的基础上做了我们自己的NileTMRG*实现。这个模型需要数据集中每个tweet的立场标签，但是这些标签对于PHEME是不可用的，因此使用了Kochkina的立场分类模型实现，而最终NileTMRG*获得了更好的效果。</li><li>NileTMRG模型显示了流水线任务按顺序执行的场景，上一个步骤(立场分类)的结果作为下一个步骤(谣言验证)的输入，证明了立场分类是谣言验证的有效指标。</li></ul><h3 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h3><ul><li>我们对数据集中的tweet进行以下预处理：删除非字母字符，将所有单词转换为小写，使用<strong>NLTK</strong>进行词性分类。对推文文本进行预处理后，我们对一条推文中的每个单词提取谷歌新闻数据集上预先训练好的word2vec词嵌入，并取其平均值，得到一条推文表示。由于tweet的长度较短，这种表示方式在tweet上表现得很好。</li></ul><h2 id="Experiment-setup"><a href="#Experiment-setup" class="headerlink" title="Experiment setup"></a>Experiment setup</h2><ul><li><p>使用<strong>the Tree of Parzen Estimators (TPE)</strong>算法来搜索参数空间，相关超参数设置见原论文。</p></li><li><p>最终结果如下图</p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig5.png" style="zoom:100%;"></p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig6.png" style="zoom:100%;"></p><p><img src="/2021/03/25/%E3%80%8AAll-in-one%20Multi-task%20Learning%20for%20Rumour%20Verification%E3%80%8B%E7%AC%94%E8%AE%B0/fig7.png" style="zoom:100%;"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rumour Verification</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Learning Reporting Dynamics during Breaking News for Rumour Detection in Social Media》笔记</title>
    <link href="/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Rumour-Detection-And-PHEME-Dataset"><a href="#Rumour-Detection-And-PHEME-Dataset" class="headerlink" title="Rumour Detection And PHEME Dataset"></a>Rumour Detection And PHEME Dataset</h1><ul><li>论文：<a href="https://arxiv.org/abs/1610.07363">https://arxiv.org/abs/1610.07363</a></li><li>PHEME 数据集：<a href="https://figshare.com/articles/PHEME_dataset_of_rumours_and_nonrumours/4010619">https://figshare.com/articles/PHEME_dataset_of_rumours_and_nonrumours/4010619</a></li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li>近年来，利用社交媒体来关注新闻已经变得很普遍。像Twitter这样的知名平台越来越多地被人们用来了解最新的新闻发展，以及被新闻记者用来收集新闻。然而，如恐怖袭击或暴乱的突发新闻在社交媒体上的传播速度不可避免地造成许多在新闻报道的早期阶段发布的信息是未经核实的。</li><li>谣言检测系统用于警告用户文章的未验证状态，告知用户这篇文章以后可能被证明是假的。这可以有助于限制传播虚假信息的传播，从而减少对个人、社区和社会的危害。</li><li>科学文献中关于谣言检测的研究很少，(Zhao et al., 2015)  是其中一篇解决该问题的著作。他们引入了一种寻找<strong>询问推文</strong>的方法，即寻找那些质疑原帖子可信性的推文，以确定原帖子是否是谣言。如果一条推文与手动管理的正则表达式中的一个匹配，那么它就被认为是一个询问推文。这种方法存在局限性：它依赖于人工定期修改正则表达式列表，因为这些正则表达式可能不适用于新的数据集；它假设询问推文出现，但并不是所有的谣言都一定会引发查询，这可能导致低召回率；它没有考虑到相关环境，我们可以利用环境来了解该信息是如何产生的。</li><li>论文定义谣言检测任务的目标为识别<strong>尚未被验证的信息片段</strong>，并从非谣言中区分它们。主要贡献有：<ul><li>描述了一种用于收集和注释Twitter数据集的新方法，该数据集包含各种各样的谣言和非谣言。我们的方法是一种自底向上的方法，通过与突发新闻报道相关的推特时间轴来注释谣言。</li><li>基于<strong>CRF</strong>来学习突发新闻的动态信息，这使我们能够利用上下文学习背景知识以分类谣言信息，这一过程仅根据推文的内容来判断是否是谣言。</li><li>研究了<strong>CRF</strong>作为序列分类器在五个突发新闻的推特数据集上的检测谣言性能，将CRF的性能与其他分类器比较。实验表明，CRF有实质性的改善。</li></ul></li></ul><h2 id="Definition-of-Rumour"><a href="#Definition-of-Rumour" class="headerlink" title="Definition of Rumour"></a>Definition of Rumour</h2><ul><li>谣言的定义：<em>circulating story of questionable veracity, which is apparently credible but hard to verify, and produces sufficient skepticism and/or anxiety so as to motivate finding out the actual truth.</em>  </li></ul><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><ul><li><p>论文通过模拟用户跟踪与突发新闻相关的报告的场景来收集数据，其中包括谣言和非谣言。我们的数据收集方法从Twitter流API中收集可能会引发谣言发起与传播的新闻事件相关的tweet，一旦记者告知有新闻价值的事件发生，就跟踪与该事件相关的主要标签和关键字来收集数据，随后记者通过查看关于突发新闻tweet的时间轴，将每条tweet进行注释，标志谣言或非谣言。标注采用的系统如下</p><p><img src="/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:100%;"></p></li><li><p>数据集的五个事件：</p><ul><li><em>Ferguson unrest: citizens of Ferguson in Michigan, USA, protested after the fatal shooting of an 18-year-old African American, Michael Brown, by a white police officer on August 9, 2014.</em></li><li><em>Ottawa shooting: shootings occurred on Ottawas Parliament Hill in Canada, resulting in the death of a Canadian soldier on October 22, 2014.</em></li><li><em>Sydney siege: a gunman held hostage ten customers and eight employees of a Lindt chocolate caf located at Martin Place in Sydney, Australia, on December 15, 2014.</em>  </li><li><em>Charlie Hebdo shooting: two brothers forced their way into the offices of the French satirical weekly newspaper Charlie Hebdo in Paris, killing 11 people and wounding 11 more, on January 7, 2015.</em></li><li><em>Germanwings plane crash: a passenger plane from Barcelona to Dsseldorf crashed in the French Alps on March 24, 2015, killing all passengers and crew. The plane was ultimately found to have been deliberately crashed by the co-pilot of the plane.</em>  </li></ul></li><li><p>考虑到数据集的大小，通过挑选引发大量转发的推文进行采样，转发阈值根据结果数据集的大小选择。对于样本子集中的每一条推文，同样收集所有回复它们的推文，对话收集脚本可在<a href="https://github.com/azubiaga/phemetwitter-conversation-collection上获得。使用回复推文有两个目的：在人工注释工作，回复推文可以为判断谣言与否提供帮助；而我们需要采用(Zhao">https://github.com/azubiaga/phemetwitter-conversation-collection上获得。使用回复推文有两个目的：在人工注释工作，回复推文可以为判断谣言与否提供帮助；而我们需要采用(Zhao</a> et al., 2015) <strong>询问推文</strong>的方法来作为实验的baseline。</p></li><li><p>各数据集的具体谣言与非谣言数目如Table 1。</p><p><img src="/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:100%;"></p><p>谣言数目随时间轴的变化（分为10段）如下图，</p><p><img src="/2021/03/23/%E3%80%8ALearning%20Reporting%20Dynamics%20during%20Breaking%20News%20for%20Rumour%20Detection%20in%20Social%20Media%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:100%;"></p><p>可以看到并没有明显的规律性。</p></li><li></li></ul><h2 id="Rumour-Detection-Task"><a href="#Rumour-Detection-Task" class="headerlink" title="Rumour Detection Task"></a>Rumour Detection Task</h2><ul><li>该任务以推文的演进时间线$T_L=\{t_1,t_2,\dots,t_{|TL|}\}$作为输入，分类器通过分配标签$Y=\{R,NR\}$来确定这些tweet是谣言还是非谣言，因此任务变成二分类问题。</li><li></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rumour Detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Adaptive Learned Bloom Filter (Ada-BF) Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web》笔记</title>
    <link href="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Adaptive-Learned-Bloom-Filter"><a href="#Adaptive-Learned-Bloom-Filter" class="headerlink" title="Adaptive Learned Bloom Filter"></a>Adaptive Learned Bloom Filter</h1><h2 id="Learned-Bloom-filter"><a href="#Learned-Bloom-filter" class="headerlink" title="　Learned Bloom filter"></a>　Learned Bloom filter</h2><ul><li><em>Learned Bloom filter</em> (LBF) 在<em>Bloom filter</em>之前增加了机器学习模型作为预过滤器，对于每个查询的元素$x$，给出得分$s(x)$，$s(x)$通常与$x\in S$的概率正相关。分类器先在一些可用的训练数据上进行预训练，根据其训练数据的特征对给定查询$x\in S$进行判断（二分类）。LBF设置阈值$\tau$，当$s(x)\geq \tau$时则判断$x\in S$，否则便使用<em>Bloom filter</em>进行进一步的判断。就像<em>standard Bloom filter</em>，LBF的<em>false negative rate</em>（FNR）为0。而<em>false positive rate</em>（FPR）可以由分类模型与<em>Bloom filter</em>的误报引起。</li><li>可以看出，当区域$s(x)≥τ$包含更多的$x$时，插入<em>Bloom filter</em>的关键字数会减少，从而导致良好的FPR。由于区域$s(x)≥τ$为正值，为了保证预过滤器判断正确，所以$τ$值越高越好，但$\tau$的增大会增加<em>Bloom filter</em>的负载。因此需要找到两者的平衡。</li></ul><h3 id="Wastage-of-Information"><a href="#Wastage-of-Information" class="headerlink" title="Wastage of Information"></a>Wastage of Information</h3><ul><li>当$s(x)&lt;\tau$时，采用<em>Bloom filter</em>进行查询判断，此时$s(x)$中的信息并没有得到使用。例如，当有两个元素$x_1,x_2$，并且$\tau&gt;s(x_1)\gg s(x_2)$。在使用LBF时，两者会采用相同方法进行判断，而直观来看，$x_1$比$x_2$更有可能属于$S$。</li></ul><h3 id="Strong-dependency-on-Generalization"><a href="#Strong-dependency-on-Generalization" class="headerlink" title="Strong dependency on Generalization"></a>Strong dependency on Generalization</h3><ul><li>由原理可知，当数据分布没有变化时，预过滤器更高的准确率可以降低FPR。但是，在部署了<em>Bloom filters</em>的在线环境中，数据分布可能会发生变化。众所周知，数据流具有分布上有漂移的突发性质。因此，分类器的置信度以及阈值并不是完全可靠的。其次，机器学习对特殊例子的敏感性给系统带来了新的问题，对于任何给定置信水平$τ$的分类器，可以很容易地创建被错误分类的示例。<em>Bloom filter</em>通常用于增加对抗性误报率的网络中，这可能会损害性能。由于冲突而增加的延迟可能会引发<em>Denial-of-Service attacks</em>(DoS)。</li></ul><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>对于一个分类器，分布密度$f(s(x))$在集合内和集合外的元素呈现不同的趋势。观察到，对于键，$f(s(x)|x \in S)$随着$s(x)$的增加呈现上升趋势，而$f(s(x)|x \notin S)$呈现相反的趋势。为了减少整体FPR，$f(s(x)|x \notin S)$高的组需要更低的FPRs。因此，如果用不同的方式调整哈希函数的数量，相应的组需要更多的哈希函数，而对于有几个非键的组允许更高的FPRs。</li></ul><h2 id="Adaptive-Learned-Bloom-Filter-Ada-BF"><a href="#Adaptive-Learned-Bloom-Filter-Ada-BF" class="headerlink" title="Adaptive Learned Bloom Filter (Ada-BF)"></a>Adaptive Learned Bloom Filter (Ada-BF)</h2><ul><li><p>上一节中LBF的公式，LBF实际上将$x$分成了两组。当$s(x)≥τ$时，$x$将被直接识别为集合中的元素，而不需要使用<em>Bloom filter</em>测试。换句话说，它先使用零哈希函数来标识资格。否则，将使用$K$哈希函数测试，则通过$s(x)≥τ$判断从$0$哈希函数到$K$哈希函数的条件。Ada-BF根据$s(x)$将$x$分为$g$个组，对于组$j$，采用$K_j$个哈希函数来判断它的资格。Ada-BF的结构如Figure 1(b)所示。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" style="zoom:100%;"></p></li><li><p>Ada-BF将$s(x)$分为$g$组，其中$x\in \text{Group}\ j$，$s(x)\in[\tau_{j-1};\tau_j), j = 1,2,···,g$，设$0 = τ_0 &lt; τ_1 &lt;···&lt; τ_{g−1} &lt; τ_g = 1$，来自组$j$的关键字使用$K_j$个独立的哈希函数插入到<em>Bloom filter</em>中。对于$j$组，FPR的期望值可表示为</p><script type="math/tex; mode=display">\mathbb{E}\left(\mathrm{FPR}_{j}\right)=\left(1-\left(1-\frac{1}{R}\right)^{\sum_{t=1}^{g} n_{t} K_{t}}\right)^{K_{j}}=\alpha^{K_{j}}</script><p>其中$n_{t}=\sum_{t=1}^{n} I\left(\tau_{t-1} \leq s\left(x_{i} \mid x_{i} \in S\right)&lt;\tau_{t}\right)$落在$\text{group}\ t$的关键字数。为了避免比特数组的过载，我们只在键数$n_j$较多的组中增加$K_j$，而在键数$n_j$较少的组中减少$K_j$。很明显，Ada-BF对LBF进行了推广。当Ada-BF只通过将查询分成两组时$K_1 = K, K_2 = 0， τ_1 = τ$， Ada-BF降为LBF。</p><p>值得注意的是，随着$s(x)$的增加，$f(s(x)|x\in S)$与$f(s(x)|x\notin S)$的趋势相反(Figure 2)。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig2.png" style="zoom:100%;"></p></li></ul><h3 id="Simplifying-the-Hyper-Parameters"><a href="#Simplifying-the-Hyper-Parameters" class="headerlink" title="Simplifying the Hyper-Parameters"></a>Simplifying the Hyper-Parameters</h3><ul><li><p>为了实现Ada-BF，需要确定$2g-1$个超参数，包括每组的哈希函数数量$K_j$和分组的评分阈值$τ_j (τ_0 = 0， τ_g = 1)$。使用这些超参数，对于Ada-BF，总体FPR的期望值可以表示为:</p><script type="math/tex; mode=display">\mathbb{E}(\mathrm{FPR})=\sum_{j=1}^{g} p_{j} \mathbb{E}\left(\mathrm{FPR}_{j}\right)=\sum_{j=1}^{g} p_{j} \alpha^{K_{j}}</script><p>其中$p_{j}=\operatorname{Pr}\left(\tau_{j-1} \leq s\left(x_{i} \mid x_{i} \notin S\right)&lt;\tau_{j}\right)$，$<br>p_{j}$可以用$\hat{p}_{j}=\frac{1}{m} \sum_{i=1}^{m} I\left(\tau_{j-1} \leq s\left(x_{i} \mid x_{i} \notin S\right)&lt;\tau_{j}\right)=\frac{m_{j}}{m}$表示($m$为训练数据中非键的数量，$m_j$为$j$组中非键的数量)。由于$\sum_{j=1}^{g} m_{j} \alpha^{K_{j}}=O\left(\max _{j}\left(m_{j} \alpha^{K_{j}}\right)\right)$，可以考虑使用$m_{j} \alpha^{K_{j}}$来近似。而$\alpha^{K_{j}}$随着$K_j$的增大呈指数级下降，为了保持$m_j\alpha^{K_{j}}$在不同组中的稳定，我们需要$m_j$随着$K_j$呈指数级增长。此外，由于$f(s(x)|x\notin S)$在大多数情况下随着$s(x)$变小而增大，所以对于较小的$s(x)$， $K_j$也应该变大，当$j$减少时，我们应该线性增加$K_j$，让$m_j$指数增长。</p></li><li><p>根据以上观点，设置$\frac{p_j}{p_{j+1}}=c$和$K_j-K_{j+1}=1$，其中$j=1,2,\cdots,g-1$，因为$s(x|x\notin S)$的真实密度是未知的，用$\hat{\frac{p_j}{p_{j+1}}}=\frac{m_j}{m_{j+1}}=c$来估计$\frac{p_j}{p_{j+1}}$，该策略确保了$\hat{p}_j$与$K_j$的指数级增长。现在只有三个超参数，$c,K_{min},K_{max}(K_{max}=K_1)$。默认情况下设置$K_{min} = K_{g} = 0$，等价于将$g$组中的所有项目标识为键。</p></li></ul><h3 id="Analysis-of-Adaptive-Learned-Bloom-Filter"><a href="#Analysis-of-Adaptive-Learned-Bloom-Filter" class="headerlink" title="Analysis of Adaptive Learned Bloom Filter"></a>Analysis of Adaptive Learned Bloom Filter</h3><ul><li><p>与LBF相比，Ada-BF充分利用密度分布$s(x)$，对不同区间的FPR进行优化，而且Ada-BF可以在不增加内存使用的情况下降低LBF的FPR。</p><p>当$p_j/p_{j+1}=c_j\geq c &gt; 1$，$K_j-K_{j+1}= 1$时，预期的FPR如下</p></li></ul><script type="math/tex; mode=display">  \mathbb{E}(\mathrm{FPR})=\sum_{j=1}^{g} p_{j} \alpha^{K_{j}}=\frac{\sum_{j=1}^{g} c^{g-j} \alpha^{K_{j}}}{\sum_{j=1}^{g} c^{g-j}} \leq\left\{\begin{array}{ll}  \frac{(1-c)\left(1-(c \alpha)^{g}\right)}{\left(\frac{1}{\alpha}-c\right)\left(\alpha^{g}-(c \alpha)^{g}\right)} \alpha^{K_{\max }}, & c \alpha \neq 1 \\  \frac{1-c}{1-c^{g}} \cdot g, & c \alpha=1  \end{array}\right.</script><p>  其中$K_{max} = K_1$。为了方便分析，设$cα &gt; 1$。假设$g$组的数目是固定的，提高$c$就可以满足这以上条件，而$α$会随着$c$的增大而增大。为了比较，需要LBF的$τ$等于Ada-BF的$\tau_{g-1}$，在这种情况下，分数高于$τ$的查询会被机器学习模型直接判断为键。比较整体的FPR便只需要比较得分低于$τ$的查询的FPR。</p><ul><li><p><strong>Theorem 1</strong>：对于Ada-BF，对于所有的$j\in[g-1],$给定$\frac{p_j}{p_{j+1}}\geq c &gt;1$，如果存在$λ &gt; 0$使$cα≥1+λ$成立，并且对于所有的$j\in[g-1],$$n_{j+1}−n_j &gt; 0$($n_j$是$j$组的键数)。当$g$足够大且$g≤\lfloor2K\rfloor$时(K是LBF哈希函数的个数)，Ada-BF的FPR小于LBF。</p></li><li><p>Theorem 1要求$n_j$的键数不断增加，而$p_j$随着$j$呈指数级下降。如图2所示，在真实数据集上，随着分数的增加，$f(s(x)|x\notin S)$下降得非常快，而$f(s(x)|x \in S)$增加，能够满足定理的条件。</p></li></ul><h2 id="Disjoint-Adaptive-Learned-Bloom-Filter-Disjoint-Ada-BF"><a href="#Disjoint-Adaptive-Learned-Bloom-Filter-Disjoint-Ada-BF" class="headerlink" title="Disjoint Adaptive Learned Bloom Filter (Disjoint Ada-BF)"></a>Disjoint Adaptive Learned Bloom Filter (Disjoint Ada-BF)</h2><ul><li><p>Ada-BF根据键的分数将键分成$g$组，并使用不同数量的哈希函数将键散列到同一个<em>Bloom Filter</em>中。基于类似的想法，disjoint Ada-BF也将键分成$g$组，但是将不同组的键散列到独立的<em>Bloom Filter</em>中。disjoint Ada-BF的结构如图1(c)所示。</p><p>假设<em>Bloom Filter</em>的总预算为$R$位，键被分成$g$组。因此，来自组$j$的键被插入到长度为$R_j (R = \sum_{j=1}^g R_j)$的<em>Bloom filter</em>。在查找阶段，需要确定查询所属的组并检查其在对应Bloom Filter中的成员关系。</p></li></ul><h3 id="Simplifying-the-Hyper-Parameters-1"><a href="#Simplifying-the-Hyper-Parameters-1" class="headerlink" title="Simplifying the Hyper-Parameters"></a>Simplifying the Hyper-Parameters</h3><ul><li>与Ada-BF类似，disjoint Ada-BF也有需要设置的超参数，例如组分割的分数阈值$τ_j$和<em>Bloom Filter</em>的长度$R_j$。阈值$τ_j$的确定与上一节类似。为了找到优化整体FPR的$R_j$，我们再次引用上一节的思想，即不同组的<em>false postivives</em>预期应该是相似的。对于具有$Rj$位的<em>Bloom filter</em>，最优哈希函数数量可以近似为$K_j=\frac{R_j}{n_j}\text{log(2)}$，其中$n_j$是组$j$中的键数。对应的最优FPR的期望为$\mathbb{E}\left(\mathrm{FPR}_{j}\right)=\mu^{R_{j} / n_{j}}(\mu \approx 0.618)$，因此，为了使不同组的<em>false postivives</em>预期相似，$R_j$需要满足<script type="math/tex; mode=display">m_{j} \cdot \mu^{\frac{R_{j}}{n_{j}}}=m_{1} \cdot \mu^{\frac{R_{1}}{n_{1}}} \Longleftrightarrow \frac{R_{j}}{n_{j}}-\frac{R_{1}}{n_{1}}=\frac{(j-1) \log (c)}{\log (\mu)}</script>在已知阈值$τ_j$的前提下，$n_j$是已知的，并且桶的总预算$R$是已知的，因此可以求解$R_j$。</li></ul><h3 id="Analysis-of-Disjoint-Adaptive-Learned-Bloom-Filter"><a href="#Analysis-of-Disjoint-Adaptive-Learned-Bloom-Filter" class="headerlink" title="Analysis of Disjoint Adaptive Learned Bloom Filter"></a>Analysis of Disjoint Adaptive Learned Bloom Filter</h3><ul><li>Disjoint Ada-BF使用一组较短的<em>Bloom Filter</em>来存储键的哈希输出。核心思想与Ada-BF相同，都是通过减少组的FPR来降低整体的FPR。Disjoint Ada-BF为每组分配<em>Bloom Filter</em>，以实现更小的FPR。在下面的定理中，证明在达到LBF的最优预期FPR时，Disjoint Ada-BF消耗更少的桶。</li><li><strong>Theorem 2：</strong>对于所有的$j\in[g-1]$($n_j$是组$j$的键数)，如果$\frac{p_j}{p_{j+1}}=c&gt;1$和$n_{j+1}−n_j &gt; 0$，为了实现LBF的最优FPR，当$g$较大时，Disjoint Ada-BF消耗的桶数比LBF少。</li></ul><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><ul><li><p>论文测试现有几种Bloom filter算法的性能:1)standard Bloom filter，2)learned Bloom filter，3)sandwiched learned Bloom filter  ，4)adaptive learned Bloom filter  ，5)disjoint adaptive learned Bloom filter。使用两个具有不同关联任务的数据集，即恶意url检测和病毒扫描，通过它们的FPRs和相应的内存使用来衡量性能。作者在<a href="https://github.com/DAIZHENWEI/Ada-BF">https://github.com/DAIZHENWEI/Ada-BF</a> 上开源了自己的代码与数据集。</p></li><li><p>url数据集一共有三列（url，label，score），分别为需要检测的url，标签与预先训练的随机森林模型对应得分$\text{score}(x)$(采用“sklearn.ensemble.RandomForestClassifier“)。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig3.png" style="zoom:50%;"></p><p>病毒扫描数据集一共有三列（label，score，MD5），分别为标签、预先训练的随机森林模型对应得分$\text{score}(x)$(采用“sklearn.ensemble.RandomForestClassifier“)与文件的MD5签名。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig4.png" style="zoom:50%;"></p></li><li><p>实验的相关设置可参考原论文，最终结果如下。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig5.png" style="zoom:100%;"></p></li></ul><h2 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h2><p>以下为论文代码实现的相关说明与注释，包括Bloom_filter、learned_Bloom_filter、Ada-BF、disjoint_Ada-BF四种。</p><h3 id="Bloom-filter"><a href="#Bloom-filter" class="headerlink" title="Bloom_filter"></a>Bloom_filter</h3><ul><li><p>首先采用<code>sklearn.utils.murmurhash3_32</code>函数作为<em>Bloom filter</em>中的哈希函数，根据key值得到32位的哈希值，对<em>Bloom filter</em>的大小$m$取余则得到$[0,m-1]$范围的值作为下标索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hashfunc</span>(<span class="hljs-params">m</span>):</span><br>    ss = randint(<span class="hljs-number">1</span>, <span class="hljs-number">99999999</span>)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hash_m</span>(<span class="hljs-params">x</span>):</span><br>        <span class="hljs-keyword">return</span> murmurhash3_32(x,seed=ss)%m<br>    <span class="hljs-keyword">return</span> hash_m<br></code></pre></td></tr></table></figure></li><li><p>Standard Bloom filter的类初始化方式如下，根据推导公式$k=ln\ 2\ \cdot\ (m/n)$得到最优$k$值，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BloomFilter</span>():</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, n, hash_len</span>):</span><br>        self.n = n<br>        self.hash_len = <span class="hljs-built_in">int</span>(hash_len)<br>        <span class="hljs-keyword">if</span> (self.hash_len == <span class="hljs-number">0</span>):<br>            <span class="hljs-keyword">raise</span> SyntaxError(<span class="hljs-string">&#x27;The hash table is empty&#x27;</span>)<br>        <span class="hljs-comment"># 根据推导公式得到最优k值</span><br>        <span class="hljs-keyword">if</span> (self.n &gt; <span class="hljs-number">0</span>) &amp; (self.hash_len &gt; <span class="hljs-number">0</span>):<br>            self.k = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">int</span>(self.hash_len/n*<span class="hljs-number">0.6931472</span>))<br>        <span class="hljs-keyword">elif</span> (self.n==<span class="hljs-number">0</span>):<br>            self.k = <span class="hljs-number">1</span><br>        <span class="hljs-comment"># 创建k个哈希函数</span><br>        self.h = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>            self.h.append(hashfunc(self.hash_len))<br>        <span class="hljs-comment"># 初始化“位数组”</span><br>        self.table = np.zeros(self.hash_len, dtype=<span class="hljs-built_in">int</span>)<br></code></pre></td></tr></table></figure><p>插入时进行$k$次哈希映射，将位数组中对应位置$1$，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">insert</span>(<span class="hljs-params">self, key</span>):</span><br>    <span class="hljs-keyword">if</span> self.hash_len == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">raise</span> SyntaxError(<span class="hljs-string">&#x27;cannot insert to an empty hash table&#x27;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> key:<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>            t = self.h[j](i)<br>            self.table[t] = <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>检测时，同样进行$k$次哈希映射，判断对应位是否都为$1$，返回结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test</span>(<span class="hljs-params">self, keys, single_key = <span class="hljs-literal">True</span></span>):</span><br>    <span class="hljs-keyword">if</span> single_key:<br>        test_result = <span class="hljs-number">0</span><br>        match = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> self.hash_len &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>                t = self.h[j](keys)<br>                match += <span class="hljs-number">1</span> * (self.table[t] == <span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">if</span> match == self.k:<br>                test_result = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        test_result = np.zeros(<span class="hljs-built_in">len</span>(keys))<br>        ss=<span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> self.hash_len &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> keys:<br>                match = <span class="hljs-number">0</span><br>                <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>                    t = self.h[j](key)<br>                    match += <span class="hljs-number">1</span>*(self.table[t] == <span class="hljs-number">1</span>)<br>                <span class="hljs-keyword">if</span> match == self.k:<br>                    test_result[ss] = <span class="hljs-number">1</span><br>                ss += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> test_result<br></code></pre></td></tr></table></figure></li><li><p>使用  <code>python Bloom_filter.py --data_path ./Datasets/URL_data.csv --size_of_BF 200000</code>运行代码，url任务对应main函数如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--data_path&#x27;</span>, action=<span class="hljs-string">&quot;store&quot;</span>, dest=<span class="hljs-string">&quot;data_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>,<br>                        <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;path of the dataset&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--size_of_BF&#x27;</span>, action=<span class="hljs-string">&quot;store&quot;</span>, dest=<span class="hljs-string">&quot;R_sum&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, required=<span class="hljs-literal">True</span>,<br>                        <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;size of the BF&quot;</span>)<br>    <br>    <span class="hljs-comment"># 数据集路径与位数组大小</span><br>    results = parser.parse_args()<br>    DATA_PATH = results.data_path<br>    R_sum = results.R_sum<br><br>    data = pd.read_csv(DATA_PATH)<br><br>    negative_sample = data.loc[(data[<span class="hljs-string">&#x27;label&#x27;</span>] == -<span class="hljs-number">1</span>)]<br>    positive_sample = data.loc[(data[<span class="hljs-string">&#x27;label&#x27;</span>] == <span class="hljs-number">1</span>)]<br><br>    <span class="hljs-comment"># 对所有正样例进行插入</span><br>    query = positive_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>    n = <span class="hljs-built_in">len</span>(query)<br>    bloom_filter = BloomFilter(n, R_sum)<br>    bloom_filter.insert(query)<br>    query_negative = negative_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>    <br>    <span class="hljs-comment"># 对所有负样例进行检测，得到结果</span><br>    n1 = bloom_filter.test(query_negative, single_key=<span class="hljs-literal">False</span>)<br>    print(<span class="hljs-string">&#x27;False positive items: &#x27;</span>, <span class="hljs-built_in">sum</span>(n1))<br>    print(<span class="hljs-string">&#x27;FPR:&#x27;</span>, <span class="hljs-built_in">sum</span>(n1)/<span class="hljs-built_in">len</span>(negative_sample))<br></code></pre></td></tr></table></figure></li></ul><h3 id="learned-Bloom-filter"><a href="#learned-Bloom-filter" class="headerlink" title="learned_Bloom_filter"></a>learned_Bloom_filter</h3><ul><li><p>由于数据中已经有了预先训练的随机森林模型对应得分，因此需要确定最优的$\tau$，以url任务为例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># train_negative为30%抽样得到的负样例</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Find_Optimal_Parameters</span>(<span class="hljs-params">max_thres, min_thres, R_sum, train_negative, positive_sample</span>):</span><br>    FP_opt = train_negative.shape[<span class="hljs-number">0</span>]<br>    <br>    <span class="hljs-comment"># 从最小值到最大值遍历计算确定最优值</span><br>    <span class="hljs-keyword">for</span> threshold <span class="hljs-keyword">in</span> np.arange(min_thres, max_thres+<span class="hljs-number">10</span>**(-<span class="hljs-number">6</span>), <span class="hljs-number">0.01</span>):<br>        <span class="hljs-comment"># 根据阈值得到插入Bloomfilter的样例</span><br>        query = positive_sample.loc[(positive_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        n = <span class="hljs-built_in">len</span>(query)<br>        bloom_filter = BloomFilter(n, R_sum)<br>        bloom_filter.insert(query)<br>        <span class="hljs-comment"># 分类器分类错误的样例</span><br>        ML_positive = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &gt; threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        <span class="hljs-comment"># Bloomfilter检测错误的样例</span><br>        bloom_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= threshold),<span class="hljs-string">&#x27;url&#x27;</span>]<br>        BF_positive = bloom_filter.test(bloom_negative, single_key=<span class="hljs-literal">False</span>)<br>        <span class="hljs-comment"># False Positive</span><br>        FP_items = <span class="hljs-built_in">sum</span>(BF_positive) + <span class="hljs-built_in">len</span>(ML_positive)<br>        print(<span class="hljs-string">&#x27;Threshold: %f, False positive items: %d&#x27;</span> %(<span class="hljs-built_in">round</span>(threshold, <span class="hljs-number">2</span>), FP_items))<br>        <span class="hljs-comment"># 保存最优的阈值与对应Bloomfilter</span><br>        <span class="hljs-keyword">if</span> FP_opt &gt; FP_items:<br>            FP_opt = FP_items<br>            thres_opt = threshold<br>            bloom_filter_opt = bloom_filter<br>    <span class="hljs-keyword">return</span> bloom_filter_opt, thres_opt<br></code></pre></td></tr></table></figure><p>获得最优的$\tau$后，在整个负样例上进行检测，得到最终的FPR。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-string">&#x27;&#x27;&#x27;Stage 1: Find the hyper-parameters (spare 30% samples to find the parameters)&#x27;&#x27;&#x27;</span><br>    bloom_filter_opt, thres_opt = Find_Optimal_Parameters(max_thres, min_thres, R_sum, train_negative, positive_sample)<br><br>    <span class="hljs-string">&#x27;&#x27;&#x27;Stage 2: Run LBF on all the samples&#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment">### Test queries</span><br>    ML_positive = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &gt; thres_opt), <span class="hljs-string">&#x27;url&#x27;</span>]<br>    bloom_negative = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thres_opt), <span class="hljs-string">&#x27;url&#x27;</span>]<br>    score_negative = negative_sample.loc[(negative_sample[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thres_opt), <span class="hljs-string">&#x27;score&#x27;</span>]<br>    BF_positive = bloom_filter_opt.test(bloom_negative, single_key = <span class="hljs-literal">False</span>)<br>    FP_items = <span class="hljs-built_in">sum</span>(BF_positive) + <span class="hljs-built_in">len</span>(ML_positive)<br>    FPR = FP_items/<span class="hljs-built_in">len</span>(negative_sample)<br>    print(<span class="hljs-string">&#x27;False positive items: &#123;&#125;; FPR: &#123;&#125;; Size of quries: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(FP_items, FPR, <span class="hljs-built_in">len</span>(negative_sample)))<br></code></pre></td></tr></table></figure></li></ul><h3 id="Ada-BF"><a href="#Ada-BF" class="headerlink" title="Ada-BF"></a>Ada-BF</h3><ul><li><p>Ada-BF中Bloom_filter与原始Bloom_filter的差别在于哈希函数的个数，由于$K_j-K_{j+1}=1$，且$K_g=0$，则$K_{max}$与划分的组数有关，因此Ada-BF需要根据组数进行哈希函数数量的修改，在检测时需要根据$k$值进行$k$次映射。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Ada_BloomFilter</span>():</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, n, hash_len, k_max</span>):</span><br>        self.n = n<br>        self.hash_len = <span class="hljs-built_in">int</span>(hash_len)<br>        self.h = []<br>        <span class="hljs-comment"># 创建k_max个哈希函数</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k_max)):<br>            self.h.append(hashfunc(self.hash_len))<br>        self.table = np.zeros(self.hash_len, dtype=<span class="hljs-built_in">int</span>)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">insert</span>(<span class="hljs-params">self, key, k</span>):</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k)):<br>            t = self.h[j](key)<br>            self.table[t] = <span class="hljs-number">1</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test</span>(<span class="hljs-params">self, key, k</span>):</span><br>        test_result = <span class="hljs-number">0</span><br>        match = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(k)):<br>            t = self.h[j](key)<br>            match += <span class="hljs-number">1</span>*(self.table[t] == <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> match == k:<br>            test_result = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> test_result<br></code></pre></td></tr></table></figure><p>根据上面的分析，需要确定的最优参数有组数$g$与$\hat{\frac{p_j}{p_{j+1}}}=\frac{m_j}{m_{j+1}}=c$，同样采用从最小值到最大值遍历并保存最优值的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Find_Optimal_Parameters</span>(<span class="hljs-params">c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample</span>):</span><br>    <span class="hljs-comment"># c_min到c_max寻找最优值</span><br>    c_set = np.arange(c_min, c_max+<span class="hljs-number">10</span>**(-<span class="hljs-number">6</span>), <span class="hljs-number">0.1</span>)<br>    FP_opt = train_negative.shape[<span class="hljs-number">0</span>]<br><br>    k_min = <span class="hljs-number">0</span><br>    <span class="hljs-comment"># k_max 与组数有关</span><br>    <span class="hljs-keyword">for</span> k_max <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_group_min, num_group_max+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> c_set:<br>            <span class="hljs-comment"># tau = sum([c**0, c**1,...]) 则各划分区间的最小单位</span><br>            tau = <span class="hljs-built_in">sum</span>(c ** np.arange(<span class="hljs-number">0</span>, k_max - k_min + <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>            n = positive_sample.shape[<span class="hljs-number">0</span>]<br>            hash_len = R_sum<br>            bloom_filter = Ada_BloomFilter(n, hash_len, k_max)<br>            thresholds = np.zeros(k_max - k_min + <span class="hljs-number">1</span>)<br>            thresholds[-<span class="hljs-number">1</span>] = <span class="hljs-number">1.1</span><br>            <span class="hljs-comment"># 抽样后的负样例总数</span><br>            num_negative = <span class="hljs-built_in">sum</span>(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thresholds[-<span class="hljs-number">1</span>])<br>            <span class="hljs-comment"># 按比例分成碎片，一共tau个碎片</span><br>            num_piece = <span class="hljs-built_in">int</span>(num_negative / tau) + <span class="hljs-number">1</span><br>            <br>            score = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt;= thresholds[-<span class="hljs-number">1</span>]), <span class="hljs-string">&#x27;score&#x27;</span>]<br>            score = np.sort(score)<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k_min, k_max):<br>                i = k - k_min<br>                score_1 = score[score &lt; thresholds[-(i + <span class="hljs-number">1</span>)]]<br>                <span class="hljs-comment"># 从后往前计算区间划分阈值 根据m_j/m_&#123;j+1&#125; = c并且剩下样例足够划分</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>(num_piece * c ** i) &lt; <span class="hljs-built_in">len</span>(score_1):<br>                    thresholds[-(i + <span class="hljs-number">2</span>)] = score_1[-<span class="hljs-built_in">int</span>(num_piece * c ** i)]<br><br>            query = positive_sample[<span class="hljs-string">&#x27;url&#x27;</span>]<br>            score = positive_sample[<span class="hljs-string">&#x27;score&#x27;</span>]<br>            <br>            <span class="hljs-comment"># 插入数据</span><br>            <span class="hljs-keyword">for</span> score_s, query_s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(score, query):<br>                ix = <span class="hljs-built_in">min</span>(np.where(score_s &lt; thresholds)[<span class="hljs-number">0</span>])<br>                k = k_max - ix<br>                bloom_filter.insert(query_s, k)<br>            <span class="hljs-comment"># 进行FPR估计</span><br>            ML_positive = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &gt;= thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;url&#x27;</span>]<br>            query_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;url&#x27;</span>]<br>            score_negative = train_negative.loc[(train_negative[<span class="hljs-string">&#x27;score&#x27;</span>] &lt; thresholds[-<span class="hljs-number">2</span>]), <span class="hljs-string">&#x27;score&#x27;</span>]<br><br>            <span class="hljs-comment"># 进行检测</span><br>            test_result = np.zeros(<span class="hljs-built_in">len</span>(query_negative))<br>            ss = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> score_s, query_s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(score_negative, query_negative):<br>                ix = <span class="hljs-built_in">min</span>(np.where(score_s &lt; thresholds)[<span class="hljs-number">0</span>])<br>                <span class="hljs-comment"># thres = thresholds[ix]</span><br>                k = k_max - ix<br>                test_result[ss] = bloom_filter.test(query_s, k)<br>                ss += <span class="hljs-number">1</span><br>            FP_items = <span class="hljs-built_in">sum</span>(test_result) + <span class="hljs-built_in">len</span>(ML_positive)<br>            print(<span class="hljs-string">&#x27;False positive items: %d, Number of groups: %d, c = %f&#x27;</span> %(FP_items, k_max, <span class="hljs-built_in">round</span>(c, <span class="hljs-number">2</span>)))<br>            <span class="hljs-comment"># 保存最优结果</span><br>            <span class="hljs-keyword">if</span> FP_opt &gt; FP_items:<br>                FP_opt = FP_items<br>                bloom_filter_opt = bloom_filter<br>                thresholds_opt = thresholds<br>                k_max_opt = k_max<br><br>    <span class="hljs-comment"># print(&#x27;Optimal FPs: %f, Optimal c: %f, Optimal num_group: %d&#x27; % (FP_opt, c_opt, num_group_opt))</span><br>    <span class="hljs-keyword">return</span> bloom_filter_opt, thresholds_opt, k_max_opt<br></code></pre></td></tr></table></figure><p>得到最优参数后在整个测试集上做检测，得到最终FPR。</p></li></ul><h3 id="disjoint-Ada-BF"><a href="#disjoint-Ada-BF" class="headerlink" title="disjoint_Ada-BF"></a>disjoint_Ada-BF</h3><ul><li><p>与Ada-BF不同的是，disjoint_Ada-BF需要计算每个组的<em>Bloom filter</em>的位数组大小$R_j$，计算使用的推导公式为</p><script type="math/tex; mode=display">\frac{R_{j}}{n_{j}}-\frac{R_{1}}{n_{1}}=\frac{(j-1) \log (c)}{\log (\mu)}</script><p>由于在划分阈值的时候，各组区间的非键数按$c$指数增长，因此可以用以计算$c^{j-1}$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">R_size</span>(<span class="hljs-params">count_key, count_nonkey, R0</span>):</span><br>    R = [<span class="hljs-number">0</span>]*<span class="hljs-built_in">len</span>(count_key)<br>    R[<span class="hljs-number">0</span>] = <span class="hljs-built_in">max</span>(R0,<span class="hljs-number">1</span>)<br>    <span class="hljs-comment">#　根据推导公式计算R</span><br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(count_key)):<br>        R[k] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">int</span>(count_key[k] * (np.log(count_nonkey[<span class="hljs-number">0</span>]/count_nonkey[k])/np.log(<span class="hljs-number">0.618</span>) + R[<span class="hljs-number">0</span>]/count_key[<span class="hljs-number">0</span>])), <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> R<br></code></pre></td></tr></table></figure><p>根据以上函数，调节$R_0$使得最终得到的$R$数组满足所给定内存，则退出调节。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">### Search the Bloom filters&#x27; size</span><br>R = np.zeros(num_group_1 - <span class="hljs-number">1</span>)<br>R[:] = <span class="hljs-number">0.5</span> * R_sum<br>non_empty_ix = <span class="hljs-built_in">min</span>(np.where(count_key &gt; <span class="hljs-number">0</span>)[<span class="hljs-number">0</span>])<br><span class="hljs-keyword">if</span> non_empty_ix &gt; <span class="hljs-number">0</span>:<br>    R[<span class="hljs-number">0</span>:non_empty_ix] = <span class="hljs-number">0</span><br>kk = <span class="hljs-number">1</span><br><span class="hljs-comment"># 通过调节R_0的大小,使得根据推导公式分配的R满足要求</span><br><span class="hljs-keyword">while</span> <span class="hljs-built_in">abs</span>(<span class="hljs-built_in">sum</span>(R) - R_sum) &gt; <span class="hljs-number">200</span>:<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">sum</span>(R) &gt; R_sum):<br>        R[non_empty_ix] = R[non_empty_ix] - <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        R[non_empty_ix] = R[non_empty_ix] + <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>)<br>    R[non_empty_ix:] = R_size(count_key[non_empty_ix:-<span class="hljs-number">1</span>], count_nonkey[non_empty_ix:-<span class="hljs-number">1</span>], R[non_empty_ix])<br>    <span class="hljs-comment"># 调节大小可以忽略时结束</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>((<span class="hljs-number">0.5</span> * R_sum) * (<span class="hljs-number">0.5</span>) ** kk + <span class="hljs-number">1</span>) == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">break</span><br>    kk += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li><li><p>为每个组创建一个<em>Bloom filter</em>，其他操作类似。</p></li></ul><h2 id="Preventing-Misinformation-Spread-over-Social-Media-in-Real-Time"><a href="#Preventing-Misinformation-Spread-over-Social-Media-in-Real-Time" class="headerlink" title="Preventing Misinformation Spread over Social Media in Real-Time"></a>Preventing Misinformation Spread over Social Media in Real-Time</h2><ul><li><p>由于互联网的发展，像Twitter这样的社交媒体几秒内便可在全球范围内传播信息。每天大约有5亿条推文，也就是每秒产生6000 - 10000条推文。Twitter最近报道了一项对其全球分布式索引系统(Twia)的重大改革，该系统使一条推文在一秒钟内就能被全世界看到，而误导内容(或错误信息)也因此会以极快速度在网络上产生并传播。</p></li><li><p>如果已经确定了一个错误信息的来源及其内容，为了防止其在网络快速传播，过滤这些错误信息的系统必须满足几个关键的条件。首先，一旦确定了错误信息的来源及其内容，应该在毫秒内告知全球各地的所有服务器错误信息的相关内容，同时需要保证最小的通讯开销。其次，给定大量生成的信息，需要在没有任何计算开销的情况下正确地清除信息。由于前所未有的数据生成速度，在清除信息的过程中任何计算开销都将导致系统崩溃。这是<em>Bloom filter</em>的经典用例，我们不希望错误信息通过过滤器，并且不会产生任何计算开销。否则，数据生成速率将超过我们的过滤速率。</p></li><li><p><strong>在理想情况下，使用<em>Bloom filter</em>可以压缩错误信息的数据库。每在数据库中中增加一个错误信息，只需要传输几个比特。</strong>只要FPR足够低，系统就不会崩溃。总的来说，FPR非常重要，我们希望每次更新的通信(内存)尽可能少。由于机器学习在自然语言处理方面取得显著的成功，因此有了一个更高性能的LBF，但仅靠机器学习无法保证应用程序所需的零<em>false negative</em>。</p></li><li><p>在<em>Preventing Misinformation Spread over Social Media in Real-Time</em>实验在<a href="https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset?select=Fake.csv">假新闻数据集</a>上进行，该数据集包括23481条假新闻和21417条真新闻，采用的机器学习模型利用<strong>TFIDF</strong>特征训练<strong>朴素贝叶斯分类模型</strong>，并测试不同<em>Learned Bloom filter</em>的FPR。与之前的实验结果相似，Ada-BF和disjoint Ada-BF相比于BF和LBF有明显的优势。在相同的内存预算下，BF和LBF使FPRs降低了70%以上。而Ada-BF和disjoint Ada-BF只需要LBF一半的空间，有效地将通信开销减少了$1 / 2$。</p><p><img src="/2021/03/08/%E3%80%8AAdaptive%20Learned%20Bloom%20Filter%20(Ada-BF)%20Efficient%20Utilization%20of%20the%20Classifier%20with%20Application%20to%20Real-Time%20Information%20Filtering%20on%20the%20Web%E3%80%8B%E7%AC%94%E8%AE%B0/fig6.png" style="zoom:44%;"></p></li><li><p>在进一步实验中，除了精确的成员测试外，查询到的新闻是否与数据库中的假新闻高度相似也很重要。然而，<strong>目前的Bloom filter不能处理这个任务</strong>。Kirsch和Mitzenmacher提出了<strong><em>Distance-sensitive bloom filters</em></strong>，这可能是一个可能的解决方案，<em>Learned Bloom filter</em>可以很容易地扩展到<em>Distance-sensitive bloom filters</em>。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Bloom Filter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Network Applications of Bloom Filters：A Survey》笔记</title>
    <link href="/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Bloom-Filter"><a href="#Bloom-Filter" class="headerlink" title="Bloom Filter"></a>Bloom Filter</h1><ul><li><strong>Bloom filter</strong>是一种空间效率高的随机数据结构，采用位数组表示一个集合以提供成员查询。<em>Bllom filter</em>是容许错误判断的，即把不属于这个集合的元素误判断属于这一集合，这样的错误称作<em>false positives</em>。因此<em>Bloom filter</em>不适用于零错误的应用，它通过极低的错误率节省了大量的空间。</li><li><strong>The Bloom filter principle:</strong> <em>Wherever a list or set is used, and space is at a premium, consider using a Bloom filter if the effect of false positives can be mitigated.</em> (当空间消耗昂贵而允许false positives时，考虑使用布隆过滤器。)</li></ul><h2 id="Standard-Bloom-Filter"><a href="#Standard-Bloom-Filter" class="headerlink" title="Standard Bloom Filter"></a>Standard Bloom Filter</h2><ul><li><p><em>Bllom Filter</em>采用一个$m$位的位数组来表示包含$n$个元素的集合$S=\{x_1,x_2,\dots,x_n\}$，位数组全初始化为$0$。<em>Bllom Filter</em>使用$k$个相互独立的哈希函数，将集合中的每个元素映射到$\{1,\dots,m\}$的范围中。对于集合中的每一个元素$x\in S$，第$i$个$（1\leq i \leq k）$哈希函数映射的位$h_i(x)$被设置为$1$（不进行重复设置）。</p></li><li><p>在判断$y$是否属于集合$S$时，如果所有$h_i(y)$$（1\leq i \leq k）$的位都已经设置为$1$，那么认为$y\in S$，否则$y \notin S$，因此存在将$y$误判为$S$中元素的情况。</p><p><img src="/2021/03/06/%E3%80%8ANetwork%20Applications%20of%20Bloom%20Filters%20A%20Survey%E3%80%8B%E7%AC%94%E8%AE%B0/fig1.png" alt></p></li><li><p><em>Bllom Filter</em>在判断一个元素是否属于它表示的集合时会有一定的错误率（<em>false positive rate</em>）。在很多应用中，只要<em>false positive</em>足够小，则可以接受这样的错误。假设$kn&lt;m$且各个哈希函数是完全随机的，则当$S$中的所有元素被哈希映射到<em>Bloom filter</em>后，某一特定位仍然为$0$的概率为</p><script type="math/tex; mode=display">p^{\prime}=\left(1-\frac{1}{m}\right)^{k n} \approx \mathrm{e}^{-k n / m}.</script><p>其中$1/m$表示任意一个哈希函数选中这一位的概率（前提是哈希函数是完全随机的），则$(1-1/m)$表示哈希一次没有选中这一位的概率。要把$S$完全映射到位数组中，需要做$kn$次哈希。令$p=e^{-kn/m}$，则$p$近似$p’$(在$O(1/m)$内)。</p><p>令$\rho$为位数组中$0$的比例，则$\mathbb{E}(\rho)=p’$。则错误率（<em>false positive rate</em>）为</p><script type="math/tex; mode=display">(1-\rho)^{k} \approx\left(1-p^{\prime}\right)^{k} \approx(1-p)^{k} .</script><p>得到</p><script type="math/tex; mode=display">f^{\prime}=\left(1-\left(1-\frac{1}{m}\right)^{k n}\right)^{k}=\left(1-p^{\prime}\right)^{k}, \\f=\left(1-\mathrm{e}^{-k n / m}\right)^{k}=(1-p)^{k}.</script><p>相比$p’$和$f’$，$p$和$f$更常见于分析中。</p></li><li><p><em>Bllom Filter</em>有另外一种表示方式，则将$m$位位数组平均分给$k$个hash函数，这样每个哈希函数的范围变为$m/k$位。在这种情况下，某一特定位为0的概率为</p><script type="math/tex; mode=display">\left(1-\frac{k}{m}\right)^{n} \approx \mathrm{e}^{-k n / m}.</script><p>近似上看，两者的表现类似。但在$k\geq1$时，</p><script type="math/tex; mode=display">\left(1-\frac{k}{m}\right)^{n} \leq\left(1-\frac{1}{m}\right)^{k n}</script><p>则精确得到第二种表示方式的<em>false positive rate</em>小于或等于第一种，并且将位按哈希函数划分能够实现并行化。</p></li><li><p>对于给定的$m$与$n$，根据<em>Bllom Filter</em>的原理可以知道：使用更多的哈希函数，那么在对一个不属于集合的元素进行查询时得到$0$的概率就大；而减少哈希函数的个数，则会提高位数组中$0$的比重，因此需要找到最合适的哈希函数值。如上得到$f=\exp \left(k \ln \left(1-\mathrm{e}^{-k n / m}\right)\right)$，设$g=k\ ln(1-e^{-kn/m})$，则寻找$f$的最小值等价于寻找$g$的最小值。求导可得</p><script type="math/tex; mode=display">\frac{\partial g}{\partial k}=\ln \left(1-\mathrm{e}^{-\frac{k n}{m}}\right)+\frac{k n}{m} \frac{\mathrm{e}^{-\frac{k n}{m}}}{1-\mathrm{e}^{-\frac{k n}{m}}}</script><p>解得零点$k=ln\ 2\ \cdot\ (m/n)$，该点也是一个全局最优值，对应解得$p=1/2$。在这种情况下，最小错误率$f=(1/2)^k\approx (0.6185)^{m/n}$。同样对于$f’$与$p’$，可以得到当$p’=1/2$时，$g’$取最小值。</p></li></ul><h3 id="A-Lower-Bound"><a href="#A-Lower-Bound" class="headerlink" title="A Lower Bound"></a>A Lower Bound</h3><ul><li>在不超过一定错误率的情况下，<em>Bloom Filter</em>需要设置足够大的$m$才能表示全集中任意$n$个元素的集合。假设全集中共有$u$个元素，允许的最大错误率为$\epsilon$，假设$X$为全集中任取$n$个元素的集合，$F(X)$是表示$X$的位数组。那么对于集合$X$中任意一个元素$x$，在$s = F(X)$中查询$x$都能得到肯定的结果，即$S$能够接受$x$。而<em>Bloom Filter</em>有错误率（<em>false positive rate</em>），对于一个确定的位数组来说，最多接受$n+\epsilon (u-n)$个元素。而一个确定的位数组可以表示$\left(\begin{array}{c}<br>n+\epsilon(u-n) \\<br>n<br>\end{array}\right)$个集合。$m$位的位数组共有$2^m$个不同的组合，全集中共有$\left(\begin{array}{c}<br>u \\<br>n<br>\end{array}\right)$个$n$元素的集合，因此要让$m$位的位数组表示所有$n$个元素的集合，有<script type="math/tex; mode=display">2^{m}\left(\begin{array}{c}n+\epsilon(u-n) \\n\end{array}\right) \geq\left(\begin{array}{l}u \\n\end{array}\right)</script>即<script type="math/tex; mode=display">m \geq \log _{2} \frac{\left(\begin{array}{l}u \\n\end{array}\right)}{\left(\begin{array}{c}n+\epsilon(u-n) \\n\end{array}\right)} \approx \log _{2} \frac{\left(\begin{array}{l}u \\n\end{array}\right)}{\left(\begin{array}{c}\epsilon u \\n\end{array}\right)} \geq \log _{2} \epsilon^{-n}=n \log _{2}(1 / \epsilon)</script>因此，$m$至少要大于$n \log _{2}(1 / \epsilon)$才能使错误率不大于给定的$\epsilon$。根据上节中$f=(1/2)^k=(1/2)^{ln\ 2\ \cdot\ (m/n)}$，令$f\leq \epsilon$得到<script type="math/tex; mode=display">m \geq n \frac{\log _{2}(1 / \epsilon)}{\ln 2}=n \log _{2} \mathrm{e} \cdot \log _{2}(1 / \epsilon).</script>这个结果是我们上面得到的最小值的$log_2e\approx1.44$倍，这说明在哈希函数的个数取到最优时，要让错误率不超过$\epsilon$，$m$至少需要取到最小值的$1.44$倍。</li></ul><h3 id="Hashing-vs-Bloom-Filters"><a href="#Hashing-vs-Bloom-Filters" class="headerlink" title="Hashing vs. Bloom Filters"></a>Hashing vs. Bloom Filters</h3><ul><li>哈希函数是常用的用以表示集合的方式，集合的每个元素都被映射到$\Theta(\text{log}\  n)$位上，然后再用一个哈希值的列表（已排序）表示集合。这种方法产生的错误率很小，如果集合中的每个元素用$2\ \text{log}_2\ n$位来表示，则两个特定的元素映射到相同哈希值的可能性为$1/n^2$，而不在集合中的元素与集合中的元素映射到相同哈希值的概率为$n/n^2=1/n$。</li><li><em>Bloom Filters</em>可以看作哈希的自然推广，它在错误率与采用的位数（空间消耗）中寻找均衡，只有一个哈希函数的<em>Bloom Filters</em>等价于普通的<em>Hashing</em>。<em>Bloom filters</em>产生一个恒定的<em>false positive rate</em>，当用以表示每个集合元素的比特数是恒定的。例如，当$m = 8n$时，<em>false positive rate</em>仅大于0.02。如果需要逐渐消失的错误率，每个元素至少需要采用$\Theta(\text{log}\  n)$位来表示，这也是<em>Bloom Filters</em>不受学术界关注的原因。相反，在实际应用中，为了保持每个元素的位数不变，一个常数错误可能是很有价值的。</li></ul><h3 id="Standard-Bloom-Filter-Tricks"><a href="#Standard-Bloom-Filter-Tricks" class="headerlink" title="　Standard Bloom Filter Tricks"></a>　Standard Bloom Filter Tricks</h3><ul><li><em>Bloom filter</em>的简单结构使得某些操作非常容易实现。假设有两个<em>Bloom filter</em>表示集合$S_1$和$S_2$，它们具有相同的比特数，并且使用相同的哈希函数。则一个表示$S_1,S_2$的并集的<em>Bloom filter</em>可以通过原有<em>Bloom filter</em>的两个位向量的<strong>OR</strong>得到。</li><li><p><em>Bloom filter</em>可以很容易地将大小减半，允许应用程序动态地缩小<em>Bloom filter</em>。假设<em>Bloom filter</em>的大小为$2$的幂。将<em>Bloom filter</em>的大小减半，可以将前半部分与后半部分做<strong>OR</strong>操作得到。当散列进行查找时，最高位可能被屏蔽。</p></li><li><p><em>Bloom filter</em>也可以用来近似两个集合之间的交集。假设有两个<em>Bloom filter</em>表示集合$S_1$和$S_2$，它们具有相同的比特数，并且使用相同的哈希函数。直观地说，这两个位向量的内积是它们相似性的度量。如果第$j$位是被两个<em>Bloom filter</em>同时设置的，那么它是被$S_1\cap S_2$中的元素设置，或者它同时被$S1−(S1∩S2)$中的某个元素和$S2−(S1∩S2)$中的另一个元素设置。则第$j$位被同时设置的概率为</p><script type="math/tex; mode=display">\begin{array}{l}\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1} \cap S_{2}\right|}\right) \\+\left(1-\frac{1}{m}\right)^{k\left|S_{1} \cap S_{2}\right|}\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1}-\left(S_{1} \cap S_{2}\right)\right|}\right)\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{2}-\left(S_{1} \cap S_{2}\right)\right|}\right)\end{array}</script><p>化简得到两个<em>Bloom filter</em>的期望内积和为</p><script type="math/tex; mode=display">m\left(1-\left(1-\frac{1}{m}\right)^{k\left|S_{1}\right|}-\left(1-\frac{1}{m}\right)^{k\left|S_{2}\right|}+\left(1-\frac{1}{m}\right)^{k\left(\left|S_{1}\right|+\left|S_{2}\right|-\left|S_{1} \cap S_{2}\right|\right)}\right) .</script><p>因此，已知$|S_1|,|S_2|, k, m，$以及内积的大小，可以用上式计算$|S_1∩S_2|$。如果没有给出$|S_1|,|S_2|$，它们也可以通过计算$S_1$,$S_2$的<em>Bloom filter</em>中的$0$位数来估计，集合$S$的$0$位数在其期望$m(1 - 1/m)^{k|S|}$附近。设$Z_1,Z_2$分别为$S_1,S_2$<em>Bloom filter</em>中$0$的个数，$Z_{12}$为内积中$0$的个数，则得到</p><script type="math/tex; mode=display">\frac{1}{m}\left(1-\frac{1}{m}\right)^{-k\left|S_{1} \cap S_{2}\right|} \approx \frac{Z_{1}+Z_{2}-Z_{12}}{Z_{1} Z_{2}}</script></li></ul><h2 id="Counting-Bloom-Filters"><a href="#Counting-Bloom-Filters" class="headerlink" title="　Counting Bloom Filters"></a>　Counting Bloom Filters</h2><ul><li><p>假设我们有一个随时间变化的集合，会进行元素插入和删除操作。将元素插入Bloom过滤器只需将元素进行哈希$k$次，并将对应位设为$1$。但不能通过逆过程来执行删除操作，如果我们对要删除的元素进行散列，并将其对应的位设为0。在这种情况下，Bloom filter不再正确地反映集合中的所有元素。</p></li><li><p>为了避免这个问题，Fan等人引入了计数布隆过滤器<em>(counting Bloom filter)</em>的思想。在一个<em>counting Bloom filter</em>中，采用一个计数器来代替位。当元素插入时，相应的计数器增加，当元素删除时，相应的计数器被减少。为了避免计数器溢出，可以选择足够大的计数器。Fan等人的分析表明，每个计数器4位就适用于大多数应用了。</p></li><li><p>要确定一个好的计数器大小，可以考虑一个<em>counting Bloom filter</em>表示$n$个元素的集合，使用$k$个哈希函数和$m$个计数器。设$c(i)$为第$i$个计数器的计数。第$i$个计数器为$j$次的概率是一个二项式随机变量</p><script type="math/tex; mode=display">\mathbb{P}(c(i)=j)=\left(\begin{array}{c}n k \\j\end{array}\right)\left(\frac{1}{m}\right)^{j}\left(1-\frac{1}{m}\right)^{n k-j} .</script><p>任何计数器至少为$j$的概率大于$m\mathbb{P}(c(i)\geq j)$，则</p><script type="math/tex; mode=display">\mathbb{P}(c(i) \geq j) \leq\left(\begin{array}{c}n k \\j\end{array}\right) \frac{1}{m^{j}} \leq\left(\frac{\mathrm{e} n k}{j m}\right)^{j}</script><p>假设$k≤(ln 2)m/n$，因为$k = (ln 2)m/n$获得最佳的<em>false positive rate</em>，则</p><script type="math/tex; mode=display">\mathbb{P}\left(\max _{i} c(i) \geq j\right) \leq m\left(\frac{\mathrm{e} \ln 2}{j}\right)^{j}</script><p>如果每个计数器设置为4位，则某个计数器达到16时，计数器就会溢出。从上面公式得到</p><script type="math/tex; mode=display">\mathbb{P}\left(\max _{i} c(i) \geq 16\right) \leq 1.37\times10^{-15}\times m</script><p>这个限制适用于最多$n$个项目的集合，这将满足大多数应用程序。另一种解释这个结果的方法是，当有$m\ \text{ln}\ 2$个总计数器增量分布在$m$个计数器上时，计数器的最大值很有可能是$O(\text{log}\ m)$，因此每个计数器只需要$O(\text{log}\ \text{log}\ m)$位。</p></li><li><p>在实践中，当计数器溢出时，一种解决方法是保持它的最大值。只有当计数器最终降至0而它本应保持非0时，这才会导致更多的<em>false positive rate</em>。如果删除是随机的，则此事件的预期时间相对较大。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Bloom Filter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2021/03/05/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <url>/2021/03/05/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="第一篇博客"><a href="#第一篇博客" class="headerlink" title="第一篇博客"></a>第一篇博客</h1><ul><li>测试一下</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  
  
  
  <entry>
    <title>about</title>
    <link href="/"/>
    <url>/</url>
    
    <content type="html"><![CDATA[]]></content>
    
  </entry>
  
  
  
</search>
